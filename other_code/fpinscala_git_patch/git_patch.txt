From 67ac0d82a8534ae1f65a334cb480e3ba2bd19572 Mon Sep 17 00:00:00 2001
From: "Felipe M. Vieira" <fmv1992@gmail.com>
Date: Fri, 7 Jun 2019 08:56:12 -0300
Subject: final version

---
 .../scala/fpinscala/applicative/Applicative.scala  |  282 -----
 .../main/scala/fpinscala/datastructures/List.scala |  327 ------
 .../main/scala/fpinscala/datastructures/Tree.scala |   80 --
 .../scala/fpinscala/errorhandling/Either.scala     |   73 --
 .../scala/fpinscala/errorhandling/Option.scala     |  113 --
 .../fpinscala/gettingstarted/GettingStarted.scala  |  180 ----
 .../main/scala/fpinscala/iomonad/BindTest.scala    |   47 -
 answers/src/main/scala/fpinscala/iomonad/IO.scala  |  629 -----------
 .../src/main/scala/fpinscala/iomonad/Monad.scala   |   72 --
 .../src/main/scala/fpinscala/iomonad/Task.scala    |   67 --
 .../src/main/scala/fpinscala/iomonad/Throw.scala   |   65 --
 .../src/main/scala/fpinscala/iomonad/package.scala |   37 -
 .../src/main/scala/fpinscala/laziness/Stream.scala |  257 -----
 .../fpinscala/localeffects/LocalEffects.scala      |  193 ----
 .../src/main/scala/fpinscala/monads/Monad.scala    |  189 ----
 .../src/main/scala/fpinscala/monoids/Monoid.scala  |  301 ------
 .../main/scala/fpinscala/parallelism/Actor.scala   |  137 ---
 .../scala/fpinscala/parallelism/Nonblocking.scala  |  197 ----
 .../src/main/scala/fpinscala/parallelism/Par.scala |  148 ---
 .../src/main/scala/fpinscala/parsing/JSON.scala    |   81 --
 .../src/main/scala/fpinscala/parsing/Parsers.scala |  247 -----
 .../fpinscala/parsing/instances/Reference.scala    |  148 ---
 .../fpinscala/parsing/instances/Sliceable.scala    |  273 -----
 answers/src/main/scala/fpinscala/state/State.scala |  241 -----
 .../src/main/scala/fpinscala/streamingio/Eq.scala  |   16 -
 .../scala/fpinscala/streamingio/MonadCatch.scala   |   23 -
 .../main/scala/fpinscala/streamingio/Partial.scala |   13 -
 .../scala/fpinscala/streamingio/StreamingIO.scala  | 1133 --------------------
 .../main/scala/fpinscala/streamingio/These.scala   |   48 -
 .../main/scala/fpinscala/testing/Exhaustive.scala  |  419 --------
 answers/src/main/scala/fpinscala/testing/Gen.scala |  305 ------
 build.sbt                                          |   14 +-
 .../scala/fpinscala/applicative/Applicative.scala  |  154 ---
 .../main/scala/fpinscala/datastructures/List.scala |   68 --
 .../main/scala/fpinscala/datastructures/Tree.scala |   13 -
 .../scala/fpinscala/errorhandling/Either.scala     |   37 -
 .../scala/fpinscala/errorhandling/Option.scala     |   48 -
 .../fpinscala/gettingstarted/GettingStarted.scala  |  178 ---
 .../src/main/scala/fpinscala/iomonad/IO.scala      |  583 ----------
 .../src/main/scala/fpinscala/iomonad/Monad.scala   |   73 --
 .../src/main/scala/fpinscala/iomonad/Task.scala    |   66 --
 .../src/main/scala/fpinscala/iomonad/package.scala |   37 -
 .../src/main/scala/fpinscala/laziness/Stream.scala |   55 -
 .../fpinscala/localeffects/LocalEffects.scala      |  143 ---
 .../src/main/scala/fpinscala/monads/Monad.scala    |   93 --
 .../src/main/scala/fpinscala/monoids/Monoid.scala  |  159 ---
 .../main/scala/fpinscala/parallelism/Actor.scala   |  138 ---
 .../scala/fpinscala/parallelism/Nonblocking.scala  |  174 ---
 .../src/main/scala/fpinscala/parallelism/Par.scala |   67 --
 .../src/main/scala/fpinscala/parsing/Parsers.scala |   34 -
 .../src/main/scala/fpinscala/state/State.scala     |   70 --
 .../scala/fpinscala/streamingio/MonadCatch.scala   |   22 -
 .../scala/fpinscala/streamingio/StreamingIO.scala  | 1030 ------------------
 .../src/main/scala/fpinscala/testing/Gen.scala     |   35 -
 project/build.properties                           |    3 +-
 .../scala/fpinscala/applicative/Applicative.scala  |  282 +++++
 .../main/scala/fpinscala/datastructures/List.scala |  327 ++++++
 .../main/scala/fpinscala/datastructures/Tree.scala |   80 ++
 .../scala/fpinscala/errorhandling/Either.scala     |   73 ++
 .../scala/fpinscala/errorhandling/Option.scala     |  113 ++
 .../fpinscala/gettingstarted/GettingStarted.scala  |  180 ++++
 .../main/scala/fpinscala/iomonad/BindTest.scala    |   47 +
 .../src/main/scala/fpinscala/iomonad/IO.scala      |  629 +++++++++++
 .../src/main/scala/fpinscala/iomonad/Monad.scala   |   72 ++
 .../src/main/scala/fpinscala/iomonad/Task.scala    |   67 ++
 .../src/main/scala/fpinscala/iomonad/Throw.scala   |   65 ++
 .../src/main/scala/fpinscala/iomonad/package.scala |   37 +
 .../src/main/scala/fpinscala/laziness/Stream.scala |  257 +++++
 .../fpinscala/localeffects/LocalEffects.scala      |  193 ++++
 .../src/main/scala/fpinscala/monads/Monad.scala    |  189 ++++
 .../src/main/scala/fpinscala/monoids/Monoid.scala  |  301 ++++++
 .../main/scala/fpinscala/parallelism/Actor.scala   |  137 +++
 .../scala/fpinscala/parallelism/Nonblocking.scala  |  197 ++++
 .../src/main/scala/fpinscala/parallelism/Par.scala |  148 +++
 .../src/main/scala/fpinscala/parsing/JSON.scala    |   81 ++
 .../src/main/scala/fpinscala/parsing/Parsers.scala |  247 +++++
 .../fpinscala/parsing/instances/Reference.scala    |  148 +++
 .../fpinscala/parsing/instances/Sliceable.scala    |  273 +++++
 .../src/main/scala/fpinscala/state/State.scala     |  241 +++++
 .../src/main/scala/fpinscala/streamingio/Eq.scala  |   16 +
 .../scala/fpinscala/streamingio/MonadCatch.scala   |   23 +
 .../main/scala/fpinscala/streamingio/Partial.scala |   13 +
 .../scala/fpinscala/streamingio/StreamingIO.scala  | 1133 ++++++++++++++++++++
 .../main/scala/fpinscala/streamingio/These.scala   |   48 +
 .../main/scala/fpinscala/testing/Exhaustive.scala  |  419 ++++++++
 .../src/main/scala/fpinscala/testing/Gen.scala     |  305 ++++++
 86 files changed, 6352 insertions(+), 9624 deletions(-)
 delete mode 100644 answers/src/main/scala/fpinscala/applicative/Applicative.scala
 delete mode 100644 answers/src/main/scala/fpinscala/datastructures/List.scala
 delete mode 100644 answers/src/main/scala/fpinscala/datastructures/Tree.scala
 delete mode 100644 answers/src/main/scala/fpinscala/errorhandling/Either.scala
 delete mode 100644 answers/src/main/scala/fpinscala/errorhandling/Option.scala
 delete mode 100644 answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
 delete mode 100644 answers/src/main/scala/fpinscala/iomonad/BindTest.scala
 delete mode 100644 answers/src/main/scala/fpinscala/iomonad/IO.scala
 delete mode 100644 answers/src/main/scala/fpinscala/iomonad/Monad.scala
 delete mode 100644 answers/src/main/scala/fpinscala/iomonad/Task.scala
 delete mode 100644 answers/src/main/scala/fpinscala/iomonad/Throw.scala
 delete mode 100644 answers/src/main/scala/fpinscala/iomonad/package.scala
 delete mode 100644 answers/src/main/scala/fpinscala/laziness/Stream.scala
 delete mode 100644 answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala
 delete mode 100644 answers/src/main/scala/fpinscala/monads/Monad.scala
 delete mode 100644 answers/src/main/scala/fpinscala/monoids/Monoid.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parallelism/Actor.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parallelism/Par.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parsing/JSON.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parsing/Parsers.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parsing/instances/Reference.scala
 delete mode 100644 answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala
 delete mode 100644 answers/src/main/scala/fpinscala/state/State.scala
 delete mode 100644 answers/src/main/scala/fpinscala/streamingio/Eq.scala
 delete mode 100644 answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala
 delete mode 100644 answers/src/main/scala/fpinscala/streamingio/Partial.scala
 delete mode 100644 answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala
 delete mode 100644 answers/src/main/scala/fpinscala/streamingio/These.scala
 delete mode 100644 answers/src/main/scala/fpinscala/testing/Exhaustive.scala
 delete mode 100644 answers/src/main/scala/fpinscala/testing/Gen.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/applicative/Applicative.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/datastructures/List.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/datastructures/Tree.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/errorhandling/Either.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/errorhandling/Option.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/iomonad/IO.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/iomonad/Monad.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/iomonad/Task.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/iomonad/package.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/laziness/Stream.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/localeffects/LocalEffects.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/monads/Monad.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/monoids/Monoid.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/parallelism/Actor.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/parallelism/Nonblocking.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/parallelism/Par.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/parsing/Parsers.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/state/State.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/streamingio/MonadCatch.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/streamingio/StreamingIO.scala
 delete mode 100644 exercises/src/main/scala/fpinscala/testing/Gen.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/applicative/Applicative.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/datastructures/List.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/datastructures/Tree.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Either.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Option.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/iomonad/BindTest.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/iomonad/IO.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/iomonad/Monad.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/iomonad/Task.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/iomonad/Throw.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/iomonad/package.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/laziness/Stream.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/monads/Monad.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/monoids/Monoid.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parallelism/Actor.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parallelism/Par.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parsing/JSON.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parsing/Parsers.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/state/State.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/streamingio/Eq.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/streamingio/Partial.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/streamingio/These.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/testing/Exhaustive.scala
 create mode 100644 src/main/scala/answers/src/main/scala/fpinscala/testing/Gen.scala

diff --git a/answers/src/main/scala/fpinscala/applicative/Applicative.scala b/answers/src/main/scala/fpinscala/applicative/Applicative.scala
deleted file mode 100644
index 1714aeb..0000000
--- a/answers/src/main/scala/fpinscala/applicative/Applicative.scala
+++ /dev/null
@@ -1,282 +0,0 @@
-package fpinscala
-package applicative
-
-import monads.Functor
-import state._
-import State._
-import monoids._
-import language.higherKinds
-import language.implicitConversions
-
-
-trait Applicative[F[_]] extends Functor[F] {
-  // `map2` is implemented by first currying `f` so we get a function
-  // of type `A => B => C`. This is a function that takes `A` and returns
-  // another function of type `B => C`. So if we map `f.curried` over an
-  // `F[A]`, we get `F[B => C]`. Passing that to `apply` along with the
-  // `F[B]` will give us the desired `F[C]`.
-  def map2[A,B,C](fa: F[A], fb: F[B])(f: (A, B) => C): F[C] =
-    apply(map(fa)(f.curried))(fb)
-
-  // We simply use `map2` to lift a function into `F` so we can apply it
-  // to both `fab` and `fa`. The function being lifted here is `_(_)`,
-  // which is the same as the lambda notation `(f, x) => f(x)`. That is,
-  // It's a function that takes two arguments:
-  //   1. A function `f`
-  //   2. An argument `x` to that function
-  // and it simply applies `f` to `x`.
-  def apply[A,B](fab: F[A => B])(fa: F[A]): F[B] =
-    map2(fab, fa)(_(_))
-
-  def unit[A](a: => A): F[A]
-
-  def map[A,B](fa: F[A])(f: A => B): F[B] =
-    apply(unit(f))(fa)
-
-  def sequence[A](fas: List[F[A]]): F[List[A]] =
-    traverse(fas)(fa => fa)
-
-  def traverse[A,B](as: List[A])(f: A => F[B]): F[List[B]] =
-    as.foldRight(unit(List[B]()))((a, fbs) => map2(f(a), fbs)(_ :: _))
-
-  def replicateM[A](n: Int, fa: F[A]): F[List[A]] =
-    sequence(List.fill(n)(fa))
-
-  def factor[A,B](fa: F[A], fb: F[B]): F[(A,B)] =
-    map2(fa, fb)((_,_))
-
-  def product[G[_]](G: Applicative[G]): Applicative[({type f[x] = (F[x], G[x])})#f] = {
-    val self = this
-    new Applicative[({type f[x] = (F[x], G[x])})#f] {
-      def unit[A](a: => A) = (self.unit(a), G.unit(a))
-      override def apply[A,B](fs: (F[A => B], G[A => B]))(p: (F[A], G[A])) =
-        (self.apply(fs._1)(p._1), G.apply(fs._2)(p._2))
-    }
-  }
-
-  // Here we simply use `map2` to lift `apply` and `unit` themselves from one
-  // Applicative into the other.
-  // If `self` and `G` both satisfy the laws, then so does the composite.
-  // The full proof can be found at
-  // https://github.com/runarorama/sannanir/blob/master/Applicative.v
-  def compose[G[_]](G: Applicative[G]): Applicative[({type f[x] = F[G[x]]})#f] = {
-    val self = this
-    new Applicative[({type f[x] = F[G[x]]})#f] {
-      def unit[A](a: => A) = self.unit(G.unit(a))
-      override def map2[A,B,C](fga: F[G[A]], fgb: F[G[B]])(f: (A,B) => C) =
-        self.map2(fga, fgb)(G.map2(_,_)(f))
-    }
-  }
-
-  def sequenceMap[K,V](ofa: Map[K,F[V]]): F[Map[K,V]] =
-    (ofa foldLeft unit(Map.empty[K,V])) { case (acc, (k, fv)) =>
-      map2(acc, fv)((m, v) => m + (k -> v))
-    }
-
-}
-
-sealed trait Validation[+E, +A]
-
-case class Failure[E](head: E, tail: Vector[E])
-  extends Validation[E, Nothing]
-
-case class Success[A](a: A) extends Validation[Nothing, A]
-
-object Applicative {
-  val streamApplicative = new Applicative[Stream] {
-
-    def unit[A](a: => A): Stream[A] =
-      Stream.continually(a) // The infinite, constant stream
-
-    override def map2[A,B,C](a: Stream[A], b: Stream[B])( // Combine elements pointwise
-                    f: (A,B) => C): Stream[C] =
-      a zip b map f.tupled
-  }
-
-  def validationApplicative[E]: Applicative[({type f[x] = Validation[E,x]})#f] =
-    new Applicative[({type f[x] = Validation[E,x]})#f] {
-      def unit[A](a: => A) = Success(a)
-      override def map2[A,B,C](fa: Validation[E,A], fb: Validation[E,B])(f: (A, B) => C) =
-        (fa, fb) match {
-          case (Success(a), Success(b)) => Success(f(a, b))
-          case (Failure(h1, t1), Failure(h2, t2)) =>
-            Failure(h1, t1 ++ Vector(h2) ++ t2)
-          case (e@Failure(_, _), _) => e
-          case (_, e@Failure(_, _)) => e
-        }
-    }
-
-  type Const[A, B] = A
-
-  implicit def monoidApplicative[M](M: Monoid[M]) =
-    new Applicative[({ type f[x] = Const[M, x] })#f] {
-      def unit[A](a: => A): M = M.zero
-      override def apply[A,B](m1: M)(m2: M): M = M.op(m1, m2)
-    }
-
-}
-
-trait Monad[F[_]] extends Applicative[F] {
-  def flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] =
-    join(map(ma)(f))
-
-  override def apply[A,B](mf: F[A => B])(ma: F[A]): F[B] =
-    flatMap(mf)(f => map(ma)(f))
-
-  override def map[A,B](m: F[A])(f: A => B): F[B] =
-    flatMap(m)(a => unit(f(a)))
-
-  override def map2[A,B,C](ma: F[A], mb: F[B])(f: (A, B) => C): F[C] =
-    flatMap(ma)(a => map(mb)(b => f(a, b)))
-
-  def compose[A,B,C](f: A => F[B], g: B => F[C]): A => F[C] =
-    a => flatMap(f(a))(g)
-
-  def join[A](mma: F[F[A]]): F[A] = flatMap(mma)(ma => ma)
-}
-
-object Monad {
-
-  // Notice that in the case of a `Left`, flatMap does nothing.
-  def eitherMonad[E]: Monad[({type f[x] = Either[E, x]})#f] =
-    new Monad[({type f[x] = Either[E, x]})#f] {
-      def unit[A](a: => A): Either[E, A] = Right(a)
-      override def flatMap[A,B](eea: Either[E, A])(f: A => Either[E, B]) = eea match {
-        case Right(a) => f(a)
-        case Left(b) => Left(b)
-      }
-    }
-
-  def stateMonad[S] = new Monad[({type f[x] = State[S, x]})#f] {
-    def unit[A](a: => A): State[S, A] = State(s => (a, s))
-    override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
-      st flatMap f
-  }
-
-  // Monad composition
-  def composeM[G[_],H[_]](implicit G: Monad[G], H: Monad[H], T: Traverse[H]):
-    Monad[({type f[x] = G[H[x]]})#f] = new Monad[({type f[x] = G[H[x]]})#f] {
-      def unit[A](a: => A): G[H[A]] = G.unit(H.unit(a))
-      override def flatMap[A,B](mna: G[H[A]])(f: A => G[H[B]]): G[H[B]] =
-        G.flatMap(mna)(na => G.map(T.traverse(na)(f))(H.join))
-    }
-
-}
-
-trait Traverse[F[_]] extends Functor[F] with Foldable[F] { self =>
-  def traverse[M[_]:Applicative,A,B](fa: F[A])(f: A => M[B]): M[F[B]] =
-    sequence(map(fa)(f))
-  def sequence[M[_]:Applicative,A](fma: F[M[A]]): M[F[A]] =
-    traverse(fma)(ma => ma)
-
-  type Id[A] = A
-
-  val idMonad = new Monad[Id] {
-    def unit[A](a: => A) = a
-    override def flatMap[A,B](a: A)(f: A => B): B = f(a)
-  }
-
-  def map[A,B](fa: F[A])(f: A => B): F[B] =
-    traverse[Id, A, B](fa)(f)(idMonad)
-
-  import Applicative._
-
-  override def foldMap[A,B](as: F[A])(f: A => B)(mb: Monoid[B]): B =
-    traverse[({type f[x] = Const[B,x]})#f,A,Nothing](
-      as)(f)(monoidApplicative(mb))
-
-  def traverseS[S,A,B](fa: F[A])(f: A => State[S, B]): State[S, F[B]] =
-    traverse[({type f[x] = State[S, x]})#f, A, B](fa)(f)(Monad.stateMonad)
-
-  def zipWithIndex_[A](ta: F[A]): F[(A,Int)] =
-    traverseS(ta)((a: A) => (for {
-      i <- get[Int]
-      _ <- set(i + 1)
-    } yield (a, i))).run(0)._1
-
-  def toList_[A](fa: F[A]): List[A] =
-    traverseS(fa)((a: A) => (for {
-      as <- get[List[A]] // Get the current state, the accumulated list.
-      _  <- set(a :: as) // Add the current element and set the new list as the new state.
-    } yield ())).run(Nil)._2.reverse
-
-  def mapAccum[S,A,B](fa: F[A], s: S)(f: (A, S) => (B, S)): (F[B], S) =
-    traverseS(fa)((a: A) => (for {
-      s1 <- get[S]
-      (b, s2) = f(a, s1)
-      _  <- set(s2)
-    } yield b)).run(s)
-
-  override def toList[A](fa: F[A]): List[A] =
-    mapAccum(fa, List[A]())((a, s) => ((), a :: s))._2.reverse
-
-  def zipWithIndex[A](fa: F[A]): F[(A, Int)] =
-    mapAccum(fa, 0)((a, s) => ((a, s), s + 1))._1
-
-  def reverse[A](fa: F[A]): F[A] =
-    mapAccum(fa, toList(fa).reverse)((_, as) => (as.head, as.tail))._1
-
-  override def foldLeft[A,B](fa: F[A])(z: B)(f: (B, A) => B): B =
-    mapAccum(fa, z)((a, b) => ((), f(b, a)))._2
-
-  def zip[A,B](fa: F[A], fb: F[B]): F[(A, B)] =
-    (mapAccum(fa, toList(fb)) {
-      case (a, Nil) => sys.error("zip: Incompatible shapes.")
-      case (a, b :: bs) => ((a, b), bs)
-    })._1
-
-  def zipL[A,B](fa: F[A], fb: F[B]): F[(A, Option[B])] =
-    (mapAccum(fa, toList(fb)) {
-      case (a, Nil) => ((a, None), Nil)
-      case (a, b :: bs) => ((a, Some(b)), bs)
-    })._1
-
-  def zipR[A,B](fa: F[A], fb: F[B]): F[(Option[A], B)] =
-    (mapAccum(fb, toList(fa)) {
-      case (b, Nil) => ((None, b), Nil)
-      case (b, a :: as) => ((Some(a), b), as)
-    })._1
-
-  def fuse[M[_],N[_],A,B](fa: F[A])(f: A => M[B], g: A => N[B])
-                         (implicit M: Applicative[M], N: Applicative[N]): (M[F[B]], N[F[B]]) =
-    traverse[({type f[x] = (M[x], N[x])})#f, A, B](fa)(a => (f(a), g(a)))(M product N)
-
-  def compose[G[_]](implicit G: Traverse[G]): Traverse[({type f[x] = F[G[x]]})#f] =
-    new Traverse[({type f[x] = F[G[x]]})#f] {
-      override def traverse[M[_]:Applicative,A,B](fa: F[G[A]])(f: A => M[B]) =
-        self.traverse(fa)((ga: G[A]) => G.traverse(ga)(f))
-    }
-}
-
-case class Tree[+A](head: A, tail: List[Tree[A]])
-
-object Traverse {
-  val listTraverse = new Traverse[List] {
-    override def traverse[M[_],A,B](as: List[A])(f: A => M[B])(implicit M: Applicative[M]): M[List[B]] =
-      as.foldRight(M.unit(List[B]()))((a, fbs) => M.map2(f(a), fbs)(_ :: _))
-  }
-
-  val optionTraverse = new Traverse[Option] {
-    override def traverse[M[_],A,B](oa: Option[A])(f: A => M[B])(implicit M: Applicative[M]): M[Option[B]] =
-      oa match {
-        case Some(a) => M.map(f(a))(Some(_))
-        case None    => M.unit(None)
-      }
-  }
-
-  val treeTraverse = new Traverse[Tree] {
-    override def traverse[M[_],A,B](ta: Tree[A])(f: A => M[B])(implicit M: Applicative[M]): M[Tree[B]] =
-      M.map2(f(ta.head), listTraverse.traverse(ta.tail)(a => traverse(a)(f)))(Tree(_, _))
-  }
-
-  // An example of a Foldable that is not a functor
-  case class Iteration[A](a: A, f: A => A, n: Int) {
-    def foldMap[B](g: A => B)(M: Monoid[B]): B = {
-      def iterate(n: Int, b: B, c: A): B =
-        if (n <= 0) b else iterate(n-1, g(c), f(a))
-      iterate(n, M.zero, a)
-    }
-  }
-}
-
-
diff --git a/answers/src/main/scala/fpinscala/datastructures/List.scala b/answers/src/main/scala/fpinscala/datastructures/List.scala
deleted file mode 100644
index c5354a2..0000000
--- a/answers/src/main/scala/fpinscala/datastructures/List.scala
+++ /dev/null
@@ -1,327 +0,0 @@
-package fpinscala.datastructures
-
-sealed trait List[+A] // `List` data type, parameterized on a type, `A`
-case object Nil extends List[Nothing] // A `List` data constructor representing the empty list
-/* Another data constructor, representing nonempty lists. Note that `tail` is another `List[A]`,
-which may be `Nil` or another `Cons`.
- */
-case class Cons[+A](head: A, tail: List[A]) extends List[A]
-
-object List { // `List` companion object. Contains functions for creating and working with lists.
-  def sum(ints: List[Int]): Int = ints match { // A function that uses pattern matching to add up a list of integers
-    case Nil => 0 // The sum of the empty list is 0.
-    case Cons(x,xs) => x + sum(xs) // The sum of a list starting with `x` is `x` plus the sum of the rest of the list.
-  }
-
-  def product(ds: List[Double]): Double = ds match {
-    case Nil => 1.0
-    case Cons(0.0, _) => 0.0
-    case Cons(x,xs) => x * product(xs)
-  }
-
-  def apply[A](as: A*): List[A] = // Variadic function syntax
-    if (as.isEmpty) Nil
-    else Cons(as.head, apply(as.tail: _*))
-
-  val x = List(1,2,3,4,5) match {
-    case Cons(x, Cons(2, Cons(4, _))) => x
-    case Nil => 42
-    case Cons(x, Cons(y, Cons(3, Cons(4, _)))) => x + y
-    case Cons(h, t) => h + sum(t)
-    case _ => 101
-  }
-
-  def append[A](a1: List[A], a2: List[A]): List[A] =
-    a1 match {
-      case Nil => a2
-      case Cons(h,t) => Cons(h, append(t, a2))
-    }
-
-  def foldRight[A,B](as: List[A], z: B)(f: (A, B) => B): B = // Utility functions
-    as match {
-      case Nil => z
-      case Cons(x, xs) => f(x, foldRight(xs, z)(f))
-    }
-
-  def sum2(ns: List[Int]) =
-    foldRight(ns, 0)((x,y) => x + y)
-
-  def product2(ns: List[Double]) =
-    foldRight(ns, 1.0)(_ * _) // `_ * _` is more concise notation for `(x,y) => x * y`; see sidebar
-
-
-  /*
-  3. The third case is the first that matches, with `x` bound to 1 and `y` bound to 2.
-  */
-
-  /*
-  Although we could return `Nil` when the input list is empty, we choose to throw an exception instead. This is
-  a somewhat subjective choice. In our experience, taking the tail of an empty list is often a bug, and silently
-  returning a value just means this bug will be discovered later, further from the place where it was introduced.
-
-  It's generally good practice when pattern matching to use `_` for any variables you don't intend to use on the
-  right hand side of a pattern. This makes it clear the value isn't relevant.
-  */
-  def tail[A](l: List[A]): List[A] =
-    l match {
-      case Nil => sys.error("tail of empty list")
-      case Cons(_,t) => t
-    }
-
-  /*
-  If a function body consists solely of a match expression, we'll often put the match on the same line as the
-  function signature, rather than introducing another level of nesting.
-  */
-  def setHead[A](l: List[A], h: A): List[A] = l match {
-    case Nil => sys.error("setHead on empty list")
-    case Cons(_,t) => Cons(h,t)
-  }
-
-  /*
-  Again, it's somewhat subjective whether to throw an exception when asked to drop more elements than the list
-  contains. The usual default for `drop` is not to throw an exception, since it's typically used in cases where this
-  is not indicative of a programming error. If you pay attention to how you use `drop`, it's often in cases where the
-  length of the input list is unknown, and the number of elements to be dropped is being computed from something else.
-  If `drop` threw an exception, we'd have to first compute or check the length and only drop up to that many elements.
-  */
-  def drop[A](l: List[A], n: Int): List[A] =
-    if (n <= 0) l
-    else l match {
-      case Nil => Nil
-      case Cons(_,t) => drop(t, n-1)
-    }
-
-  /*
-  Somewhat overkill, but to illustrate the feature we're using a _pattern guard_, to only match a `Cons` whose head
-  satisfies our predicate, `f`. The syntax is to add `if <cond>` after the pattern, before the `=>`, where `<cond>` can
-  use any of the variables introduced by the pattern.
-  */
-  def dropWhile[A](l: List[A], f: A => Boolean): List[A] =
-    l match {
-      case Cons(h,t) if f(h) => dropWhile(t, f)
-      case _ => l
-    }
-
-  /*
-  Note that we're copying the entire list up until the last element. Besides being inefficient, the natural recursive
-  solution will use a stack frame for each element of the list, which can lead to stack overflows for
-  large lists (can you see why?). With lists, it's common to use a temporary, mutable buffer internal to the
-  function (with lazy lists or streams, which we discuss in chapter 5, we don't normally do this). So long as the
-  buffer is allocated internal to the function, the mutation is not observable and RT is preserved.
-
-  Another common convention is to accumulate the output list in reverse order, then reverse it at the end, which
-  doesn't require even local mutation. We'll write a reverse function later in this chapter.
-  */
-  def init[A](l: List[A]): List[A] =
-    l match {
-      case Nil => sys.error("init of empty list")
-      case Cons(_,Nil) => Nil
-      case Cons(h,t) => Cons(h,init(t))
-    }
-  def init2[A](l: List[A]): List[A] = {
-    import collection.mutable.ListBuffer
-    val buf = new ListBuffer[A]
-    @annotation.tailrec
-    def go(cur: List[A]): List[A] = cur match {
-      case Nil => sys.error("init of empty list")
-      case Cons(_,Nil) => List(buf.toList: _*)
-      case Cons(h,t) => buf += h; go(t)
-    }
-    go(l)
-  }
-
-  /*
-  No, this is not possible! The reason is because _before_ we ever call our function, `f`, we evaluate its argument,
-  which in the case of `foldRight` means traversing the list all the way to the end. We need _non-strict_ evaluation
-  to support early termination---we discuss this in chapter 5.
-  */
-
-  /*
-  We get back the original list! Why is that? As we mentioned earlier, one way of thinking about what `foldRight` "does"
-  is it replaces the `Nil` constructor of the list with the `z` argument, and it replaces the `Cons` constructor with
-  the given function, `f`. If we just supply `Nil` for `z` and `Cons` for `f`, then we get back the input list.
-
-  foldRight(Cons(1, Cons(2, Cons(3, Nil))), Nil:List[Int])(Cons(_,_))
-  Cons(1, foldRight(Cons(2, Cons(3, Nil)), Nil:List[Int])(Cons(_,_)))
-  Cons(1, Cons(2, foldRight(Cons(3, Nil), Nil:List[Int])(Cons(_,_))))
-  Cons(1, Cons(2, Cons(3, foldRight(Nil, Nil:List[Int])(Cons(_,_)))))
-  Cons(1, Cons(2, Cons(3, Nil)))
-  */
-
-  def length[A](l: List[A]): Int =
-    foldRight(l, 0)((_,acc) => acc + 1)
-
-  /*
-  It's common practice to annotate functions you expect to be tail-recursive with the `tailrec` annotation. If the
-  function is not tail-recursive, it will yield a compile error, rather than silently compiling the code and resulting
-  in greater stack space usage at runtime.
-  */
-  @annotation.tailrec
-  def foldLeft[A,B](l: List[A], z: B)(f: (B, A) => B): B = l match {
-    case Nil => z
-    case Cons(h,t) => foldLeft(t, f(z,h))(f)
-  }
-
-  def sum3(l: List[Int]) = foldLeft(l, 0)(_ + _)
-  def product3(l: List[Double]) = foldLeft(l, 1.0)(_ * _)
-
-  def length2[A](l: List[A]): Int = foldLeft(l, 0)((acc,h) => acc + 1)
-
-  def reverse[A](l: List[A]): List[A] = foldLeft(l, List[A]())((acc,h) => Cons(h,acc))
-
-  /*
-  The implementation of `foldRight` in terms of `reverse` and `foldLeft` is a common trick for avoiding stack overflows
-  when implementing a strict `foldRight` function as we've done in this chapter. (We'll revisit this in a later chapter,
-  when we discuss laziness).
-
-  The other implementations build up a chain of functions which, when called, results in the operations being performed
-  with the correct associativity. We are calling `foldRight` with the `B` type being instantiated to `B => B`, then
-  calling the built up function with the `z` argument. Try expanding the definitions by substituting equals for equals
-  using a simple example, like `foldLeft(List(1,2,3), 0)(_ + _)` if this isn't clear. Note these implementations are
-  more of theoretical interest - they aren't stack-safe and won't work for large lists.
-  */
-  def foldRightViaFoldLeft[A,B](l: List[A], z: B)(f: (A,B) => B): B =
-    foldLeft(reverse(l), z)((b,a) => f(a,b))
-
-  def foldRightViaFoldLeft_1[A,B](l: List[A], z: B)(f: (A,B) => B): B =
-    foldLeft(l, (b:B) => b)((g,a) => b => g(f(a,b)))(z)
-
-  def foldLeftViaFoldRight[A,B](l: List[A], z: B)(f: (B,A) => B): B =
-    foldRight(l, (b:B) => b)((a,g) => b => g(f(b,a)))(z)
-
-  /*
-  `append` simply replaces the `Nil` constructor of the first list with the second list, which is exactly the operation
-  performed by `foldRight`.
-  */
-  def appendViaFoldRight[A](l: List[A], r: List[A]): List[A] =
-    foldRight(l, r)(Cons(_,_))
-
-  /*
-  Since `append` takes time proportional to its first argument, and this first argument never grows because of the
-  right-associativity of `foldRight`, this function is linear in the total length of all lists. You may want to try
-  tracing the execution of the implementation on paper to convince yourself that this works.
-
-  Note that we're simply referencing the `append` function, without writing something like `(x,y) => append(x,y)`
-  or `append(_,_)`. In Scala there is a rather arbitrary distinction between functions defined as _methods_, which are
-  introduced with the `def` keyword, and function values, which are the first-class objects we can pass to other
-  functions, put in collections, and so on. This is a case where Scala lets us pretend the distinction doesn't exist.
-  In other cases, you'll be forced to write `append _` (to convert a `def` to a function value)
-  or even `(x: List[A], y: List[A]) => append(x,y)` if the function is polymorphic and the type arguments aren't known.
-  */
-  def concat[A](l: List[List[A]]): List[A] =
-    foldRight(l, Nil:List[A])(append)
-
-  def add1(l: List[Int]): List[Int] =
-    foldRight(l, Nil:List[Int])((h,t) => Cons(h+1,t))
-
-  def doubleToString(l: List[Double]): List[String] =
-    foldRight(l, Nil:List[String])((h,t) => Cons(h.toString,t))
-
-  /*
-  A natural solution is using `foldRight`, but our implementation of `foldRight` is not stack-safe. We can
-  use `foldRightViaFoldLeft` to avoid the stack overflow (variation 1), but more commonly, with our current
-  implementation of `List`, `map` will just be implemented using local mutation (variation 2). Again, note that the
-  mutation isn't observable outside the function, since we're only mutating a buffer that we've allocated.
-  */
-  def map[A,B](l: List[A])(f: A => B): List[B] =
-    foldRight(l, Nil:List[B])((h,t) => Cons(f(h),t))
-
-  def map_1[A,B](l: List[A])(f: A => B): List[B] =
-    foldRightViaFoldLeft(l, Nil:List[B])((h,t) => Cons(f(h),t))
-
-  def map_2[A,B](l: List[A])(f: A => B): List[B] = {
-    val buf = new collection.mutable.ListBuffer[B]
-    def go(l: List[A]): Unit = l match {
-      case Nil => ()
-      case Cons(h,t) => buf += f(h); go(t)
-    }
-    go(l)
-    List(buf.toList: _*) // converting from the standard Scala list to the list we've defined here
-  }
-
-  /*
-  The discussion about `map` also applies here.
-  */
-  def filter[A](l: List[A])(f: A => Boolean): List[A] =
-    foldRight(l, Nil:List[A])((h,t) => if (f(h)) Cons(h,t) else t)
-
-  def filter_1[A](l: List[A])(f: A => Boolean): List[A] =
-    foldRightViaFoldLeft(l, Nil:List[A])((h,t) => if (f(h)) Cons(h,t) else t)
-
-  def filter_2[A](l: List[A])(f: A => Boolean): List[A] = {
-    val buf = new collection.mutable.ListBuffer[A]
-    def go(l: List[A]): Unit = l match {
-      case Nil => ()
-      case Cons(h,t) => if (f(h)) buf += h; go(t)
-    }
-    go(l)
-    List(buf.toList: _*) // converting from the standard Scala list to the list we've defined here
-  }
-
-  /*
-  This could also be implemented directly using `foldRight`.
-  */
-  def flatMap[A,B](l: List[A])(f: A => List[B]): List[B] =
-    concat(map(l)(f))
-
-  def filterViaFlatMap[A](l: List[A])(f: A => Boolean): List[A] =
-    flatMap(l)(a => if (f(a)) List(a) else Nil)
-
-  /*
-  To match on multiple values, we can put the values into a pair and match on the pair, as shown next, and the same
-  syntax extends to matching on N values (see sidebar "Pairs and tuples in Scala" for more about pair and tuple
-  objects). You can also (somewhat less conveniently, but a bit more efficiently) nest pattern matches: on the
-  right hand side of the `=>`, simply begin another `match` expression. The inner `match` will have access to all the
-  variables introduced in the outer `match`.
-
-  The discussion about stack usage from the explanation of `map` also applies here.
-  */
-  def addPairwise(a: List[Int], b: List[Int]): List[Int] = (a,b) match {
-    case (Nil, _) => Nil
-    case (_, Nil) => Nil
-    case (Cons(h1,t1), Cons(h2,t2)) => Cons(h1+h2, addPairwise(t1,t2))
-  }
-
-  /*
-  This function is usually called `zipWith`. The discussion about stack usage from the explanation of `map` also
-  applies here. By putting the `f` in the second argument list, Scala can infer its type from the previous argument list.
-  */
-  def zipWith[A,B,C](a: List[A], b: List[B])(f: (A,B) => C): List[C] = (a,b) match {
-    case (Nil, _) => Nil
-    case (_, Nil) => Nil
-    case (Cons(h1,t1), Cons(h2,t2)) => Cons(f(h1,h2), zipWith(t1,t2)(f))
-  }
-
-  /*
-  There's nothing particularly bad about this implementation,
-  except that it's somewhat monolithic and easy to get wrong.
-  Where possible, we prefer to assemble functions like this using
-  combinations of other functions. It makes the code more obviously
-  correct and easier to read and understand. Notice that in this
-  implementation we need special purpose logic to break out of our
-  loops early. In Chapter 5 we'll discuss ways of composing functions
-  like this from simpler components, without giving up the efficiency
-  of having the resulting functions work in one pass over the data.
-  
-  It's good to specify some properties about these functions.
-  For example, do you expect these expressions to be true?
-  
-  (xs append ys) startsWith xs
-  xs startsWith Nil
-  (xs append ys append zs) hasSubsequence ys
-  xs hasSubsequence Nil
-
-  */
-  @annotation.tailrec
-  def startsWith[A](l: List[A], prefix: List[A]): Boolean = (l,prefix) match {
-    case (_,Nil) => true
-    case (Cons(h,t),Cons(h2,t2)) if h == h2 => startsWith(t, t2)
-    case _ => false
-  }
-  @annotation.tailrec
-  def hasSubsequence[A](sup: List[A], sub: List[A]): Boolean = sup match {
-    case Nil => sub == Nil
-    case _ if startsWith(sup, sub) => true
-    case Cons(h,t) => hasSubsequence(t, sub)
-  }
-}
diff --git a/answers/src/main/scala/fpinscala/datastructures/Tree.scala b/answers/src/main/scala/fpinscala/datastructures/Tree.scala
deleted file mode 100644
index edb1018..0000000
--- a/answers/src/main/scala/fpinscala/datastructures/Tree.scala
+++ /dev/null
@@ -1,80 +0,0 @@
-package fpinscala.datastructures
-
-sealed trait Tree[+A]
-case class Leaf[A](value: A) extends Tree[A]
-case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]
-
-
-object Tree {
-
-
-
-  def size[A](t: Tree[A]): Int = t match {
-    case Leaf(_) => 1
-    case Branch(l,r) => 1 + size(l) + size(r)
-  }
-
-  /*
-  We're using the method `max` that exists on all `Int` values rather than an explicit `if` expression.
-  
-  Note how similar the implementation is to `size`. We'll abstract out the common pattern in a later exercise. 
-  */
-  def maximum(t: Tree[Int]): Int = t match {
-    case Leaf(n) => n
-    case Branch(l,r) => maximum(l) max maximum(r)
-  }
-
-  /*
-  Again, note how similar the implementation is to `size` and `maximum`.
-  */
-  def depth[A](t: Tree[A]): Int = t match {
-    case Leaf(_) => 0
-    case Branch(l,r) => 1 + (depth(l) max depth(r))
-  }
-
-  def map[A,B](t: Tree[A])(f: A => B): Tree[B] = t match {
-    case Leaf(a) => Leaf(f(a))
-    case Branch(l,r) => Branch(map(l)(f), map(r)(f))
-  }
-
-  /* 
-  Like `foldRight` for lists, `fold` receives a "handler" for each of the data constructors of the type, and recursively
-  accumulates some value using these handlers. As with `foldRight`, `fold(t)(Leaf(_))(Branch(_,_)) == t`, and we can use
-  this function to implement just about any recursive function that would otherwise be defined by pattern matching.
-  */
-  def fold[A,B](t: Tree[A])(f: A => B)(g: (B,B) => B): B = t match {
-    case Leaf(a) => f(a)
-    case Branch(l,r) => g(fold(l)(f)(g), fold(r)(f)(g))
-  }
-  
-  def sizeViaFold[A](t: Tree[A]): Int = 
-    fold(t)(a => 1)(1 + _ + _)
-  
-  def maximumViaFold(t: Tree[Int]): Int = 
-    fold(t)(a => a)(_ max _)
-  
-  def depthViaFold[A](t: Tree[A]): Int = 
-    fold(t)(a => 0)((d1,d2) => 1 + (d1 max d2))
-  
-  /*
-  Note the type annotation required on the expression `Leaf(f(a))`. Without this annotation, we get an error like this: 
-  
-  type mismatch;
-    found   : fpinscala.datastructures.Branch[B]
-    required: fpinscala.datastructures.Leaf[B]
-       fold(t)(a => Leaf(f(a)))(Branch(_,_))
-                                      ^  
-  
-  This error is an unfortunate consequence of Scala using subtyping to encode algebraic data types. Without the
-  annotation, the result type of the fold gets inferred as `Leaf[B]` and it is then expected that the second argument
-  to `fold` will return `Leaf[B]`, which it doesn't (it returns `Branch[B]`). Really, we'd prefer Scala to
-  infer `Tree[B]` as the result type in both cases. When working with algebraic data types in Scala, it's somewhat
-  common to define helper functions that simply call the corresponding data constructors but give the less specific
-  result type:
-    
-    def leaf[A](a: A): Tree[A] = Leaf(a)
-    def branch[A](l: Tree[A], r: Tree[A]): Tree[A] = Branch(l, r)
-  */
-  def mapViaFold[A,B](t: Tree[A])(f: A => B): Tree[B] = 
-    fold(t)(a => Leaf(f(a)): Tree[B])(Branch(_,_))
-}
\ No newline at end of file
diff --git a/answers/src/main/scala/fpinscala/errorhandling/Either.scala b/answers/src/main/scala/fpinscala/errorhandling/Either.scala
deleted file mode 100644
index 0e0fa3c..0000000
--- a/answers/src/main/scala/fpinscala/errorhandling/Either.scala
+++ /dev/null
@@ -1,73 +0,0 @@
-package fpinscala.errorhandling
-
-
-//hide std library `Option` and `Either`, since we are writing our own in this chapter
-import scala.{Option => _, Either => _, _}
-
-sealed trait Either[+E,+A] {
- def map[B](f: A => B): Either[E, B] = 
-   this match {
-     case Right(a) => Right(f(a))
-     case Left(e) => Left(e)
-   }
-   
- def flatMap[EE >: E, B](f: A => Either[EE, B]): Either[EE, B] =
-   this match {
-     case Left(e) => Left(e)
-     case Right(a) => f(a)
-   }
- def orElse[EE >: E, AA >: A](b: => Either[EE, AA]): Either[EE, AA] =
-   this match {
-     case Left(_) => b
-     case Right(a) => Right(a)
-   }
- def map2[EE >: E, B, C](b: Either[EE, B])(f: (A, B) => C): 
-   Either[EE, C] = for { a <- this; b1 <- b } yield f(a,b1)
-}
-case class Left[+E](get: E) extends Either[E,Nothing]
-case class Right[+A](get: A) extends Either[Nothing,A]
-
-object Either {
-  def mean(xs: IndexedSeq[Double]): Either[String, Double] = 
-    if (xs.isEmpty) 
-      Left("mean of empty list!")
-    else 
-      Right(xs.sum / xs.length)
-
-  def safeDiv(x: Int, y: Int): Either[Exception, Int] = 
-    try Right(x / y)
-    catch { case e: Exception => Left(e) }
-
-  def Try[A](a: => A): Either[Exception, A] =
-    try Right(a)
-    catch { case e: Exception => Left(e) }
-
-  def traverse[E,A,B](es: List[A])(f: A => Either[E, B]): Either[E, List[B]] = 
-    es match {
-      case Nil => Right(Nil)
-      case h::t => (f(h) map2 traverse(t)(f))(_ :: _)
-    }
-  
-  def traverse_1[E,A,B](es: List[A])(f: A => Either[E, B]): Either[E, List[B]] = 
-    es.foldRight[Either[E,List[B]]](Right(Nil))((a, b) => f(a).map2(b)(_ :: _))
-  
-  def sequence[E,A](es: List[Either[E,A]]): Either[E,List[A]] = 
-    traverse(es)(x => x)
-
-  /*
-  There are a number of variations on `Option` and `Either`. If we want to accumulate multiple errors, a simple
-  approach is a new data type that lets us keep a list of errors in the data constructor that represents failures:
-  
-  trait Partial[+A,+B]
-  case class Errors[+A](get: Seq[A]) extends Partial[A,Nothing]
-  case class Success[+B](get: B) extends Partial[Nothing,B]
-  
-  There is a type very similar to this called `Validation` in the Scalaz library. You can implement `map`, `map2`,
-  `sequence`, and so on for this type in such a way that errors are accumulated when possible (`flatMap` is unable to
-  accumulate errors--can you see why?). This idea can even be generalized further--we don't need to accumulate failing
-  values into a list; we can accumulate values using any user-supplied binary function.
-  
-  It's also possible to use `Either[List[E],_]` directly to accumulate errors, using different implementations of
-  helper functions like `map2` and `sequence`.
-  */
-}
\ No newline at end of file
diff --git a/answers/src/main/scala/fpinscala/errorhandling/Option.scala b/answers/src/main/scala/fpinscala/errorhandling/Option.scala
deleted file mode 100644
index f2ca3dc..0000000
--- a/answers/src/main/scala/fpinscala/errorhandling/Option.scala
+++ /dev/null
@@ -1,113 +0,0 @@
-package fpinscala.errorhandling
-
-//hide std library `Option` and `Either`, since we are writing our own in this chapter
-import scala.{Option => _, Either => _, _}
-
-sealed trait Option[+A] {
-  def map[B](f: A => B): Option[B] = this match {
-    case None => None
-    case Some(a) => Some(f(a))
-  }
-
-  def getOrElse[B>:A](default: => B): B = this match {
-    case None => default
-    case Some(a) => a
-  }
-
-  def flatMap[B](f: A => Option[B]): Option[B] =
-    map(f) getOrElse None
-
-  /*
-  Of course, we can also implement `flatMap` with explicit pattern matching.
-  */
-  def flatMap_1[B](f: A => Option[B]): Option[B] = this match {
-    case None => None
-    case Some(a) => f(a)
-  }
-
-  def orElse[B>:A](ob: => Option[B]): Option[B] =
-    this map (Some(_)) getOrElse ob
-
-  /*
-  Again, we can implement this with explicit pattern matching.
-  */
-  def orElse_1[B>:A](ob: => Option[B]): Option[B] = this match {
-    case None => ob
-    case _ => this
-  }
-
-  def filter(f: A => Boolean): Option[A] = this match {
-    case Some(a) if f(a) => this
-    case _ => None
-  }
-  /*
-  This can also be defined in terms of `flatMap`.
-  */
-  def filter_1(f: A => Boolean): Option[A] =
-    flatMap(a => if (f(a)) Some(a) else None)
-}
-case class Some[+A](get: A) extends Option[A]
-case object None extends Option[Nothing]
-
-object Option {
-  def failingFn(i: Int): Int = {
-    // `val y: Int = ...` declares `y` as having type `Int`, and sets it equal to the right hand side of the `=`.
-    val y: Int = throw new Exception("fail!")
-    try {
-      val x = 42 + 5
-      x + y
-    }
-    // A `catch` block is just a pattern matching block like the ones we've seen. `case e: Exception` is a pattern
-    // that matches any `Exception`, and it binds this value to the identifier `e`. The match returns the value 43.
-    catch { case e: Exception => 43 }
-  }
-
-  def failingFn2(i: Int): Int = {
-    try {
-      val x = 42 + 5
-      // A thrown Exception can be given any type; here we're annotating it with the type `Int`
-      x + ((throw new Exception("fail!")): Int)
-    }
-    catch { case e: Exception => 43 }
-  }
-
-  def mean(xs: Seq[Double]): Option[Double] =
-    if (xs.isEmpty) None
-    else Some(xs.sum / xs.length)
-
-  def variance(xs: Seq[Double]): Option[Double] =
-    mean(xs) flatMap (m => mean(xs.map(x => math.pow(x - m, 2))))
-
-  // a bit later in the chapter we'll learn nicer syntax for
-  // writing functions like this
-  def map2[A,B,C](a: Option[A], b: Option[B])(f: (A, B) => C): Option[C] =
-    a flatMap (aa => b map (bb => f(aa, bb)))
-
-  /*
-  Here's an explicit recursive version:
-  */
-  def sequence[A](a: List[Option[A]]): Option[List[A]] =
-    a match {
-      case Nil => Some(Nil)
-      case h :: t => h flatMap (hh => sequence(t) map (hh :: _))
-    }
-  /*
-  It can also be implemented using `foldRight` and `map2`. The type annotation on `foldRight` is needed here; otherwise
-  Scala wrongly infers the result type of the fold as `Some[Nil.type]` and reports a type error (try it!). This is an
-  unfortunate consequence of Scala using subtyping to encode algebraic data types.
-  */
-  def sequence_1[A](a: List[Option[A]]): Option[List[A]] =
-    a.foldRight[Option[List[A]]](Some(Nil))((x,y) => map2(x,y)(_ :: _))
-
-  def traverse[A, B](a: List[A])(f: A => Option[B]): Option[List[B]] =
-    a match {
-      case Nil => Some(Nil)
-      case h::t => map2(f(h), traverse(t)(f))(_ :: _)
-    }
-
-  def traverse_1[A, B](a: List[A])(f: A => Option[B]): Option[List[B]] =
-    a.foldRight[Option[List[B]]](Some(Nil))((h,t) => map2(f(h),t)(_ :: _))
-
-  def sequenceViaTraverse[A](a: List[Option[A]]): Option[List[A]] =
-    traverse(a)(x => x)
-}
diff --git a/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala b/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
deleted file mode 100644
index 9dadf08..0000000
--- a/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
+++ /dev/null
@@ -1,180 +0,0 @@
-package fpinscala.gettingstarted
-
-// A comment!
-/* Another comment */
-/** A documentation comment */
-object MyModule {
-  def abs(n: Int): Int =
-    if (n < 0) -n
-    else n
-
-  private def formatAbs(x: Int) = {
-    val msg = "The absolute value of %d is %d"
-    msg.format(x, abs(x))
-  }
-
-  def main(args: Array[String]): Unit =
-    println(formatAbs(-42))
-
-  // A definition of factorial, using a local, tail recursive function
-  def factorial(n: Int): Int = {
-    @annotation.tailrec
-    def go(n: Int, acc: Int): Int =
-      if (n <= 0) acc
-      else go(n-1, n*acc)
-
-    go(n, 1)
-  }
-
-  // Another implementation of `factorial`, this time with a `while` loop
-  def factorial2(n: Int): Int = {
-    var acc = 1
-    var i = n
-    while (i > 0) { acc *= i; i -= 1 }
-    acc
-  }
-
-  // Exercise 1: Write a function to compute the nth fibonacci number
-
-  // 0 and 1 are the first two numbers in the sequence,
-  // so we start the accumulators with those.
-  // At every iteration, we add the two numbers to get the next one.
-  def fib(n: Int): Int = {
-    @annotation.tailrec
-    def loop(n: Int, prev: Int, cur: Int): Int =
-      if (n == 0) prev
-      else loop(n - 1, cur, prev + cur)
-    loop(n, 0, 1)
-  }
-
-  // This definition and `formatAbs` are very similar..
-  private def formatFactorial(n: Int) = {
-    val msg = "The factorial of %d is %d."
-    msg.format(n, factorial(n))
-  }
-
-  // We can generalize `formatAbs` and `formatFactorial` to
-  // accept a _function_ as a parameter
-  def formatResult(name: String, n: Int, f: Int => Int) = {
-    val msg = "The %s of %d is %d."
-    msg.format(name, n, f(n))
-  }
-}
-
-object FormatAbsAndFactorial {
-
-  import MyModule._
-
-  // Now we can use our general `formatResult` function
-  // with both `abs` and `factorial`
-  def main(args: Array[String]): Unit = {
-    println(formatResult("absolute value", -42, abs))
-    println(formatResult("factorial", 7, factorial))
-  }
-}
-
-// Functions get passed around so often in FP that it's
-// convenient to have syntax for constructing a function
-// *without* having to give it a name
-object AnonymousFunctions {
-  import MyModule._
-
-  // Some examples of anonymous functions:
-  def main(args: Array[String]): Unit = {
-    println(formatResult("absolute value", -42, abs))
-    println(formatResult("factorial", 7, factorial))
-    println(formatResult("increment", 7, (x: Int) => x + 1))
-    println(formatResult("increment2", 7, (x) => x + 1))
-    println(formatResult("increment3", 7, x => x + 1))
-    println(formatResult("increment4", 7, _ + 1))
-    println(formatResult("increment5", 7, x => { val r = x + 1; r }))
-  }
-}
-
-object MonomorphicBinarySearch {
-
-  // First, a findFirst, specialized to `String`.
-  // Ideally, we could generalize this to work for any `Array` type.
-  def findFirst(ss: Array[String], key: String): Int = {
-    @annotation.tailrec
-    def loop(n: Int): Int =
-      // If `n` is past the end of the array, return `-1`
-      // indicating the key doesn't exist in the array.
-      if (n >= ss.length) -1
-      // `ss(n)` extracts the n'th element of the array `ss`.
-      // If the element at `n` is equal to the key, return `n`
-      // indicating that the element appears in the array at that index.
-      else if (ss(n) == key) n
-      else loop(n + 1) // Otherwise increment `n` and keep looking.
-    // Start the loop at the first element of the array.
-    loop(0)
-  }
-
-}
-
-object PolymorphicFunctions {
-
-  // Here's a polymorphic version of `findFirst`, parameterized on
-  // a function for testing whether an `A` is the element we want to find.
-  // Instead of hard-coding `String`, we take a type `A` as a parameter.
-  // And instead of hard-coding an equality check for a given key,
-  // we take a function with which to test each element of the array.
-  def findFirst[A](as: Array[A], p: A => Boolean): Int = {
-    @annotation.tailrec
-    def loop(n: Int): Int =
-      if (n >= as.length) -1
-      // If the function `p` matches the current element,
-      // we've found a match and we return its index in the array.
-      else if (p(as(n))) n
-      else loop(n + 1)
-
-    loop(0)
-  }
-
-
-  // Exercise 2: Implement a polymorphic function to check whether
-  // an `Array[A]` is sorted
-  def isSorted[A](as: Array[A], gt: (A,A) => Boolean): Boolean = {
-    @annotation.tailrec
-    def go(n: Int): Boolean =
-      if (n >= as.length-1) true
-      else if (gt(as(n), as(n+1))) false
-      else go(n+1)
-
-    go(0)
-  }
-
-  // Polymorphic functions are often so constrained by their type
-  // that they only have one implementation! Here's an example:
-
-  def partial1[A,B,C](a: A, f: (A,B) => C): B => C =
-    (b: B) => f(a, b)
-
-  // Exercise 3: Implement `curry`.
-
-  // Note that `=>` associates to the right, so we could
-  // write the return type as `A => B => C`
-  def curry[A,B,C](f: (A, B) => C): A => (B => C) =
-    a => b => f(a, b)
-
-  // NB: The `Function2` trait has a `curried` method already
-
-  // Exercise 4: Implement `uncurry`
-  def uncurry[A,B,C](f: A => B => C): (A, B) => C =
-    (a, b) => f(a)(b)
-
-  /*
-  NB: There is a method on the `Function` object in the standard library,
-  `Function.uncurried` that you can use for uncurrying.
-
-  Note that we can go back and forth between the two forms. We can curry
-  and uncurry and the two forms are in some sense "the same". In FP jargon,
-  we say that they are _isomorphic_ ("iso" = same; "morphe" = shape, form),
-  a term we inherit from category theory.
-  */
-
-  // Exercise 5: Implement `compose`
-
-  def compose[A,B,C](f: B => C, g: A => B): A => C =
-    a => f(g(a))
-}
diff --git a/answers/src/main/scala/fpinscala/iomonad/BindTest.scala b/answers/src/main/scala/fpinscala/iomonad/BindTest.scala
deleted file mode 100644
index 803d0cc..0000000
--- a/answers/src/main/scala/fpinscala/iomonad/BindTest.scala
+++ /dev/null
@@ -1,47 +0,0 @@
-package fpinscala.iomonad
-
-import language.higherKinds
-import language.postfixOps
-
-object BindTest extends App {
-
-  def timeit(n: Int)(task: => Unit): Unit = {
-    val start = System.currentTimeMillis
-    (0 to n).foreach { _ => task }
-    val stop = System.currentTimeMillis
-    println((stop - start) / 1000.0 + " seconds")
-  }
-
-  val N = 100000
-  def go[F[_]](F: Monad[F])(unit: F[Unit])(f: F[Int] => Int): Unit = {
-    import F.toMonadic
-    f { (0 to N).map(i => F.map(unit)(_ => i)).foldLeft(F.unit(0)) {
-      (f1,f2) => for {
-        acc <- f1
-        i <- f2
-      } yield { // if (i == N) println("result: " + (acc+i))
-                (acc + i)
-              }
-    }}
-  }
-
-  import fpinscala.parallelism.Nonblocking._
-
-  object ParMonad extends Monad[Par] {
-    def unit[A](a: => A) = Par.unit(a)
-    def flatMap[A,B](pa: Par[A])(f: A => Par[B]) = Par.fork { Par.flatMap(pa)(f) }
-  }
-
-  val pool = java.util.concurrent.Executors.newFixedThreadPool(4)
-
-  timeit(10) { go(Throw)(Throw.unit(())) ( _ run ) }
-  timeit(10) { go(IO2b.TailRec)(IO2b.TailRec.unit(())) ( IO2b.run ) }
-  timeit(10) { go(IO2c.Async)(IO2c.Async.unit(()))(r => Par.run(pool) { IO2c.run(r) }) }
-  timeit(10) { go[IO](ioMonad)(ioMonad.unit(()))(r => unsafePerformIO(r)(pool)) }
-  timeit(10) { go(Task)(Task.now(()))(r => r.run(pool)) }
-  timeit(10) { go(Task)(Task.forkUnit(()))(r => r.run(pool)) }
-  timeit(10) { go(ParMonad)(ParMonad.unit(())) { p => Par.run(pool)(p) }}
-
-  // Par.run(pool)(ParMonad.forever { ParMonad.unit { println("woot") }})
-  pool.shutdown()
-}
diff --git a/answers/src/main/scala/fpinscala/iomonad/IO.scala b/answers/src/main/scala/fpinscala/iomonad/IO.scala
deleted file mode 100644
index 47a1d34..0000000
--- a/answers/src/main/scala/fpinscala/iomonad/IO.scala
+++ /dev/null
@@ -1,629 +0,0 @@
-package fpinscala.iomonad
-
-import scala.io.StdIn.readLine
-import language.higherKinds
-import language.postfixOps
-
-object IO0 {
-                            /*
-
-  Our first attempt at data type for representing computations that
-  may perform I/O. Has a simple 'interpreter' baked in--the `run`
-  function, which just returns `Unit`.
-
-                             */
-  trait IO { self =>
-    def run: Unit
-    def ++(io: IO): IO = new IO {
-      def run = { self.run; io.run }
-    }
-  }
-  object IO {
-    def empty: IO = new IO { def run = () }
-  }
-
-                            /*
-
-  The API of this `IO` type isn't very useful.  Not many operations
-  (it is only a monoid), and not many laws to help with reasoning. It
-  is completely _opaque_. Also cannot represent _input_ effects, like
-  reading from console, for instance:
-
-                             */
-
-  def fahrenheitToCelsius(f: Double): Double =
-    (f - 32) * 5.0/9.0
-
-  // Ordinary code with side effects
-  def converter: Unit = {
-    println("Enter a temperature in degrees Fahrenheit: ")
-    val d = readLine.toDouble
-    println(fahrenheitToCelsius(d))
-  }
-
-  // A pure version is not possible!
-  /*
-  def converter: IO = {
-    val prompt: IO = PrintLine("Enter a temperature in degrees fahrenheit: ")
-    // now what ???
-  }
-  */
-}
-
-object IO1 {
-                            /*
-
-  We need a way for our `IO` actions to yield a result of some
-  meaningful type. We do this by adding a type parameter to `IO`,
-  which now forms a `Monad`.
-                             */
-
-  sealed trait IO[A] { self =>
-    def run: A
-    def map[B](f: A => B): IO[B] =
-      new IO[B] { def run = f(self.run) }
-    def flatMap[B](f: A => IO[B]): IO[B] =
-      new IO[B] { def run = f(self.run).run }
-  }
-
-  object IO extends Monad[IO] {
-    def unit[A](a: => A): IO[A] = new IO[A] { def run = a }
-    def flatMap[A,B](fa: IO[A])(f: A => IO[B]) = fa flatMap f
-    def apply[A](a: => A): IO[A] = unit(a) // syntax for IO { .. }
-
-    def ref[A](a: A): IO[IORef[A]] = IO { new IORef(a) }
-    sealed class IORef[A](var value: A) {
-      def set(a: A): IO[A] = IO { value = a; a }
-      def get: IO[A] = IO { value }
-      def modify(f: A => A): IO[A] = get flatMap (a => set(f(a)))
-    }
-  }
-
-  // We can now express the example
-
-  def ReadLine: IO[String] = IO { readLine }
-  def PrintLine(msg: String): IO[Unit] = IO { println(msg) }
-  import IO0.fahrenheitToCelsius
-
-  def converter: IO[Unit] = for {
-    _ <- PrintLine("Enter a temperature in degrees Fahrenheit: ")
-    d <- ReadLine.map(_.toDouble)
-    _ <- PrintLine(fahrenheitToCelsius(d).toString)
-  } yield ()
-
-  /*                         Some other examples                      */
-
-  import IO._ // import all the `IO` combinators that come from `Monad`
-
-  // An `IO[Unit]` that reads a line from the console and echoes it back.
-  val echo = ReadLine.flatMap(PrintLine)
-
-  // Parses an `Int` by reading a line from the console.
-  val readInt: IO[Int] = ReadLine.map(_.toInt)
-
-  // Parses an `(Int,Int)` by reading two lines from the console.
-  val readInts: IO[(Int,Int)] = readInt ** readInt
-
-  // Repeat `converter` 5 times, discarding the results (which are
-  // just `Unit`). We can replace `converter` here with any `IO`
-  // action we wished to repeat 5 times (ex: `echo` or `readInts`).
-  val prompts: IO[Unit] = replicateM_(5)(converter)
-
-  // An `IO[List[String]]` that will read 10 lines from the console and
-  // return the list of results.
-  val lines: IO[List[String]] = replicateM(10)(ReadLine)
-
-                            /*
-
-  Larger example using various monadic combinators. Sample run:
-
-     The Amazing Factorial REPL, v2.0
-     q - quit
-     <number> - compute the factorial of the given number
-     <anything else> - bomb with horrible error
-     3
-     factorial: 6
-     7
-     factorial: 5040
-     q
-
-                             */
-  val helpstring = """
-  | The Amazing Factorial REPL, v2.0
-  | q - quit
-  | <number> - compute the factorial of the given number
-  | <anything else> - bomb with horrible error
-  """.trim.stripMargin
-
-  def factorial(n: Int): IO[Int] = for {
-    acc <- ref(1)
-    _ <- foreachM (1 to n toStream) (i => acc.modify(_ * i).skip)
-    result <- acc.get
-  } yield result
-
-  val factorialREPL: IO[Unit] = sequence_(
-    IO { println(helpstring) },
-    doWhile { IO { readLine } } { line =>
-      val ok = line != "q"
-      when (ok) { for {
-        n <- factorial(line.toInt)
-        _ <- IO { println("factorial: " + n) }
-      } yield () }
-    }
-  )
-}
-
-
-object IO2a {
-
-  /*
-  The previous IO representation overflows the stack for some programs.
-  The problem is that `run` call itself recursively, which means that
-  an infinite or long running IO computation will have a chain of regular
-  calls to `run`, eventually overflowing the stack.
-
-  The general solution is to make the `IO` type into a data type that we
-  interpret using a tail recursive loop, using pattern matching.
-  */
-
-  sealed trait IO[A] {
-    def flatMap[B](f: A => IO[B]): IO[B] =
-      FlatMap(this, f) // we do not interpret the `flatMap` here, just return it as a value
-    def map[B](f: A => B): IO[B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[A](a: A) extends IO[A]
-  case class Suspend[A](resume: () => A) extends IO[A]
-  case class FlatMap[A,B](sub: IO[A], k: A => IO[B]) extends IO[B]
-
-  object IO extends Monad[IO] { // Notice that none of these operations DO anything
-    def unit[A](a: => A): IO[A] = Return(a)
-    def flatMap[A,B](a: IO[A])(f: A => IO[B]): IO[B] = a flatMap f
-    def suspend[A](a: => IO[A]) =
-      Suspend(() => ()).flatMap { _ => a }
-
-  }
-
-  def printLine(s: String): IO[Unit] =
-    Suspend(() => Return(println(s)))
-
-  val p = IO.forever(printLine("Still going..."))
-
-  val actions: Stream[IO[Unit]] =
-    Stream.fill(100000)(printLine("Still going..."))
-  val composite: IO[Unit] =
-    actions.foldLeft(IO.unit(())) { (acc, a) => acc flatMap { _ => a } }
-
-  // There is only one sensible way to implement this as a
-  // tail-recursive function, the one tricky case is left-nested
-  // flatMaps, as in `((a flatMap f) flatMap g)`, which we
-  // reassociate to the right as `a flatMap (ar => f(a) flatMap g)`
-  @annotation.tailrec def run[A](io: IO[A]): A = io match {
-    case Return(a) => a
-    case Suspend(r) => r()
-    case FlatMap(x, f) => x match {
-      case Return(a) => run(f(a))
-      case Suspend(r) => run(f(r()))
-      case FlatMap(y, g) => run(y flatMap (a => g(a) flatMap f))
-    }
-  }
-}
-
-object IO2aTests {
-  import IO2a._
-
-  /*
-  Pg 240: REPL session has a typo, should be:
-
-  val g = List.fill(100000)(f).foldLeft(f) {
-    (a, b) => x => Suspend(() => ()).flatMap { _ => a(x).flatMap(b)}
-  }
-
-  Note: we could write a little helper function to make this nicer:
-
-  def suspend[A](a: => IO[A]) = Suspend(() => ()).flatMap { _ => a }
-
-  val g = List.fill(100000)(f).foldLeft(f) {
-    (a, b) => x => suspend { a(x).flatMap(b) }
-  }
-   */
-
-  val f: Int => IO[Int] = (i: Int) => Return(i)
-
-  val g: Int => IO[Int] =
-    List.fill(10000)(f).foldLeft(f){
-      (a: Function1[Int, IO[Int]],
-        b: Function1[Int, IO[Int]]) => {
-        (x: Int) => IO.suspend(a(x).flatMap(b))
-      }
-    }
-
-  def main(args: Array[String]): Unit = {
-    val gFortyTwo = g(42)
-    println("g(42) = " + gFortyTwo)
-    println("run(g(42)) = " + run(gFortyTwo))
-  }
-}
-
-
-
-object IO2b {
-
-  /*
-   * As it turns out, there's nothing about this data type that is specific
-   * to I/O, it's just a general purpose data type for optimizing tail calls.
-   * Here it is, renamed to `TailRec`. This type is also sometimes called
-   * `Trampoline`, because of the way interpreting it bounces back and forth
-   * between the main `run` loop and the functions contained in the `TailRec`.
-   */
-
-  sealed trait TailRec[A] {
-    def flatMap[B](f: A => TailRec[B]): TailRec[B] =
-      FlatMap(this, f)
-    def map[B](f: A => B): TailRec[B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[A](a: A) extends TailRec[A]
-  case class Suspend[A](resume: () => A) extends TailRec[A]
-  case class FlatMap[A,B](sub: TailRec[A], k: A => TailRec[B]) extends TailRec[B]
-
-  object TailRec extends Monad[TailRec] {
-    def unit[A](a: => A): TailRec[A] = Return(a)
-    def flatMap[A,B](a: TailRec[A])(f: A => TailRec[B]): TailRec[B] = a flatMap f
-    def suspend[A](a: => TailRec[A]) =
-      Suspend(() => ()).flatMap { _ => a }
-
-  }
-
-  @annotation.tailrec def run[A](t: TailRec[A]): A = t match {
-    case Return(a) => a
-    case Suspend(r) => r()
-    case FlatMap(x, f) => x match {
-      case Return(a) => run(f(a))
-      case Suspend(r) => run(f(r()))
-      case FlatMap(y, g) => run(y flatMap (a => g(a) flatMap f))
-    }
-  }
-}
-
-object IO2bTests {
-  import IO2b._
-
-  val f: Int => TailRec[Int] = (i: Int) => Return(i)
-
-  val g: Int => TailRec[Int] =
-    List.fill(10000)(f).foldLeft(f){
-      (a: Function1[Int, TailRec[Int]],
-        b: Function1[Int, TailRec[Int]]) => {
-        (x: Int) => TailRec.suspend(a(x).flatMap(b))
-      }
-    }
-
-  def main(args: Array[String]): Unit = {
-    val gFortyTwo = g(42)
-    println("g(42) = " + gFortyTwo)
-    println("run(g(42)) = " + run(gFortyTwo))
-  }
-}
-
-
-object IO2c {
-
-  import fpinscala.parallelism.Nonblocking._
-
-  /*
-   * We've solved our first problem of ensuring stack safety, but we're still
-   * being very inexplicit about what sort of effects can occur, and we also
-   * haven't found a way of describing asynchronous computations. Our `Suspend`
-   * thunks will just block the current thread when run by the interpreter.
-   * We could fix that by changing the signature of `Suspend` to take a `Par`.
-   * We'll call this new type `Async`.
-   */
-
-  sealed trait Async[A] { // will rename this type to `Async`
-    def flatMap[B](f: A => Async[B]): Async[B] =
-      FlatMap(this, f)
-    def map[B](f: A => B): Async[B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[A](a: A) extends Async[A]
-  case class Suspend[A](resume: Par[A]) extends Async[A] // notice this is a `Par`
-  case class FlatMap[A,B](sub: Async[A], k: A => Async[B]) extends Async[B]
-
-  object Async extends Monad[Async] {
-    def unit[A](a: => A): Async[A] = Return(a)
-    def flatMap[A,B](a: Async[A])(f: A => Async[B]): Async[B] = a flatMap f
-  }
-
-  // return either a `Suspend`, a `Return`, or a right-associated `FlatMap`
-  @annotation.tailrec def step[A](async: Async[A]): Async[A] = async match {
-    case FlatMap(FlatMap(x, f), g) => step(x flatMap (a => f(a) flatMap g))
-    case FlatMap(Return(x), f) => step(f(x))
-    case _ => async
-  }
-
-  def run[A](async: Async[A]): Par[A] = step(async) match {
-    case Return(a) => Par.unit(a)
-    case Suspend(r) => r
-    case FlatMap(x, f) => x match {
-      case Suspend(r) => Par.flatMap(r)(a => run(f(a)))
-      case _ => sys.error("Impossible, since `step` eliminates these cases")
-    }
-  }
-  // The fact that `run` only uses the `unit` and `flatMap` functions of
-  // `Par` is a clue that choosing `Par` was too specific of a choice,
-  // this interpreter could be generalized to work with any monad.
-}
-
-
-object IO3 {
-
-  /*
-  We can generalize `TailRec` and `Async` to the type `Free`, which is
-  a `Monad` for any choice of `F`.
-  */
-
-  sealed trait Free[F[_],A] {
-    def flatMap[B](f: A => Free[F,B]): Free[F,B] =
-      FlatMap(this, f)
-    def map[B](f: A => B): Free[F,B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[F[_],A](a: A) extends Free[F, A]
-  case class Suspend[F[_],A](s: F[A]) extends Free[F, A]
-  case class FlatMap[F[_],A,B](s: Free[F, A],
-                               f: A => Free[F, B]) extends Free[F, B]
-
-  // Exercise 1: Implement the free monad
-  def freeMonad[F[_]]: Monad[({type f[a] = Free[F,a]})#f] =
-    new Monad[({type f[a] = Free[F,a]})#f] {
-      def unit[A](a: => A) = Return(a)
-      def flatMap[A,B](fa: Free[F, A])(f: A => Free[F, B]) = fa flatMap f
-    }
-
-  // Exercise 2: Implement a specialized `Function0` interpreter.
-  @annotation.tailrec
-  def runTrampoline[A](a: Free[Function0,A]): A = (a) match {
-    case Return(a) => a
-    case Suspend(r) => r()
-    case FlatMap(x,f) => x match {
-      case Return(a) => runTrampoline { f(a) }
-      case Suspend(r) => runTrampoline { f(r()) }
-      case FlatMap(a0,g) => runTrampoline { a0 flatMap { a0 => g(a0) flatMap f } }
-    }
-  }
-
-  // Exercise 3: Implement a `Free` interpreter which works for any `Monad`
-  def run[F[_],A](a: Free[F,A])(implicit F: Monad[F]): F[A] = step(a) match {
-    case Return(a) => F.unit(a)
-    case Suspend(r) => r
-    case FlatMap(Suspend(r), f) => F.flatMap(r)(a => run(f(a)))
-    case _ => sys.error("Impossible, since `step` eliminates these cases")
-  }
-
-  // return either a `Suspend`, a `Return`, or a right-associated `FlatMap`
-  @annotation.tailrec
-  def step[F[_],A](a: Free[F,A]): Free[F,A] = a match {
-    case FlatMap(FlatMap(x, f), g) => step(x flatMap (a => f(a) flatMap g))
-    case FlatMap(Return(x), f) => step(f(x))
-    case _ => a
-  }
-
-  /*
-  The type constructor `F` lets us control the set of external requests our
-  program is allowed to make. For instance, here is a type that allows for
-  only console I/O effects.
-  */
-
-  import fpinscala.parallelism.Nonblocking.Par
-
-  sealed trait Console[A] {
-    def toPar: Par[A]
-    def toThunk: () => A
-
-    // other interpreters
-    def toState: ConsoleState[A]
-    def toReader: ConsoleReader[A]
-  }
-
-  case object ReadLine extends Console[Option[String]] {
-    def toPar = Par.lazyUnit(run)
-    def toThunk = () => run
-
-    def run: Option[String] =
-      try Some(readLine())
-      catch { case e: Exception => None }
-
-    def toState = ConsoleState { bufs =>
-      bufs.in match {
-        case List() => (None, bufs)
-        case h :: t => (Some(h), bufs.copy(in = t))
-      }
-    }
-    def toReader = ConsoleReader { in => Some(in) }
-  }
-
-  case class PrintLine(line: String) extends Console[Unit] {
-    def toPar = Par.lazyUnit(println(line))
-    def toThunk = () => println(line)
-    def toReader = ConsoleReader { s => () } // noop
-    def toState = ConsoleState { bufs => ((), bufs.copy(out = bufs.out :+ line)) } // append to the output
-  }
-
-  object Console {
-    type ConsoleIO[A] = Free[Console, A]
-
-    def readLn: ConsoleIO[Option[String]] =
-      Suspend(ReadLine)
-
-    def printLn(line: String): ConsoleIO[Unit] =
-      Suspend(PrintLine(line))
-  }
-
-  /*
-  How do we actually _run_ a `ConsoleIO` program? We don't have a `Monad[Console]`
-  for calling `run`, and we can't use `runTrampoline` either since we have `Console`,
-  not `Function0`. We need a way to translate from `Console` to `Function0`
-  (if we want to evaluate it sequentially) or a `Par`.
-
-  We introduce the following type to do this translation:
-  */
-
-  /* Translate between any `F[A]` to `G[A]`. */
-  trait Translate[F[_], G[_]] { def apply[A](f: F[A]): G[A] }
-
-  type ~>[F[_], G[_]] = Translate[F,G] // gives us infix syntax `F ~> G` for `Translate[F,G]`
-
-  implicit val function0Monad = new Monad[Function0] {
-    def unit[A](a: => A) = () => a
-    def flatMap[A,B](a: Function0[A])(f: A => Function0[B]) =
-      () => f(a())()
-  }
-
-  implicit val parMonad = new Monad[Par] {
-    def unit[A](a: => A) = Par.unit(a)
-    def flatMap[A,B](a: Par[A])(f: A => Par[B]) = Par.fork { Par.flatMap(a)(f) }
-  }
-
-  def runFree[F[_],G[_],A](free: Free[F,A])(t: F ~> G)(
-                           implicit G: Monad[G]): G[A] =
-    step(free) match {
-      case Return(a) => G.unit(a)
-      case Suspend(r) => t(r)
-      case FlatMap(Suspend(r), f) => G.flatMap(t(r))(a => runFree(f(a))(t))
-      case _ => sys.error("Impossible, since `step` eliminates these cases")
-    }
-
-  val consoleToFunction0 =
-    new (Console ~> Function0) { def apply[A](a: Console[A]) = a.toThunk }
-  val consoleToPar =
-    new (Console ~> Par) { def apply[A](a: Console[A]) = a.toPar }
-
-  def runConsoleFunction0[A](a: Free[Console,A]): () => A =
-    runFree[Console,Function0,A](a)(consoleToFunction0)
-  def runConsolePar[A](a: Free[Console,A]): Par[A] =
-    runFree[Console,Par,A](a)(consoleToPar)
-
-  /*
-  The `runConsoleFunction0` implementation is unfortunately not stack safe,
-  because it relies of the stack safety of the underlying monad, and the
-  `Function0` monad we gave is not stack safe. To see the problem, try
-  running: `freeMonad.forever(Console.printLn("Hello"))`.
-  */
-
-  // Exercise 4 (optional, hard): Implement `runConsole` using `runFree`,
-  // without going through `Par`. Hint: define `translate` using `runFree`.
-
-  def translate[F[_],G[_],A](f: Free[F,A])(fg: F ~> G): Free[G,A] = {
-    type FreeG[A] = Free[G,A]
-    val t = new (F ~> FreeG) {
-      def apply[A](a: F[A]): Free[G,A] = Suspend { fg(a) }
-    }
-    runFree(f)(t)(freeMonad[G])
-  }
-
-  def runConsole[A](a: Free[Console,A]): A =
-    runTrampoline { translate(a)(new (Console ~> Function0) {
-      def apply[A](c: Console[A]) = c.toThunk
-    })}
-
-
-  /*
-  There is nothing about `Free[Console,A]` that requires we interpret
-  `Console` using side effects. Here are two pure ways of interpreting
-  a `Free[Console,A]`.
-  */
-  import Console._
-
-  case class Buffers(in: List[String], out: Vector[String])
-
-  // A specialized state monad
-  case class ConsoleState[A](run: Buffers => (A, Buffers)) {
-    def map[B](f: A => B): ConsoleState[B] =
-      ConsoleState { s =>
-        val (a, s1) = run(s)
-        (f(a), s1)
-      }
-    def flatMap[B](f: A => ConsoleState[B]): ConsoleState[B] =
-      ConsoleState { s =>
-        val (a, s1) = run(s)
-        f(a).run(s1)
-      }
-  }
-  object ConsoleState {
-    implicit val monad = new Monad[ConsoleState] {
-      def unit[A](a: => A) = ConsoleState(bufs => (a,bufs))
-      def flatMap[A,B](ra: ConsoleState[A])(f: A => ConsoleState[B]) = ra flatMap f
-    }
-  }
-
-  // A specialized reader monad
-  case class ConsoleReader[A](run: String => A) {
-    def map[B](f: A => B): ConsoleReader[B] =
-      ConsoleReader(r => f(run(r)))
-    def flatMap[B](f: A => ConsoleReader[B]): ConsoleReader[B] =
-      ConsoleReader(r => f(run(r)).run(r))
-  }
-  object ConsoleReader {
-    implicit val monad = new Monad[ConsoleReader] {
-      def unit[A](a: => A) = ConsoleReader(_ => a)
-      def flatMap[A,B](ra: ConsoleReader[A])(f: A => ConsoleReader[B]) = ra flatMap f
-    }
-  }
-
-  val consoleToState =
-    new (Console ~> ConsoleState) { def apply[A](a: Console[A]) = a.toState }
-  val consoleToReader =
-    new (Console ~> ConsoleReader) { def apply[A](a: Console[A]) = a.toReader }
-
-  /* Can interpet these as before to convert our `ConsoleIO` to a pure value that does no I/O! */
-  def runConsoleReader[A](io: ConsoleIO[A]): ConsoleReader[A] =
-    runFree[Console,ConsoleReader,A](io)(consoleToReader)
-
-  def runConsoleState[A](io: ConsoleIO[A]): ConsoleState[A] =
-    runFree[Console,ConsoleState,A](io)(consoleToState)
-
-  // So `Free[F,A]` is not really an I/O type. The interpreter `runFree` gets
-  // to choose how to interpret these `F` requests, and whether to do "real" I/O
-  // or simply convert to some pure value!
-
-  // NB: These interpretations are not stack safe for the same reason,
-  // can instead work with `case class ConsoleReader[A](run: String => Trampoline[A])`,
-  // which gives us a stack safe monad
-
-  // We conclude that a good representation of an `IO` monad is this:
-  type IO[A] = Free[Par, A]
-
-  /*
-   * Exercise 5: Implement a non-blocking read from an asynchronous file channel.
-   * We'll just give the basic idea - here, we construct a `Future`
-   * by reading from an `AsynchronousFileChannel`, a `java.nio` class
-   * which supports asynchronous reads.
-   */
-
-  import java.nio._
-  import java.nio.channels._
-
-  // Provides the syntax `Async { k => ... }` for asyncronous IO blocks.
-  def Async[A](cb: (A => Unit) => Unit): IO[A] =
-    Suspend(Par.async(cb))
-
-  // Provides the `IO { ... }` syntax for synchronous IO blocks.
-  def IO[A](a: => A): IO[A] = Suspend { Par.delay(a) }
-
-  def read(file: AsynchronousFileChannel,
-           fromPosition: Long,
-           numBytes: Int): Par[Either[Throwable, Array[Byte]]] =
-    Par.async { (cb: Either[Throwable, Array[Byte]] => Unit) =>
-      val buf = ByteBuffer.allocate(numBytes)
-      file.read(buf, fromPosition, (), new CompletionHandler[Integer, Unit] {
-        def completed(bytesRead: Integer, ignore: Unit) = {
-          val arr = new Array[Byte](bytesRead)
-          buf.slice.get(arr, 0, bytesRead)
-          cb(Right(arr))
-        }
-        def failed(err: Throwable, ignore: Unit) =
-          cb(Left(err))
-      })
-    }
-}
diff --git a/answers/src/main/scala/fpinscala/iomonad/Monad.scala b/answers/src/main/scala/fpinscala/iomonad/Monad.scala
deleted file mode 100644
index 52b35e2..0000000
--- a/answers/src/main/scala/fpinscala/iomonad/Monad.scala
+++ /dev/null
@@ -1,72 +0,0 @@
-package fpinscala.iomonad
-
-import language.higherKinds // Disable warnings for type constructor polymorphism
-import language.implicitConversions
-
-trait Functor[F[_]] {
-  def map[A,B](a: F[A])(f: A => B): F[B]
-}
-
-trait Monad[F[_]] extends Functor[F] {
-  def unit[A](a: => A): F[A]
-  def flatMap[A,B](a: F[A])(f: A => F[B]): F[B]
-
-  def map[A,B](a: F[A])(f: A => B): F[B] = flatMap(a)(a => unit(f(a)))
-  def map2[A,B,C](a: F[A], b: F[B])(f: (A,B) => C): F[C] =
-    flatMap(a)(a => map(b)(b => f(a,b)))
-  def sequence_[A](fs: Stream[F[A]]): F[Unit] = foreachM(fs)(skip)
-  def sequence_[A](fs: F[A]*): F[Unit] = sequence_(fs.toStream)
-  def replicateM[A](n: Int)(f: F[A]): F[List[A]] =
-    Stream.fill(n)(f).foldRight(unit(List[A]()))(map2(_,_)(_ :: _))
-  def replicateM_[A](n: Int)(f: F[A]): F[Unit] =
-    foreachM(Stream.fill(n)(f))(skip)
-  def as[A,B](a: F[A])(b: B): F[B] = map(a)(_ => b)
-  def skip[A](a: F[A]): F[Unit] = as(a)(())
-  def when[A](b: Boolean)(fa: => F[A]): F[Boolean] =
-    if (b) as(fa)(true) else unit(false)
-  def forever[A,B](a: F[A]): F[B] = {
-    lazy val t: F[B] = a flatMap (_ => t)
-    t
-  }
-  def while_(a: F[Boolean])(b: F[Unit]): F[Unit] = {
-    lazy val t: F[Unit] = while_(a)(b)
-    a flatMap (c => skip(when(c)(t)))
-  }
-  def doWhile[A](a: F[A])(cond: A => F[Boolean]): F[Unit] = for {
-    a1 <- a
-    ok <- cond(a1)
-    _ <- if (ok) doWhile(a)(cond) else unit(())
-  } yield ()
-
-  def foldM[A,B](l: Stream[A])(z: B)(f: (B,A) => F[B]): F[B] =
-    l match {
-      case h #:: t => f(z,h) flatMap (z2 => foldM(t)(z2)(f))
-      case _ => unit(z)
-    }
-  def foldM_[A,B](l: Stream[A])(z: B)(f: (B,A) => F[B]): F[Unit] =
-    skip { foldM(l)(z)(f) }
-  def foreachM[A](l: Stream[A])(f: A => F[Unit]): F[Unit] =
-    foldM_(l)(())((u,a) => skip(f(a)))
-  def seq[A,B,C](f: A => F[B])(g: B => F[C]): A => F[C] =
-    f andThen (fb => flatMap(fb)(g))
-
-  // syntax
-  implicit def toMonadic[A](a: F[A]): Monadic[F,A] =
-    new Monadic[F,A] { val F = Monad.this; def get = a }
-}
-
-trait Monadic[F[_],A] {
-  val F: Monad[F]
-  import F._
-  def get: F[A]
-  private val a = get
-  def map[B](f: A => B): F[B] = F.map(a)(f)
-  def flatMap[B](f: A => F[B]): F[B] = F.flatMap(a)(f)
-  def **[B](b: F[B]) = F.map2(a,b)((_,_))
-  def *>[B](b: F[B]) = F.map2(a,b)((_,b) => b)
-  def map2[B,C](b: F[B])(f: (A,B) => C): F[C] = F.map2(a,b)(f)
-  def as[B](b: B): F[B] = F.as(a)(b)
-  def skip: F[Unit] = F.skip(a)
-  def replicateM(n: Int) = F.replicateM(n)(a)
-  def replicateM_(n: Int) = F.replicateM_(n)(a)
-}
diff --git a/answers/src/main/scala/fpinscala/iomonad/Task.scala b/answers/src/main/scala/fpinscala/iomonad/Task.scala
deleted file mode 100644
index 0e8349a..0000000
--- a/answers/src/main/scala/fpinscala/iomonad/Task.scala
+++ /dev/null
@@ -1,67 +0,0 @@
-package fpinscala.iomonad
-
-import fpinscala.parallelism.Nonblocking._
-import java.util.concurrent.ExecutorService
-
-/*
- * `Task[A]` is a wrapper around `Free[Par, Either[Throwable, A]]`, with some
- * convenience functions for handling exceptions.
- */
-case class Task[A](get: IO[Either[Throwable, A]]) {
-
-  def flatMap[B](f: A => Task[B]): Task[B] =
-    Task(get.flatMap {
-      case Left(e) => IO(Left(e))
-      case Right(a) => f(a).get
-    })
-
-  def map[B](f: A => B): Task[B] = flatMap(f andThen (Task.now))
-
-  /* 'Catches' exceptions in the given task and returns them as values. */
-  def attempt: Task[Either[Throwable,A]] =
-    Task(get map {
-      case Left(e) => Right(Left(e))
-      case Right(a) => Right(Right(a))
-    })
-
-  def handle[B>:A](f: PartialFunction[Throwable,B]): Task[B] =
-    attempt flatMap {
-      case Left(e) => f.lift(e) map (Task.now) getOrElse Task.fail(e)
-      case Right(a) => Task.now(a)
-    }
-
-  def or[B>:A](t2: Task[B]): Task[B] =
-    Task(this.get flatMap {
-      case Left(e) => t2.get
-      case a => IO(a)
-    })
-
-  def run(implicit E: ExecutorService): A = unsafePerformIO(get) match {
-    case Left(e) => throw e
-    case Right(a) => a
-  }
-
-  def attemptRun(implicit E: ExecutorService): Either[Throwable,A] =
-    try unsafePerformIO(get) catch { case t: Throwable => Left(t) }
-}
-
-object Task extends Monad[Task] {
-  def unit[A](a: => A) = Task(IO(Try(a)))
-
-  def flatMap[A,B](a: Task[A])(f: A => Task[B]): Task[B] =
-    a flatMap f
-
-  def fail[A](e: Throwable): Task[A] = Task(IO(Left(e)))
-  def now[A](a: A): Task[A] = Task(Return(Right(a)))
-
-  def more[A](a: => Task[A]): Task[A] = Task.now(()) flatMap (_ => a)
-
-  def delay[A](a: => A): Task[A] = more(now(a))
-  def fork[A](a: => Task[A]): Task[A] =
-    Task { par { Par.lazyUnit(()) } flatMap (_ => a.get) }
-  def forkUnit[A](a: => A): Task[A] = fork(now(a))
-
-  def Try[A](a: => A): Either[Throwable,A] =
-    try Right(a) catch { case e: Throwable => Left(e) }
-}
-
diff --git a/answers/src/main/scala/fpinscala/iomonad/Throw.scala b/answers/src/main/scala/fpinscala/iomonad/Throw.scala
deleted file mode 100644
index 5bf1d6b..0000000
--- a/answers/src/main/scala/fpinscala/iomonad/Throw.scala
+++ /dev/null
@@ -1,65 +0,0 @@
-package fpinscala.iomonad
-
-/**
- * A version of `TailRec` implemented using exceptions.
- * In the implementation of `flatMap`, rather than calling
- * the function, we throw an exception indicating what
- * function we want to call. A central loop repeatedly tries
- * and catches these exceptions to force the computation.
- */
-trait Throw[+A] {
-  import Throw._
-
-  @annotation.tailrec
-  final def run: A = this match {
-    case Done(a) => a
-    case More(thunk) => force(thunk).run
-  }
-}
-
-object Throw extends Monad[Throw] {
-
-  /* Exception indicating that the central loop should call `f(a)`. */
-  case class Call[A,+B] private[Throw] (a: A, f: A => B) extends Exception {
-    override def fillInStackTrace = this
-  }
-
-  case class Done[+A](a: A) extends Throw[A]
-  case class More[+A](thunk: () => Throw[A]) extends Throw[A]
-
-  /* Defer evaluation of `f(a)` to the central evaluation loop. */
-  def defer[A,B](a: A)(f: A => B): B =
-    throw new Call(a, f)
-
-  /* Central evaluation loop. */
-  def ap[A,B](a: A)(f: A => B): B = {
-    var ai: Any = a
-    var fi: Any => Any = f.asInstanceOf[Any => Any]
-    while (true) {
-      try return fi(ai).asInstanceOf[B]
-      catch { case Call(a2,f2) => ai = a2; fi = f2; }
-    }
-    return null.asInstanceOf[B] // unreachable
-  }
-
-  /* Convenience function for forcing a thunk. */
-  def force[A](f: () => A): A =
-    ap(f)(f => f())
-
-  def more[A](a: => Throw[A]): Throw[A] = More(() => a)
-
-  /* `Throw` forms a `Monad`. */
-
-  def unit[A](a: => A): Throw[A] = more(Done(a))
-
-  def flatMap[A,B](a: Throw[A])(f: A => Throw[B]): Throw[B] =
-    a match {
-      case Done(a) => f(a)
-      case More(thunk) =>
-        try thunk() flatMap f
-        catch { case Call(a0,g) => more {
-          defer(a0)(g.asInstanceOf[Any => Throw[A]].
-                    andThen(_ flatMap f))
-        }}
-    }
-}
diff --git a/answers/src/main/scala/fpinscala/iomonad/package.scala b/answers/src/main/scala/fpinscala/iomonad/package.scala
deleted file mode 100644
index 29c2b6e..0000000
--- a/answers/src/main/scala/fpinscala/iomonad/package.scala
+++ /dev/null
@@ -1,37 +0,0 @@
-package fpinscala
-
-import language.higherKinds
-
-package object iomonad {
-  import fpinscala.parallelism.Nonblocking._
-
-  type IO[A] = IO3.IO[A]
-  def IO[A](a: => A): IO[A] = IO3.IO[A](a)
-
-  implicit val ioMonad = IO3.freeMonad[Par]
-
-  def now[A](a: A): IO[A] = IO3.Return(a)
-
-  def fork[A](a: => IO[A]): IO[A] = par(Par.lazyUnit(())) flatMap (_ => a)
-
-  def forkUnit[A](a: => A): IO[A] = fork(now(a))
-
-  def delay[A](a: => A): IO[A] = now(()) flatMap (_ => now(a))
-
-  def par[A](a: Par[A]): IO[A] = IO3.Suspend(a)
-
-  def async[A](cb: ((A => Unit) => Unit)): IO[A] =
-    fork(par(Par.async(cb)))
-
-  type Free[F[_], A] = IO3.Free[F, A]
-
-  def Return[A](a: A): IO[A] = IO3.Return[Par,A](a)
-
-  // To run an `IO`, we need an executor service.
-  // The name we have chosen for this method, `unsafePerformIO`,
-  // reflects that is is unsafe, i.e. that it has side effects,
-  // and that it _performs_ the actual I/O.
-  import java.util.concurrent.ExecutorService
-  def unsafePerformIO[A](io: IO[A])(implicit E: ExecutorService): A =
-    Par.run(E) { IO3.run(io)(IO3.parMonad) }
-}
diff --git a/answers/src/main/scala/fpinscala/laziness/Stream.scala b/answers/src/main/scala/fpinscala/laziness/Stream.scala
deleted file mode 100644
index d2a2f94..0000000
--- a/answers/src/main/scala/fpinscala/laziness/Stream.scala
+++ /dev/null
@@ -1,257 +0,0 @@
-package fpinscala.laziness
-
-import Stream._
-trait Stream[+A] {
-
-  // The natural recursive solution
-  def toListRecursive: List[A] = this match {
-    case Cons(h,t) => h() :: t().toListRecursive
-    case _ => List()
-  }
-
-  /*
-  The above solution will stack overflow for large streams, since it's
-  not tail-recursive. Here is a tail-recursive implementation. At each
-  step we cons onto the front of the `acc` list, which will result in the
-  reverse of the stream. Then at the end we reverse the result to get the
-  correct order again.
-  */
-  def toList: List[A] = {
-    @annotation.tailrec
-    def go(s: Stream[A], acc: List[A]): List[A] = s match {
-      case Cons(h,t) => go(t(), h() :: acc)
-      case _ => acc
-    }
-    go(this, List()).reverse
-  }
-
-  /*
-  In order to avoid the `reverse` at the end, we could write it using a
-  mutable list buffer and an explicit loop instead. Note that the mutable
-  list buffer never escapes our `toList` method, so this function is
-  still _pure_.
-  */
-  def toListFast: List[A] = {
-    val buf = new collection.mutable.ListBuffer[A]
-    @annotation.tailrec
-    def go(s: Stream[A]): List[A] = s match {
-      case Cons(h,t) =>
-        buf += h()
-        go(t())
-      case _ => buf.toList
-    }
-    go(this)
-  }
-
-  /*
-    Create a new Stream[A] from taking the n first elements from this. We can achieve that by recursively
-    calling take on the invoked tail of a cons cell. We make sure that the tail is not invoked unless
-    we need to, by handling the special case where n == 1 separately. If n == 0, we can avoid looking
-    at the stream at all.
-  */
-  def take(n: Int): Stream[A] = this match {
-    case Cons(h, t) if n > 1 => cons(h(), t().take(n - 1))
-    case Cons(h, _) if n == 1 => cons(h(), empty)
-    case _ => empty
-  }
-
-  /*
-    Create a new Stream[A] from this, but ignore the n first elements. This can be achieved by recursively calling
-    drop on the invoked tail of a cons cell. Note that the implementation is also tail recursive.
-  */
-  @annotation.tailrec
-  final def drop(n: Int): Stream[A] = this match {
-    case Cons(_, t) if n > 0 => t().drop(n - 1)
-    case _ => this
-  }
-
-  /*
-  It's a common Scala style to write method calls without `.` notation, as in `t() takeWhile f`.
-  */
-  def takeWhile(f: A => Boolean): Stream[A] = this match {
-    case Cons(h,t) if f(h()) => cons(h(), t() takeWhile f)
-    case _ => empty
-  }
-
-  def foldRight[B](z: => B)(f: (A, => B) => B): B = // The arrow `=>` in front of the argument type `B` means that the function `f` takes its second argument by name and may choose not to evaluate it.
-    this match {
-      case Cons(h,t) => f(h(), t().foldRight(z)(f)) // If `f` doesn't evaluate its second argument, the recursion never occurs.
-      case _ => z
-    }
-
-  def exists(p: A => Boolean): Boolean =
-    foldRight(false)((a, b) => p(a) || b) // Here `b` is the unevaluated recursive step that folds the tail of the stream. If `p(a)` returns `true`, `b` will never be evaluated and the computation terminates early.
-
-  /*
-  Since `&&` is non-strict in its second argument, this terminates the traversal as soon as a nonmatching element is found.
-  */
-  def forAll(f: A => Boolean): Boolean =
-    foldRight(true)((a,b) => f(a) && b)
-
-  def takeWhile_1(f: A => Boolean): Stream[A] =
-    foldRight(empty[A])((h,t) =>
-      if (f(h)) cons(h,t)
-      else      empty)
-
-  def headOption: Option[A] =
-    foldRight(None: Option[A])((h,_) => Some(h))
-
-  def map[B](f: A => B): Stream[B] =
-    foldRight(empty[B])((h,t) => cons(f(h), t))
-
-  def filter(f: A => Boolean): Stream[A] =
-    foldRight(empty[A])((h,t) =>
-      if (f(h)) cons(h, t)
-      else t)
-
-  def append[B>:A](s: => Stream[B]): Stream[B] =
-    foldRight(s)((h,t) => cons(h,t))
-
-  def flatMap[B](f: A => Stream[B]): Stream[B] =
-    foldRight(empty[B])((h,t) => f(h) append t)
-
-  def mapViaUnfold[B](f: A => B): Stream[B] =
-    unfold(this) {
-      case Cons(h,t) => Some((f(h()), t()))
-      case _ => None
-    }
-
-  def takeViaUnfold(n: Int): Stream[A] =
-    unfold((this,n)) {
-      case (Cons(h,t), 1) => Some((h(), (empty, 0)))
-      case (Cons(h,t), n) if n > 1 => Some((h(), (t(), n-1)))
-      case _ => None
-    }
-
-  def takeWhileViaUnfold(f: A => Boolean): Stream[A] =
-    unfold(this) {
-      case Cons(h,t) if f(h()) => Some((h(), t()))
-      case _ => None
-    }
-
-  def zipWith[B,C](s2: Stream[B])(f: (A,B) => C): Stream[C] =
-    unfold((this, s2)) {
-      case (Cons(h1,t1), Cons(h2,t2)) =>
-        Some((f(h1(), h2()), (t1(), t2())))
-      case _ => None
-    }
-
-  // special case of `zipWith`
-  def zip[B](s2: Stream[B]): Stream[(A,B)] =
-    zipWith(s2)((_,_))
-
-
-  def zipAll[B](s2: Stream[B]): Stream[(Option[A],Option[B])] =
-    zipWithAll(s2)((_,_))
-
-  def zipWithAll[B, C](s2: Stream[B])(f: (Option[A], Option[B]) => C): Stream[C] =
-    Stream.unfold((this, s2)) {
-      case (Empty, Empty) => None
-      case (Cons(h, t), Empty) => Some(f(Some(h()), Option.empty[B]) -> (t(), empty[B]))
-      case (Empty, Cons(h, t)) => Some(f(Option.empty[A], Some(h())) -> (empty[A] -> t()))
-      case (Cons(h1, t1), Cons(h2, t2)) => Some(f(Some(h1()), Some(h2())) -> (t1() -> t2()))
-    }
-
-  /*
-  `s startsWith s2` when corresponding elements of `s` and `s2` are all equal, until the point that `s2` is exhausted. If `s` is exhausted first, or we find an element that doesn't match, we terminate early. Using non-strictness, we can compose these three separate logical steps--the zipping, the termination when the second stream is exhausted, and the termination if a nonmatching element is found or the first stream is exhausted.
-  */
-  def startsWith[A](s: Stream[A]): Boolean =
-    zipAll(s).takeWhile(!_._2.isEmpty) forAll {
-      case (h,h2) => h == h2
-    }
-
-  /*
-  The last element of `tails` is always the empty `Stream`, so we handle this as a special case, by appending it to the output.
-  */
-  def tails: Stream[Stream[A]] =
-    unfold(this) {
-      case Empty => None
-      case s => Some((s, s drop 1))
-    } append Stream(empty)
-
-  def hasSubsequence[A](s: Stream[A]): Boolean =
-    tails exists (_ startsWith s)
-
-  /*
-  The function can't be implemented using `unfold`, since `unfold` generates elements of the `Stream` from left to right. It can be implemented using `foldRight` though.
-
-  The implementation is just a `foldRight` that keeps the accumulated value and the stream of intermediate results, which we `cons` onto during each iteration. When writing folds, it's common to have more state in the fold than is needed to compute the result. Here, we simply extract the accumulated list once finished.
-  */
-  def scanRight[B](z: B)(f: (A, => B) => B): Stream[B] =
-    foldRight((z, Stream(z)))((a, p0) => {
-      // p0 is passed by-name and used in by-name args in f and cons. So use lazy val to ensure only one evaluation...
-      lazy val p1 = p0
-      val b2 = f(a, p1._1)
-      (b2, cons(b2, p1._2))
-    })._2
-
-  @annotation.tailrec
-  final def find(f: A => Boolean): Option[A] = this match {
-    case Empty => None
-    case Cons(h, t) => if (f(h())) Some(h()) else t().find(f)
-  }
-}
-case object Empty extends Stream[Nothing]
-case class Cons[+A](h: () => A, t: () => Stream[A]) extends Stream[A]
-
-object Stream {
-  def cons[A](hd: => A, tl: => Stream[A]): Stream[A] = {
-    lazy val head = hd
-    lazy val tail = tl
-    Cons(() => head, () => tail)
-  }
-
-  def empty[A]: Stream[A] = Empty
-
-  def apply[A](as: A*): Stream[A] =
-    if (as.isEmpty) empty
-    else cons(as.head, apply(as.tail: _*))
-
-  val ones: Stream[Int] = Stream.cons(1, ones)
-
-  // This is more efficient than `cons(a, constant(a))` since it's just
-  // one object referencing itself.
-  def constant[A](a: A): Stream[A] = {
-    lazy val tail: Stream[A] = Cons(() => a, () => tail)
-    tail
-  }
-
-  def from(n: Int): Stream[Int] =
-    cons(n, from(n+1))
-
-  val fibs = {
-    def go(f0: Int, f1: Int): Stream[Int] =
-      cons(f0, go(f1, f0+f1))
-    go(0, 1)
-  }
-
-  def unfold[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] =
-    f(z) match {
-      case Some((h,s)) => cons(h, unfold(s)(f))
-      case None => empty
-    }
-
-  /*
-  The below two implementations use `fold` and `map` functions in the Option class to implement unfold, thereby doing away with the need to manually pattern match as in the above solution.
-   */
-  def unfoldViaFold[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] =
-    f(z).fold(empty[A])((p: (A,S)) => cons(p._1,unfold(p._2)(f)))
-
-  def unfoldViaMap[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] =
-    f(z).map((p: (A,S)) => cons(p._1,unfold(p._2)(f))).getOrElse(empty[A])
-
-  /*
-  Scala provides shorter syntax when the first action of a function literal is to match on an expression.  The function passed to `unfold` in `fibsViaUnfold` is equivalent to `p => p match { case (f0,f1) => ... }`, but we avoid having to choose a name for `p`, only to pattern match on it.
-  */
-  val fibsViaUnfold =
-    unfold((0,1)) { case (f0,f1) => Some((f0,(f1,f0+f1))) }
-
-  def fromViaUnfold(n: Int) =
-    unfold(n)(n => Some((n,n+1)))
-
-  def constantViaUnfold[A](a: A) =
-    unfold(a)(_ => Some((a,a)))
-
-  // could also of course be implemented as constant(1)
-  val onesViaUnfold = unfold(1)(_ => Some((1,1)))
-}
diff --git a/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala b/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala
deleted file mode 100644
index f9e92fe..0000000
--- a/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala
+++ /dev/null
@@ -1,193 +0,0 @@
-package fpinscala.localeffects
-
-import fpinscala.monads._
-
-object Mutable {
-  def quicksort(xs: List[Int]): List[Int] = if (xs.isEmpty) xs else {
-    val arr = xs.toArray
-    def swap(x: Int, y: Int) = {
-      val tmp = arr(x)
-      arr(x) = arr(y)
-      arr(y) = tmp
-    }
-    def partition(l: Int, r: Int, pivot: Int) = {
-      val pivotVal = arr(pivot)
-      swap(pivot, r)
-      var j = l
-      for (i <- l until r) if (arr(i) < pivotVal) {
-        swap(i, j)
-        j += 1
-      }
-      swap(j, r)
-      j
-    }
-    def qs(l: Int, r: Int): Unit = if (l < r) {
-      val pi = partition(l, r, l + (r - l) / 2)
-      qs(l, pi - 1)
-      qs(pi + 1, r)
-    }
-    qs(0, arr.length - 1)
-    arr.toList
-  }
-}
-
-sealed trait ST[S,A] { self =>
-  protected def run(s: S): (A,S)
-  def map[B](f: A => B): ST[S,B] = new ST[S,B] {
-    def run(s: S) = {
-      val (a, s1) = self.run(s)
-      (f(a), s1)
-    }
-  }
-  def flatMap[B](f: A => ST[S,B]): ST[S,B] = new ST[S,B] {
-    def run(s: S) = {
-      val (a, s1) = self.run(s)
-      f(a).run(s1)
-    }
-  }
-}
-
-object ST {
-  def apply[S,A](a: => A) = {
-    lazy val memo = a
-    new ST[S,A] {
-      def run(s: S) = (memo, s)
-    }
-  }
-  def runST[A](st: RunnableST[A]): A =
-    st[Unit].run(())._1
-}
-
-sealed trait STRef[S,A] {
-  protected var cell: A
-  def read: ST[S,A] = ST(cell)
-  def write(a: => A): ST[S,Unit] = new ST[S,Unit] {
-    def run(s: S) = {
-      cell = a
-      ((), s)
-    }
-  }
-}
-
-object STRef {
-  def apply[S,A](a: A): ST[S, STRef[S,A]] = ST(new STRef[S,A] {
-    var cell = a
-  })
-}
-
-trait RunnableST[A] {
-  def apply[S]: ST[S,A]
-}
-
-// Scala requires an implicit Manifest for constructing arrays.
-sealed abstract class STArray[S,A](implicit manifest: Manifest[A]) {
-  protected def value: Array[A]
-  def size: ST[S,Int] = ST(value.size)
-
-  // Write a value at the give index of the array
-  def write(i: Int, a: A): ST[S,Unit] = new ST[S,Unit] {
-    def run(s: S) = {
-      value(i) = a
-      ((), s)
-    }
-  }
-
-  // Read the value at the given index of the array
-  def read(i: Int): ST[S,A] = ST(value(i))
-
-  // Turn the array into an immutable list
-  def freeze: ST[S,List[A]] = ST(value.toList)
-
-  def fill(xs: Map[Int,A]): ST[S,Unit] =
-    xs.foldRight(ST[S,Unit](())) {
-      case ((k, v), st) => st flatMap (_ => write(k, v))
-    }
-
-  def swap(i: Int, j: Int): ST[S,Unit] = for {
-    x <- read(i)
-    y <- read(j)
-    _ <- write(i, y)
-    _ <- write(j, x)
-  } yield ()
-}
-
-object STArray {
-  // Construct an array of the given size filled with the value v
-  def apply[S,A:Manifest](sz: Int, v: A): ST[S, STArray[S,A]] =
-    ST(new STArray[S,A] {
-      lazy val value = Array.fill(sz)(v)
-    })
-
-  def fromList[S,A:Manifest](xs: List[A]): ST[S, STArray[S,A]] =
-    ST(new STArray[S,A] {
-      lazy val value = xs.toArray
-    })
-}
-
-object Immutable {
-  def noop[S] = ST[S,Unit](())
-
-  def partition[S](a: STArray[S,Int], l: Int, r: Int, pivot: Int): ST[S,Int] = for {
-    vp <- a.read(pivot)
-    _ <- a.swap(pivot, r)
-    j <- STRef(l)
-    _ <- (l until r).foldLeft(noop[S])((s, i) => for {
-      _ <- s
-      vi <- a.read(i)
-      _  <- if (vi < vp) (for {
-        vj <- j.read
-        _  <- a.swap(i, vj)
-        _  <- j.write(vj + 1)
-      } yield ()) else noop[S]
-    } yield ())
-    x <- j.read
-    _ <- a.swap(x, r)
-  } yield x
-
-  def qs[S](a: STArray[S,Int], l: Int, r: Int): ST[S, Unit] = if (l < r) for {
-    pi <- partition(a, l, r, l + (r - l) / 2)
-    _ <- qs(a, l, pi - 1)
-    _ <- qs(a, pi + 1, r)
-  } yield () else noop[S]
-
-  def quicksort(xs: List[Int]): List[Int] =
-    if (xs.isEmpty) xs else ST.runST(new RunnableST[List[Int]] {
-      def apply[S] = for {
-        arr    <- STArray.fromList(xs)
-        size   <- arr.size
-        _      <- qs(arr, 0, size - 1)
-        sorted <- arr.freeze
-      } yield sorted
-  })
-}
-
-import scala.collection.mutable.HashMap
-
-sealed trait STMap[S,K,V] {
-  protected def table: HashMap[K,V]
-
-  def size: ST[S,Int] = ST(table.size)
-
-  // Get the value under a key
-  def apply(k: K): ST[S,V] = ST(table(k))
-
-  // Get the value under a key, or None if the key does not exist
-  def get(k: K): ST[S, Option[V]] = ST(table.get(k))
-
-  // Add a value under a key
-  def +=(kv: (K, V)): ST[S,Unit] = ST(table += kv)
-
-  // Remove a key
-  def -=(k: K): ST[S,Unit] = ST(table -= k)
-}
-
-object STMap {
-  def empty[S,K,V]: ST[S, STMap[S,K,V]] = ST(new STMap[S,K,V] {
-    val table = HashMap.empty[K,V]
-  })
-
-  def fromMap[S,K,V](m: Map[K,V]): ST[S, STMap[S,K,V]] = ST(new STMap[S,K,V] {
-    val table = (HashMap.newBuilder[K,V] ++= m).result
-  })
-}
-
diff --git a/answers/src/main/scala/fpinscala/monads/Monad.scala b/answers/src/main/scala/fpinscala/monads/Monad.scala
deleted file mode 100644
index f6e34cb..0000000
--- a/answers/src/main/scala/fpinscala/monads/Monad.scala
+++ /dev/null
@@ -1,189 +0,0 @@
-package fpinscala
-package monads
-
-import parsing._
-import testing._
-import parallelism._
-import state._
-import parallelism.Par._
-import language.higherKinds
-
-
-trait Functor[F[_]] {
-  def map[A,B](fa: F[A])(f: A => B): F[B]
-
-  def distribute[A,B](fab: F[(A, B)]): (F[A], F[B]) =
-    (map(fab)(_._1), map(fab)(_._2))
-
-  def codistribute[A,B](e: Either[F[A], F[B]]): F[Either[A, B]] = e match {
-    case Left(fa) => map(fa)(Left(_))
-    case Right(fb) => map(fb)(Right(_))
-  }
-}
-
-object Functor {
-  val listFunctor = new Functor[List] {
-    def map[A,B](as: List[A])(f: A => B): List[B] = as map f
-  }
-}
-
-trait Monad[F[_]] extends Functor[F] {
-  def unit[A](a: => A): F[A]
-
-  def flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] =
-    join(map(ma)(f))
-
-  def map[A,B](ma: F[A])(f: A => B): F[B] =
-    flatMap(ma)(a => unit(f(a)))
-  def map2[A,B,C](ma: F[A], mb: F[B])(f: (A, B) => C): F[C] =
-    flatMap(ma)(a => map(mb)(b => f(a, b)))
-
-  def sequence[A](lma: List[F[A]]): F[List[A]] =
-    lma.foldRight(unit(List[A]()))((ma, mla) => map2(ma, mla)(_ :: _))
-
-  def traverse[A,B](la: List[A])(f: A => F[B]): F[List[B]] =
-    la.foldRight(unit(List[B]()))((a, mlb) => map2(f(a), mlb)(_ :: _))
-
-  // For `List`, the `replicateM` function will generate a list of lists.
-  // It will contain all the lists of length `n` with elements selected from the
-  // input list.
-  // For `Option`, it will generate either `Some` or `None` based on whether the
-  // input is `Some` or `None`. The `Some` case will contain a list of length `n`
-  // that repeats the element in the input `Option`.
-  // The general meaning of `replicateM` is described very well by the
-  // implementation `sequence(List.fill(n)(ma))`. It repeats the `ma` monadic value
-  // `n` times and gathers the results in a single value, where the monad `M`
-  // determines how values are actually combined.
-
-  // Recursive version:
-  def _replicateM[A](n: Int, ma: F[A]): F[List[A]] =
-    if (n <= 0) unit(List[A]()) else map2(ma, _replicateM(n - 1, ma))(_ :: _)
-
-  // Using `sequence` and the `List.fill` function of the standard library:
-  def replicateM[A](n: Int, ma: F[A]): F[List[A]] =
-    sequence(List.fill(n)(ma))
-
-
-  def compose[A,B,C](f: A => F[B], g: B => F[C]): A => F[C] =
-    a => flatMap(f(a))(g)
-
-  def _flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] =
-    compose((_:Unit) => ma, f)(())
-
-  def join[A](mma: F[F[A]]): F[A] = flatMap(mma)(ma => ma)
-
-  def filterM[A](ms: List[A])(f: A => F[Boolean]): F[List[A]] =
-    ms.foldRight(unit(List[A]()))((x,y) =>
-      compose(f, (b: Boolean) => if (b) map2(unit(x),y)(_ :: _) else y)(x))
-}
-
-case class Reader[R, A](run: R => A)
-
-object Monad {
-  val genMonad = new Monad[Gen] {
-    def unit[A](a: => A): Gen[A] = Gen.unit(a)
-    override def flatMap[A,B](ma: Gen[A])(f: A => Gen[B]): Gen[B] =
-      ma flatMap f
-  }
-
-  val parMonad = new Monad[Par] {
-    def unit[A](a: => A) = Par.unit(a)
-    override def flatMap[A,B](ma: Par[A])(f: A => Par[B]) = Par.flatMap(ma)(f)
-  }
-
-  def parserMonad[P[+_]](p: Parsers[P]) = new Monad[P] {
-    def unit[A](a: => A) = p.succeed(a)
-    override def flatMap[A,B](ma: P[A])(f: A => P[B]) = p.flatMap(ma)(f)
-  }
-
-  val optionMonad = new Monad[Option] {
-    def unit[A](a: => A) = Some(a)
-    override def flatMap[A,B](ma: Option[A])(f: A => Option[B]) = ma flatMap f
-  }
-
-  val streamMonad = new Monad[Stream] {
-    def unit[A](a: => A) = Stream(a)
-    override def flatMap[A,B](ma: Stream[A])(f: A => Stream[B]) = ma flatMap f
-  }
-
-  val listMonad = new Monad[List] {
-    def unit[A](a: => A) = List(a)
-    override def flatMap[A,B](ma: List[A])(f: A => List[B]) = ma flatMap f
-  }
-
-  // Since `State` is a binary type constructor, we need to partially apply it
-  // with the `S` type argument. Thus, it is not just one monad, but an entire
-  // family of monads, one for each type `S`. One solution is to create a class
-  // `StateMonads` that accepts the `S` type argument and then has a _type member_
-  // for the fully applied `State[S, A]` type inside:
-  class StateMonads[S] {
-    type StateS[A] = State[S, A]
-
-    // We can then declare the monad for the `StateS` type constructor:
-    val monad = new Monad[StateS] {
-      def unit[A](a: => A): State[S, A] = State(s => (a, s))
-      override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
-        st flatMap f
-    }
-  }
-
-  // But we don't have to create a full class like `StateMonads`. We can create
-  // an anonymous class inline, inside parentheses, and project out its type member,
-  // `lambda`:
-  def stateMonad[S] = new Monad[({type lambda[x] = State[S, x]})#lambda] {
-    def unit[A](a: => A): State[S, A] = State(s => (a, s))
-    override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
-      st flatMap f
-  }
-
-  val idMonad = new Monad[Id] {
-    def unit[A](a: => A) = Id(a)
-    override def flatMap[A,B](ida: Id[A])(f: A => Id[B]): Id[B] = ida flatMap f
-  }
-
-  def getState[S]: State[S,S] = State(s => (s,s))
-  def setState[S](s: S): State[S,Unit] = State(_ => ((),s))
-
-  val F = stateMonad[Int]
-
-  def zipWithIndex[A](as: List[A]): List[(Int,A)] =
-    as.foldLeft(F.unit(List[(Int, A)]()))((acc,a) => for {
-      xs <- acc
-      n  <- getState
-      _  <- setState(n + 1)
-    } yield (n, a) :: xs).run(0)._1.reverse
-
-  // The action of Reader's `flatMap` is to pass the `r` argument along to both the
-  // outer Reader and also to the result of `f`, the inner Reader. Similar to how
-  // `State` passes along a state, except that in `Reader` the "state" is read-only.
-
-  // The meaning of `sequence` here is that if you have a list of functions, you can
-  // turn it into a function that takes one argument and passes it to all the functions
-  // in the list, returning a list of the results.
-
-  // The meaning of `join` is simply to pass the same value as both arguments to a
-  // binary function.
-
-  // The meaning of `replicateM` is to apply the same function a number of times to
-  // the same argument, returning a list of the results. Note that if this function
-  // is _pure_, (which it should be), this can be exploited by only applying the
-  // function once and replicating the result instead of calling the function many times.
-  // This means the Reader monad can override replicateM to provide a very efficient
-  // implementation.
-
-  def readerMonad[R] = new Monad[({type f[x] = Reader[R,x]})#f] {
-    def unit[A](a: => A): Reader[R, A] = Reader(_ => a)
-    override def flatMap[A,B](st: Reader[R, A])(f: A => Reader[R, B]): Reader[R, B] =
-      Reader(r => f(st.run(r)).run(r))
-  }
-}
-
-case class Id[A](value: A) {
-  def map[B](f: A => B): Id[B] = Id(f(value))
-  def flatMap[B](f: A => Id[B]): Id[B] = f(value)
-}
-
-object Reader {
-  def ask[R]: Reader[R, R] = Reader(r => r)
-}
-
diff --git a/answers/src/main/scala/fpinscala/monoids/Monoid.scala b/answers/src/main/scala/fpinscala/monoids/Monoid.scala
deleted file mode 100644
index 66721e2..0000000
--- a/answers/src/main/scala/fpinscala/monoids/Monoid.scala
+++ /dev/null
@@ -1,301 +0,0 @@
-package fpinscala.monoids
-
-import fpinscala.parallelism.Nonblocking._
-import fpinscala.parallelism.Nonblocking.Par.toParOps // infix syntax for `Par.map`, `Par.flatMap`, etc
-import language.higherKinds
-
-trait Monoid[A] {
-  def op(a1: A, a2: A): A
-  def zero: A
-}
-
-object Monoid {
-
-  val stringMonoid = new Monoid[String] {
-    def op(a1: String, a2: String) = a1 + a2
-    val zero = ""
-  }
-
-  def listMonoid[A] = new Monoid[List[A]] {
-    def op(a1: List[A], a2: List[A]) = a1 ++ a2
-    val zero = Nil
-  }
-
-  val intAddition: Monoid[Int] = new Monoid[Int] {
-    def op(x: Int, y: Int) = x + y
-    val zero = 0
-  }
-
-  val intMultiplication: Monoid[Int] = new Monoid[Int] {
-    def op(x: Int, y: Int) = x * y
-    val zero = 1
-  }
-
-  val booleanOr: Monoid[Boolean] = new Monoid[Boolean] {
-    def op(x: Boolean, y: Boolean) = x || y
-    val zero = false
-  }
-
-  val booleanAnd: Monoid[Boolean] = new Monoid[Boolean] {
-    def op(x: Boolean, y: Boolean) = x && y
-    val zero = true
-  }
-
-  // Notice that we have a choice in how we implement `op`.
-  // We can compose the options in either order. Both of those implementations
-  // satisfy the monoid laws, but they are not equivalent.
-  // This is true in general--that is, every monoid has a _dual_ where the
-  // `op` combines things in the opposite order. Monoids like `booleanOr` and
-  // `intAddition` are equivalent to their duals because their `op` is commutative
-  // as well as associative.
-  def optionMonoid[A]: Monoid[Option[A]] = new Monoid[Option[A]] {
-    def op(x: Option[A], y: Option[A]) = x orElse y
-    val zero = None
-  }
-
-  // We can get the dual of any monoid just by flipping the `op`.
-  def dual[A](m: Monoid[A]): Monoid[A] = new Monoid[A] {
-    def op(x: A, y: A): A = m.op(y, x)
-    val zero = m.zero
-  }
-
-  // Now we can have both monoids on hand
-  def firstOptionMonoid[A]: Monoid[Option[A]] = optionMonoid[A]
-  def lastOptionMonoid[A]: Monoid[Option[A]] = dual(firstOptionMonoid)
-
-  // There is a choice of implementation here as well.
-  // Do we implement it as `f compose g` or `f andThen g`? We have to pick one.
-  def endoMonoid[A]: Monoid[A => A] = new Monoid[A => A] {
-    def op(f: A => A, g: A => A) = f compose g
-    val zero = (a: A) => a
-  }
-
-  import fpinscala.testing._
-  import Prop._
-
-  def monoidLaws[A](m: Monoid[A], gen: Gen[A]): Prop =
-    // Associativity
-    forAll(for {
-      x <- gen
-      y <- gen
-      z <- gen
-    } yield (x, y, z))(p =>
-      m.op(p._1, m.op(p._2, p._3)) == m.op(m.op(p._1, p._2), p._3)) &&
-    // Identity
-    forAll(gen)((a: A) =>
-      m.op(a, m.zero) == a && m.op(m.zero, a) == a)
-
-  def concatenate[A](as: List[A], m: Monoid[A]): A =
-    as.foldLeft(m.zero)(m.op)
-
-  // Notice that this function does not require the use of `map` at all.
-  // All we need is `foldLeft`.
-  def foldMap[A, B](as: List[A], m: Monoid[B])(f: A => B): B =
-    as.foldLeft(m.zero)((b, a) => m.op(b, f(a)))
-
-  // The function type `(A, B) => B`, when curried, is `A => (B => B)`.
-  // And of course, `B => B` is a monoid for any `B` (via function composition).
-  def foldRight[A, B](as: List[A])(z: B)(f: (A, B) => B): B =
-    foldMap(as, endoMonoid[B])(f.curried)(z)
-
-  // Folding to the left is the same except we flip the arguments to
-  // the function `f` to put the `B` on the correct side.
-  // Then we have to also "flip" the monoid so that it operates from left to right.
-  def foldLeft[A, B](as: List[A])(z: B)(f: (B, A) => B): B =
-    foldMap(as, dual(endoMonoid[B]))(a => b => f(b, a))(z)
-
-  def foldMapV[A, B](as: IndexedSeq[A], m: Monoid[B])(f: A => B): B =
-    if (as.length == 0)
-      m.zero
-    else if (as.length == 1)
-      f(as(0))
-    else {
-      val (l, r) = as.splitAt(as.length / 2)
-      m.op(foldMapV(l, m)(f), foldMapV(r, m)(f))
-    }
-
-  // This implementation detects only ascending order,
-  // but you can write a monoid that detects both ascending and descending
-  // order if you like.
-  def ordered(ints: IndexedSeq[Int]): Boolean = {
-    // Our monoid tracks the minimum and maximum element seen so far
-    // as well as whether the elements are so far ordered.
-    val mon = new Monoid[Option[(Int, Int, Boolean)]] {
-      def op(o1: Option[(Int, Int, Boolean)], o2: Option[(Int, Int, Boolean)]) =
-        (o1, o2) match {
-          // The ranges should not overlap if the sequence is ordered.
-          case (Some((x1, y1, p)), Some((x2, y2, q))) =>
-            Some((x1 min x2, y1 max y2, p && q && y1 <= x2))
-          case (x, None) => x
-          case (None, x) => x
-        }
-      val zero = None
-    }
-    // The empty sequence is ordered, and each element by itself is ordered.
-    foldMapV(ints, mon)(i => Some((i, i, true))).map(_._3).getOrElse(true)
-  }
-
-  // This ability to 'lift' a monoid any monoid to operate within
-  // some context (here `Par`) is something we'll discuss more in
-  // chapters 11 & 12
-  def par[A](m: Monoid[A]): Monoid[Par[A]] = new Monoid[Par[A]] {
-    def zero = Par.unit(m.zero)
-    def op(a: Par[A], b: Par[A]) = a.map2(b)(m.op)
-  }
-
-  // we perform the mapping and the reducing both in parallel
-  def parFoldMap[A,B](v: IndexedSeq[A], m: Monoid[B])(f: A => B): Par[B] =
-    Par.parMap(v)(f).flatMap { bs =>
-      foldMapV(bs, par(m))(b => Par.lazyUnit(b))
-    }
-
-  sealed trait WC
-  case class Stub(chars: String) extends WC
-  case class Part(lStub: String, words: Int, rStub: String) extends WC
-
-  val wcMonoid: Monoid[WC] = new Monoid[WC] {
-    // The empty result, where we haven't seen any characters yet.
-    val zero = Stub("")
-
-    def op(a: WC, b: WC) = (a, b) match {
-      case (Stub(c), Stub(d)) => Stub(c + d)
-      case (Stub(c), Part(l, w, r)) => Part(c + l, w, r)
-      case (Part(l, w, r), Stub(c)) => Part(l, w, r + c)
-      case (Part(l1, w1, r1), Part(l2, w2, r2)) =>
-        Part(l1, w1 + (if ((r1 + l2).isEmpty) 0 else 1) + w2, r2)
-    }
-  }
-
-  def count(s: String): Int = {
-    // A single character's count. Whitespace does not count,
-    // and non-whitespace starts a new Stub.
-    def wc(c: Char): WC =
-      if (c.isWhitespace)
-        Part("", 0, "")
-      else
-        Stub(c.toString)
-    // `unstub(s)` is 0 if `s` is empty, otherwise 1.
-    def unstub(s: String) = s.length min 1
-    foldMapV(s.toIndexedSeq, wcMonoid)(wc) match {
-      case Stub(s) => unstub(s)
-      case Part(l, w, r) => unstub(l) + w + unstub(r)
-    }
-  }
-
-  def productMonoid[A,B](A: Monoid[A], B: Monoid[B]): Monoid[(A, B)] =
-    new Monoid[(A, B)] {
-      def op(x: (A, B), y: (A, B)) =
-        (A.op(x._1, y._1), B.op(x._2, y._2))
-      val zero = (A.zero, B.zero)
-    }
-
-  def functionMonoid[A,B](B: Monoid[B]): Monoid[A => B] =
-    new Monoid[A => B] {
-      def op(f: A => B, g: A => B) = a => B.op(f(a), g(a))
-      val zero: A => B = a => B.zero
-    }
-
-  def mapMergeMonoid[K,V](V: Monoid[V]): Monoid[Map[K, V]] =
-    new Monoid[Map[K, V]] {
-      def zero = Map[K,V]()
-      def op(a: Map[K, V], b: Map[K, V]) =
-        (a.keySet ++ b.keySet).foldLeft(zero) { (acc,k) =>
-          acc.updated(k, V.op(a.getOrElse(k, V.zero),
-                              b.getOrElse(k, V.zero)))
-        }
-    }
-
-
-  def bag[A](as: IndexedSeq[A]): Map[A, Int] =
-    foldMapV(as, mapMergeMonoid[A, Int](intAddition))((a: A) => Map(a -> 1))
-
-}
-
-trait Foldable[F[_]] {
-  import Monoid._
-
-  def foldRight[A,B](as: F[A])(z: B)(f: (A, B) => B): B =
-    foldMap(as)(f.curried)(endoMonoid[B])(z)
-
-  def foldLeft[A,B](as: F[A])(z: B)(f: (B, A) => B): B =
-    foldMap(as)(a => (b: B) => f(b, a))(dual(endoMonoid[B]))(z)
-
-  def foldMap[A, B](as: F[A])(f: A => B)(mb: Monoid[B]): B =
-    foldRight(as)(mb.zero)((a, b) => mb.op(f(a), b))
-
-  def concatenate[A](as: F[A])(m: Monoid[A]): A =
-    foldLeft(as)(m.zero)(m.op)
-
-  def toList[A](as: F[A]): List[A] =
-    foldRight(as)(List[A]())(_ :: _)
-}
-
-object ListFoldable extends Foldable[List] {
-  override def foldRight[A, B](as: List[A])(z: B)(f: (A, B) => B) =
-    as.foldRight(z)(f)
-  override def foldLeft[A, B](as: List[A])(z: B)(f: (B, A) => B) =
-    as.foldLeft(z)(f)
-  override def foldMap[A, B](as: List[A])(f: A => B)(mb: Monoid[B]): B =
-    foldLeft(as)(mb.zero)((b, a) => mb.op(b, f(a)))
-  override def toList[A](as: List[A]): List[A] = as
-}
-
-object IndexedSeqFoldable extends Foldable[IndexedSeq] {
-  import Monoid._
-  override def foldRight[A, B](as: IndexedSeq[A])(z: B)(f: (A, B) => B) =
-    as.foldRight(z)(f)
-  override def foldLeft[A, B](as: IndexedSeq[A])(z: B)(f: (B, A) => B) =
-    as.foldLeft(z)(f)
-  override def foldMap[A, B](as: IndexedSeq[A])(f: A => B)(mb: Monoid[B]): B =
-    foldMapV(as, mb)(f)
-}
-
-object StreamFoldable extends Foldable[Stream] {
-  override def foldRight[A, B](as: Stream[A])(z: B)(f: (A, B) => B) =
-    as.foldRight(z)(f)
-  override def foldLeft[A, B](as: Stream[A])(z: B)(f: (B, A) => B) =
-    as.foldLeft(z)(f)
-}
-
-sealed trait Tree[+A]
-case class Leaf[A](value: A) extends Tree[A]
-case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]
-
-object TreeFoldable extends Foldable[Tree] {
-  override def foldMap[A, B](as: Tree[A])(f: A => B)(mb: Monoid[B]): B = as match {
-    case Leaf(a) => f(a)
-    case Branch(l, r) => mb.op(foldMap(l)(f)(mb), foldMap(r)(f)(mb))
-  }
-  override def foldLeft[A, B](as: Tree[A])(z: B)(f: (B, A) => B) = as match {
-    case Leaf(a) => f(z, a)
-    case Branch(l, r) => foldLeft(r)(foldLeft(l)(z)(f))(f)
-  }
-  override def foldRight[A, B](as: Tree[A])(z: B)(f: (A, B) => B) = as match {
-    case Leaf(a) => f(a, z)
-    case Branch(l, r) => foldRight(l)(foldRight(r)(z)(f))(f)
-  }
-}
-
-// Notice that in `TreeFoldable.foldMap`, we don't actually use the `zero`
-// from the `Monoid`. This is because there is no empty tree.
-// This suggests that there might be a class of types that are foldable
-// with something "smaller" than a monoid, consisting only of an
-// associative `op`. That kind of object (a monoid without a `zero`) is
-// called a semigroup. `Tree` itself is not a monoid, but it is a semigroup.
-
-object OptionFoldable extends Foldable[Option] {
-  override def foldMap[A, B](as: Option[A])(f: A => B)(mb: Monoid[B]): B =
-    as match {
-      case None => mb.zero
-      case Some(a) => f(a)
-    }
-  override def foldLeft[A, B](as: Option[A])(z: B)(f: (B, A) => B) = as match {
-    case None => z
-    case Some(a) => f(z, a)
-  }
-  override def foldRight[A, B](as: Option[A])(z: B)(f: (A, B) => B) = as match {
-    case None => z
-    case Some(a) => f(a, z)
-  }
-}
-
diff --git a/answers/src/main/scala/fpinscala/parallelism/Actor.scala b/answers/src/main/scala/fpinscala/parallelism/Actor.scala
deleted file mode 100644
index 3271b23..0000000
--- a/answers/src/main/scala/fpinscala/parallelism/Actor.scala
+++ /dev/null
@@ -1,137 +0,0 @@
-package fpinscala.parallelism
-
-import java.util.concurrent.atomic.{AtomicInteger, AtomicReference}
-import java.util.concurrent.{Callable,ExecutorService}
-import annotation.tailrec
-
-/*
- * Implementation is taken from `scalaz` library, with only minor changes. See:
- *
- * https://github.com/scalaz/scalaz/blob/scalaz-seven/concurrent/src/main/scala/scalaz/concurrent/Actor.scala
- *
- * This code is copyright Andriy Plokhotnyuk, Runar Bjarnason, and other contributors,
- * and is licensed using 3-clause BSD, see LICENSE file at:
- *
- * https://github.com/scalaz/scalaz/blob/scalaz-seven/etc/LICENCE
- */
-
-/**
- * Processes messages of type `A`, one at a time. Messages are submitted to
- * the actor with the method `!`. Processing is typically performed asynchronously,
- * this is controlled by the provided `strategy`.
- *
- * Memory consistency guarantee: when each message is processed by the `handler`, any memory that it
- * mutates is guaranteed to be visible by the `handler` when it processes the next message, even if
- * the `strategy` runs the invocations of `handler` on separate threads. This is achieved because
- * the `Actor` reads a volatile memory location before entering its event loop, and writes to the same
- * location before suspending.
- *
- * Implementation based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:
- * [[http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue]]
- *
- * @see scalaz.concurrent.Promise for a use case.
- *
- * @param handler  The message handler
- * @param onError  Exception handler, called if the message handler throws any `Throwable`.
- * @param strategy Execution strategy, for example, a strategy that is backed by an `ExecutorService`
- * @tparam A       The type of messages accepted by this actor.
- */
-final class Actor[A](strategy: Strategy)(handler: A => Unit, onError: Throwable => Unit = throw(_)) {
-  self =>
-
-  private val tail = new AtomicReference(new Node[A]())
-  private val suspended = new AtomicInteger(1)
-  private val head = new AtomicReference(tail.get)
-
-  /** Alias for `apply` */
-  def !(a: A) {
-    val n = new Node(a)
-    head.getAndSet(n).lazySet(n)
-    trySchedule()
-  }
-
-  /** Pass the message `a` to the mailbox of this actor */
-  def apply(a: A) {
-    this ! a
-  }
-
-  def contramap[B](f: B => A): Actor[B] =
-    new Actor[B](strategy)((b: B) => (this ! f(b)), onError)
-
-  private def trySchedule() {
-    if (suspended.compareAndSet(1, 0)) schedule()
-  }
-
-  private def schedule() {
-    strategy(act())
-  }
-
-  private def act() {
-    val t = tail.get
-    val n = batchHandle(t, 1024)
-    if (n ne t) {
-      n.a = null.asInstanceOf[A]
-      tail.lazySet(n)
-      schedule()
-    } else {
-      suspended.set(1)
-      if (n.get ne null) trySchedule()
-    }
-  }
-
-  @tailrec
-  private def batchHandle(t: Node[A], i: Int): Node[A] = {
-    val n = t.get
-    if (n ne null) {
-      try {
-        handler(n.a)
-      } catch {
-        case ex: Throwable => onError(ex)
-      }
-      if (i > 0) batchHandle(n, i - 1) else n
-    } else t
-  }
-}
-
-private class Node[A](var a: A = null.asInstanceOf[A]) extends AtomicReference[Node[A]]
-
-object Actor {
-
-  /** Create an `Actor` backed by the given `ExecutorService`. */
-  def apply[A](es: ExecutorService)(handler: A => Unit, onError: Throwable => Unit = throw(_)): Actor[A] =
-    new Actor(Strategy.fromExecutorService(es))(handler, onError)
-}
-
-/**
- * Provides a function for evaluating expressions, possibly asynchronously.
- * The `apply` function should typically begin evaluating its argument
- * immediately. The returned thunk can be used to block until the resulting `A`
- * is available.
- */
-trait Strategy {
-  def apply[A](a: => A): () => A
-}
-
-object Strategy {
-
-  /**
-   * We can create a `Strategy` from any `ExecutorService`. It's a little more
-   * convenient than submitting `Callable` objects directly.
-   */
-  def fromExecutorService(es: ExecutorService): Strategy = new Strategy {
-    def apply[A](a: => A): () => A = {
-      val f = es.submit { new Callable[A] { def call = a} }
-      () => f.get
-    }
-  }
-
-  /**
-   * A `Strategy` which begins executing its argument immediately in the calling thread.
-   */
-  def sequential: Strategy = new Strategy {
-    def apply[A](a: => A): () => A = {
-      val r = a
-      () => r
-    }
-  }
-}
diff --git a/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala b/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala
deleted file mode 100644
index dca2377..0000000
--- a/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala
+++ /dev/null
@@ -1,197 +0,0 @@
-package fpinscala.parallelism
-
-import java.util.concurrent.{Callable, CountDownLatch, ExecutorService}
-import java.util.concurrent.atomic.AtomicReference
-import language.implicitConversions
-
-object Nonblocking {
-
-  trait Future[+A] {
-    private[parallelism] def apply(k: A => Unit): Unit
-  }
-
-  type Par[+A] = ExecutorService => Future[A]
-
-  object Par {
-
-    def run[A](es: ExecutorService)(p: Par[A]): A = {
-      val ref = new java.util.concurrent.atomic.AtomicReference[A] // A mutable, threadsafe reference, to use for storing the result
-      val latch = new CountDownLatch(1) // A latch which, when decremented, implies that `ref` has the result
-      p(es) { a => ref.set(a); latch.countDown } // Asynchronously set the result, and decrement the latch
-      latch.await // Block until the `latch.countDown` is invoked asynchronously
-      ref.get // Once we've passed the latch, we know `ref` has been set, and return its value
-    }
-
-    def unit[A](a: A): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          cb(a)
-      }
-
-    /** A non-strict version of `unit` */
-    def delay[A](a: => A): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          cb(a)
-      }
-
-    def fork[A](a: => Par[A]): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          eval(es)(a(es)(cb))
-      }
-
-    /**
-     * Helper function for constructing `Par` values out of calls to non-blocking continuation-passing-style APIs.
-     * This will come in handy in Chapter 13.
-     */
-    def async[A](f: (A => Unit) => Unit): Par[A] = es => new Future[A] {
-      def apply(k: A => Unit) = f(k)
-    }
-
-    /**
-     * Helper function, for evaluating an action
-     * asynchronously, using the given `ExecutorService`.
-     */
-    def eval(es: ExecutorService)(r: => Unit): Unit =
-      es.submit(new Callable[Unit] { def call = r })
-
-    def map2[A,B,C](p: Par[A], p2: Par[B])(f: (A,B) => C): Par[C] =
-      es => new Future[C] {
-        def apply(cb: C => Unit): Unit = {
-          var ar: Option[A] = None
-          var br: Option[B] = None
-          // this implementation is a little too liberal in forking of threads -
-          // it forks a new logical thread for the actor and for stack-safety,
-          // forks evaluation of the callback `cb`
-          val combiner = Actor[Either[A,B]](es) {
-            case Left(a) =>
-              if (br.isDefined) eval(es)(cb(f(a,br.get)))
-              else ar = Some(a)
-            case Right(b) =>
-              if (ar.isDefined) eval(es)(cb(f(ar.get,b)))
-              else br = Some(b)
-          }
-          p(es)(a => combiner ! Left(a))
-          p2(es)(b => combiner ! Right(b))
-        }
-      }
-
-    // specialized version of `map`
-    def map[A,B](p: Par[A])(f: A => B): Par[B] =
-      es => new Future[B] {
-        def apply(cb: B => Unit): Unit =
-          p(es)(a => eval(es) { cb(f(a)) })
-      }
-
-    def lazyUnit[A](a: => A): Par[A] =
-      fork(unit(a))
-
-    def asyncF[A,B](f: A => B): A => Par[B] =
-      a => lazyUnit(f(a))
-
-    def sequenceRight[A](as: List[Par[A]]): Par[List[A]] =
-      as match {
-        case Nil => unit(Nil)
-        case h :: t => map2(h, fork(sequence(t)))(_ :: _)
-      }
-
-    def sequenceBalanced[A](as: IndexedSeq[Par[A]]): Par[IndexedSeq[A]] = fork {
-      if (as.isEmpty) unit(Vector())
-      else if (as.length == 1) map(as.head)(a => Vector(a))
-      else {
-        val (l,r) = as.splitAt(as.length/2)
-        map2(sequenceBalanced(l), sequenceBalanced(r))(_ ++ _)
-      }
-    }
-
-    def sequence[A](as: List[Par[A]]): Par[List[A]] =
-      map(sequenceBalanced(as.toIndexedSeq))(_.toList)
-
-    def parMap[A,B](as: List[A])(f: A => B): Par[List[B]] =
-      sequence(as.map(asyncF(f)))
-
-    def parMap[A,B](as: IndexedSeq[A])(f: A => B): Par[IndexedSeq[B]] =
-      sequenceBalanced(as.map(asyncF(f)))
-
-    // exercise answers
-
-    /*
-     * We can implement `choice` as a new primitive.
-     *
-     * `p(es)(result => ...)` for some `ExecutorService`, `es`, and
-     * some `Par`, `p`, is the idiom for running `p`, and registering
-     * a callback to be invoked when its result is available. The
-     * result will be bound to `result` in the function passed to
-     * `p(es)`.
-     *
-     * If you find this code difficult to follow, you may want to
-     * write down the type of each subexpression and follow the types
-     * through the implementation. What is the type of `p(es)`? What
-     * about `t(es)`? What about `t(es)(cb)`?
-     */
-    def choice[A](p: Par[Boolean])(t: Par[A], f: Par[A]): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          p(es) { b =>
-            if (b) eval(es) { t(es)(cb) }
-            else eval(es) { f(es)(cb) }
-          }
-      }
-
-    /* The code here is very similar. */
-    def choiceN[A](p: Par[Int])(ps: List[Par[A]]): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          p(es) { ind => eval(es) { ps(ind)(es)(cb) }}
-      }
-
-    def choiceViaChoiceN[A](a: Par[Boolean])(ifTrue: Par[A], ifFalse: Par[A]): Par[A] =
-      choiceN(map(a)(b => if (b) 0 else 1))(List(ifTrue, ifFalse))
-
-    def choiceMap[K,V](p: Par[K])(ps: Map[K,Par[V]]): Par[V] =
-      es => new Future[V] {
-        def apply(cb: V => Unit): Unit =
-          p(es)(k => ps(k)(es)(cb))
-      }
-
-    /* `chooser` is usually called `flatMap` or `bind`. */
-    def chooser[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-      flatMap(p)(f)
-
-    def flatMap[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-      es => new Future[B] {
-        def apply(cb: B => Unit): Unit =
-          p(es)(a => f(a)(es)(cb))
-      }
-
-    def choiceViaFlatMap[A](p: Par[Boolean])(f: Par[A], t: Par[A]): Par[A] =
-      flatMap(p)(b => if (b) t else f)
-
-    def choiceNViaFlatMap[A](p: Par[Int])(choices: List[Par[A]]): Par[A] =
-      flatMap(p)(i => choices(i))
-
-    def join[A](p: Par[Par[A]]): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          p(es)(p2 => eval(es) { p2(es)(cb) })
-      }
-
-    def joinViaFlatMap[A](a: Par[Par[A]]): Par[A] =
-      flatMap(a)(x => x)
-
-    def flatMapViaJoin[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-      join(map(p)(f))
-
-    /* Gives us infix syntax for `Par`. */
-    implicit def toParOps[A](p: Par[A]): ParOps[A] = new ParOps(p)
-
-    // infix versions of `map`, `map2` and `flatMap`
-    class ParOps[A](p: Par[A]) {
-      def map[B](f: A => B): Par[B] = Par.map(p)(f)
-      def map2[B,C](b: Par[B])(f: (A,B) => C): Par[C] = Par.map2(p,b)(f)
-      def flatMap[B](f: A => Par[B]): Par[B] = Par.flatMap(p)(f)
-      def zip[B](b: Par[B]): Par[(A,B)] = p.map2(b)((_,_))
-    }
-  }
-}
diff --git a/answers/src/main/scala/fpinscala/parallelism/Par.scala b/answers/src/main/scala/fpinscala/parallelism/Par.scala
deleted file mode 100644
index d8b7ced..0000000
--- a/answers/src/main/scala/fpinscala/parallelism/Par.scala
+++ /dev/null
@@ -1,148 +0,0 @@
-package fpinscala.parallelism
-
-import java.util.concurrent._
-import language.implicitConversions
-
-
-object Par {
-  type Par[A] = ExecutorService => Future[A]
-
-  def run[A](s: ExecutorService)(a: Par[A]): Future[A] = a(s)
-
-  def unit[A](a: A): Par[A] = (es: ExecutorService) => UnitFuture(a) // `unit` is represented as a function that returns a `UnitFuture`, which is a simple implementation of `Future` that just wraps a constant value. It doesn't use the `ExecutorService` at all. It's always done and can't be cancelled. Its `get` method simply returns the value that we gave it.
-
-  private case class UnitFuture[A](get: A) extends Future[A] {
-    def isDone = true
-    def get(timeout: Long, units: TimeUnit) = get
-    def isCancelled = false
-    def cancel(evenIfRunning: Boolean): Boolean = false
-  }
-
-  def map2[A,B,C](a: Par[A], b: Par[B])(f: (A,B) => C): Par[C] = // `map2` doesn't evaluate the call to `f` in a separate logical thread, in accord with our design choice of having `fork` be the sole function in the API for controlling parallelism. We can always do `fork(map2(a,b)(f))` if we want the evaluation of `f` to occur in a separate thread.
-    (es: ExecutorService) => {
-      val af = a(es)
-      val bf = b(es)
-      UnitFuture(f(af.get, bf.get)) // This implementation of `map2` does _not_ respect timeouts. It simply passes the `ExecutorService` on to both `Par` values, waits for the results of the Futures `af` and `bf`, applies `f` to them, and wraps them in a `UnitFuture`. In order to respect timeouts, we'd need a new `Future` implementation that records the amount of time spent evaluating `af`, then subtracts that time from the available time allocated for evaluating `bf`.
-    }
-
-  def fork[A](a: => Par[A]): Par[A] = // This is the simplest and most natural implementation of `fork`, but there are some problems with it--for one, the outer `Callable` will block waiting for the "inner" task to complete. Since this blocking occupies a thread in our thread pool, or whatever resource backs the `ExecutorService`, this implies that we're losing out on some potential parallelism. Essentially, we're using two threads when one should suffice. This is a symptom of a more serious problem with the implementation, and we will discuss this later in the chapter.
-    es => es.submit(new Callable[A] {
-      def call = a(es).get
-    })
-
-  def lazyUnit[A](a: => A): Par[A] = fork(unit(a))
-
-  def asyncF[A,B](f: A => B): A => Par[B] =
-    a => lazyUnit(f(a))
-
-  def map[A,B](pa: Par[A])(f: A => B): Par[B] =
-    map2(pa, unit(()))((a,_) => f(a))
-
-  def sortPar(parList: Par[List[Int]]) = map(parList)(_.sorted)
-
-  def sequence_simple[A](l: List[Par[A]]): Par[List[A]] =
-    l.foldRight[Par[List[A]]](unit(List()))((h,t) => map2(h,t)(_ :: _))
-
-  // This implementation forks the recursive step off to a new logical thread,
-  // making it effectively tail-recursive. However, we are constructing
-  // a right-nested parallel program, and we can get better performance by
-  // dividing the list in half, and running both halves in parallel.
-  // See `sequenceBalanced` below.
-  def sequenceRight[A](as: List[Par[A]]): Par[List[A]] =
-    as match {
-      case Nil => unit(Nil)
-      case h :: t => map2(h, fork(sequenceRight(t)))(_ :: _)
-    }
-
-  // We define `sequenceBalanced` using `IndexedSeq`, which provides an
-  // efficient function for splitting the sequence in half.
-  def sequenceBalanced[A](as: IndexedSeq[Par[A]]): Par[IndexedSeq[A]] = fork {
-    if (as.isEmpty) unit(Vector())
-    else if (as.length == 1) map(as.head)(a => Vector(a))
-    else {
-      val (l,r) = as.splitAt(as.length/2)
-      map2(sequenceBalanced(l), sequenceBalanced(r))(_ ++ _)
-    }
-  }
-
-  def sequence[A](as: List[Par[A]]): Par[List[A]] =
-    map(sequenceBalanced(as.toIndexedSeq))(_.toList)
-
-  def parFilter[A](l: List[A])(f: A => Boolean): Par[List[A]] = {
-    val pars: List[Par[List[A]]] =
-      l map (asyncF((a: A) => if (f(a)) List(a) else List()))
-    map(sequence(pars))(_.flatten) // convenience method on `List` for concatenating a list of lists
-  }
-
-  def equal[A](e: ExecutorService)(p: Par[A], p2: Par[A]): Boolean =
-    p(e).get == p2(e).get
-
-  def delay[A](fa: => Par[A]): Par[A] =
-    es => fa(es)
-
-  def choice[A](cond: Par[Boolean])(t: Par[A], f: Par[A]): Par[A] =
-    es =>
-      if (run(es)(cond).get) t(es) // Notice we are blocking on the result of `cond`.
-      else f(es)
-
-  def choiceN[A](n: Par[Int])(choices: List[Par[A]]): Par[A] =
-    es => {
-      val ind = run(es)(n).get // Full source files
-      run(es)(choices(ind))
-    }
-
-  def choiceViaChoiceN[A](a: Par[Boolean])(ifTrue: Par[A], ifFalse: Par[A]): Par[A] =
-    choiceN(map(a)(b => if (b) 0 else 1))(List(ifTrue, ifFalse))
-
-  def choiceMap[K,V](key: Par[K])(choices: Map[K,Par[V]]): Par[V] =
-    es => {
-      val k = run(es)(key).get
-      run(es)(choices(k))
-    }
-
-  def chooser[A,B](p: Par[A])(choices: A => Par[B]): Par[B] =
-    es => {
-      val k = run(es)(p).get
-      run(es)(choices(k))
-    }
-
-  /* `chooser` is usually called `flatMap` or `bind`. */
-  def flatMap[A,B](p: Par[A])(choices: A => Par[B]): Par[B] =
-    es => {
-      val k = run(es)(p).get
-      run(es)(choices(k))
-    }
-
-  def choiceViaFlatMap[A](p: Par[Boolean])(f: Par[A], t: Par[A]): Par[A] =
-    flatMap(p)(b => if (b) t else f)
-
-  def choiceNViaFlatMap[A](p: Par[Int])(choices: List[Par[A]]): Par[A] =
-    flatMap(p)(i => choices(i))
-
-  // see nonblocking implementation in `Nonblocking.scala`
-  def join[A](a: Par[Par[A]]): Par[A] =
-    es => run(es)(run(es)(a).get())
-
-  def joinViaFlatMap[A](a: Par[Par[A]]): Par[A] =
-    flatMap(a)(x => x)
-
-  def flatMapViaJoin[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-    join(map(p)(f))
-  /* Gives us infix syntax for `Par`. */
-  implicit def toParOps[A](p: Par[A]): ParOps[A] = new ParOps(p)
-
-  class ParOps[A](p: Par[A]) {
-
-  }
-}
-
-object Examples {
-  import Par._
-  def sum(ints: IndexedSeq[Int]): Int = // `IndexedSeq` is a superclass of random-access sequences like `Vector` in the standard library. Unlike lists, these sequences provide an efficient `splitAt` method for dividing them into two parts at a particular index.
-    if (ints.size <= 1)
-      ints.headOption getOrElse 0 // `headOption` is a method defined on all collections in Scala. We saw this function in chapter 3.
-    else {
-      val (l,r) = ints.splitAt(ints.length/2) // Divide the sequence in half using the `splitAt` function.
-      sum(l) + sum(r) // Recursively sum both halves and add the results together.
-    }
-}
diff --git a/answers/src/main/scala/fpinscala/parsing/JSON.scala b/answers/src/main/scala/fpinscala/parsing/JSON.scala
deleted file mode 100644
index a6630af..0000000
--- a/answers/src/main/scala/fpinscala/parsing/JSON.scala
+++ /dev/null
@@ -1,81 +0,0 @@
-package fpinscala.parsing
-
-import language.higherKinds
-import language.implicitConversions
-
-trait JSON
-
-object JSON {
-  case object JNull extends JSON
-  case class JNumber(get: Double) extends JSON
-  case class JString(get: String) extends JSON
-  case class JBool(get: Boolean) extends JSON
-  case class JArray(get: IndexedSeq[JSON]) extends JSON
-  case class JObject(get: Map[String, JSON]) extends JSON
-
-  def jsonParser[Parser[+_]](P: Parsers[Parser]): Parser[JSON] = {
-    // we'll hide the string implicit conversion and promote strings to tokens instead
-    // this is a bit nicer than having to write token everywhere
-    import P.{string => _, _}
-    implicit def tok(s: String) = token(P.string(s))
-
-    def array = surround("[","]")(
-      value sep "," map (vs => JArray(vs.toIndexedSeq))) scope "array"
-    def obj = surround("{","}")(
-      keyval sep "," map (kvs => JObject(kvs.toMap))) scope "object"
-    def keyval = escapedQuoted ** (":" *> value)
-    def lit = scope("literal") {
-      "null".as(JNull) |
-      double.map(JNumber(_)) |
-      escapedQuoted.map(JString(_)) |
-      "true".as(JBool(true)) |
-      "false".as(JBool(false))
-    }
-    def value: Parser[JSON] = lit | obj | array
-    root(whitespace *> (obj | array))
-  }
-}
-
-/**
- * JSON parsing example.
- */
-object JSONExample extends App {
-  val jsonTxt = """
-{
-  "Company name" : "Microsoft Corporation",
-  "Ticker"  : "MSFT",
-  "Active"  : true,
-  "Price"   : 30.66,
-  "Shares outstanding" : 8.38e9,
-  "Related companies" : [ "HPQ", "IBM", "YHOO", "DELL", "GOOG" ]
-}
-"""
-
-  val malformedJson1 = """
-{
-  "Company name" ; "Microsoft Corporation"
-}
-"""
-
-  val malformedJson2 = """
-[
-  [ "HPQ", "IBM",
-  "YHOO", "DELL" ++
-  "GOOG"
-  ]
-]
-"""
-
-  val P = fpinscala.parsing.Reference
-  import fpinscala.parsing.ReferenceTypes.Parser
-
-  def printResult[E](e: Either[E,JSON]) =
-    e.fold(println, println)
-
-  val json: Parser[JSON] = JSON.jsonParser(P)
-  printResult { P.run(json)(jsonTxt) }
-  println("--")
-  printResult { P.run(json)(malformedJson1) }
-  println("--")
-  printResult { P.run(json)(malformedJson2) }
-}
diff --git a/answers/src/main/scala/fpinscala/parsing/Parsers.scala b/answers/src/main/scala/fpinscala/parsing/Parsers.scala
deleted file mode 100644
index 5238d1c..0000000
--- a/answers/src/main/scala/fpinscala/parsing/Parsers.scala
+++ /dev/null
@@ -1,247 +0,0 @@
-package fpinscala.parsing
-
-import java.util.regex._
-import scala.util.matching.Regex
-import fpinscala.testing._
-import fpinscala.testing.Prop._
-import language.higherKinds
-import language.implicitConversions
-
-trait Parsers[Parser[+_]] { self => // so inner classes may call methods of trait
-  def run[A](p: Parser[A])(input: String): Either[ParseError,A]
-
-  implicit def string(s: String): Parser[String]
-  implicit def operators[A](p: Parser[A]) = ParserOps[A](p)
-  implicit def asStringParser[A](a: A)(implicit f: A => Parser[String]):
-    ParserOps[String] = ParserOps(f(a))
-
-  def char(c: Char): Parser[Char] =
-    string(c.toString) map (_.charAt(0))
-
-  /*
-   * A default `succeed` implementation in terms of `string` and `map`.
-   * We leave `succeed` abstract, since `map` is defined below in terms of
-   * `flatMap` and `succeed`, which would be a circular definition! But we include
-   * the definition here in case implementations wish to use it
-   * (say if they provide a custom implementation of `map`, breaking the cycle)
-   */
-  def defaultSucceed[A](a: A): Parser[A] =
-    string("") map (_ => a)
-
-  def succeed[A](a: A): Parser[A]
-
-  def slice[A](p: Parser[A]): Parser[String]
-
-  def many1[A](p: Parser[A]): Parser[List[A]] =
-    map2(p, many(p))(_ :: _)
-
-  def listOfN[A](n: Int, p: Parser[A]): Parser[List[A]] =
-    if (n <= 0) succeed(List())
-    else map2(p, listOfN(n-1, p))(_ :: _)
-
-  def many[A](p: Parser[A]): Parser[List[A]] =
-    map2(p, many(p))(_ :: _) or succeed(List())
-
-  def or[A](p1: Parser[A], p2: => Parser[A]): Parser[A]
-
-  def flatMap[A,B](p: Parser[A])(f: A => Parser[B]): Parser[B]
-
-  implicit def regex(r: Regex): Parser[String]
-
-  /*
-  These can be implemented using a for-comprehension, which delegates to the `flatMap` and `map` implementations we've provided on `ParserOps`, or they can be implemented in terms of these functions directly.
-  */
-  def product[A,B](p: Parser[A], p2: => Parser[B]): Parser[(A,B)] =
-    flatMap(p)(a => map(p2)(b => (a,b)))
-
-  def map2[A,B,C](p: Parser[A], p2: => Parser[B])(f: (A,B) => C): Parser[C] =
-    for { a <- p; b <- p2 } yield f(a,b)
-
-  def map[A,B](a: Parser[A])(f: A => B): Parser[B] =
-    flatMap(a)(f andThen succeed)
-
-  def label[A](msg: String)(p: Parser[A]): Parser[A]
-
-  def scope[A](msg: String)(p: Parser[A]): Parser[A]
-
-  def attempt[A](p: Parser[A]): Parser[A]
-
-  /** Sequences two parsers, ignoring the result of the first.
-    * We wrap the ignored half in slice, since we don't care about its result. */
-  def skipL[B](p: Parser[Any], p2: => Parser[B]): Parser[B] =
-    map2(slice(p), p2)((_,b) => b)
-
-  /** Sequences two parsers, ignoring the result of the second.
-    * We wrap the ignored half in slice, since we don't care about its result. */
-  def skipR[A](p: Parser[A], p2: => Parser[Any]): Parser[A] =
-    map2(p, slice(p2))((a,b) => a)
-
-  def opt[A](p: Parser[A]): Parser[Option[A]] =
-    p.map(Some(_)) or succeed(None)
-
-  /** Parser which consumes zero or more whitespace characters. */
-  def whitespace: Parser[String] = "\\s*".r
-
-  /** Parser which consumes 1 or more digits. */
-  def digits: Parser[String] = "\\d+".r
-
-  /** Parser which consumes reluctantly until it encounters the given string. */
-  def thru(s: String): Parser[String] = (".*?"+Pattern.quote(s)).r
-
-  /** Unescaped string literals, like "foo" or "bar". */
-  def quoted: Parser[String] = string("\"") *> thru("\"").map(_.dropRight(1))
-
-  /** Unescaped or escaped string literals, like "An \n important \"Quotation\"" or "bar". */
-  def escapedQuoted: Parser[String] =
-    // rather annoying to write, left as an exercise
-    // we'll just use quoted (unescaped literals) for now
-    token(quoted label "string literal")
-
-  /** C/Java style floating point literals, e.g .1, -1.0, 1e9, 1E-23, etc.
-    * Result is left as a string to keep full precision
-    */
-  def doubleString: Parser[String] =
-    token("[-+]?([0-9]*\\.)?[0-9]+([eE][-+]?[0-9]+)?".r)
-
-  /** Floating point literals, converted to a `Double`. */
-  def double: Parser[Double] =
-    doubleString map (_.toDouble) label "double literal"
-
-  /** Attempts `p` and strips trailing whitespace, usually used for the tokens of a grammar. */
-  def token[A](p: Parser[A]): Parser[A] =
-    attempt(p) <* whitespace
-
-  /** Zero or more repetitions of `p`, separated by `p2`, whose results are ignored. */
-  def sep[A](p: Parser[A], p2: Parser[Any]): Parser[List[A]] = // use `Parser[Any]` since don't care about result type of separator
-    sep1(p,p2) or succeed(List())
-
-  /** One or more repetitions of `p`, separated by `p2`, whose results are ignored. */
-  def sep1[A](p: Parser[A], p2: Parser[Any]): Parser[List[A]] =
-    map2(p, many(p2 *> p))(_ :: _)
-
-  /** Parses a sequence of left-associative binary operators with the same precedence. */
-  def opL[A](p: Parser[A])(op: Parser[(A,A) => A]): Parser[A] =
-    map2(p, many(op ** p))((h,t) => t.foldLeft(h)((a,b) => b._1(a,b._2)))
-
-  /** Wraps `p` in start/stop delimiters. */
-  def surround[A](start: Parser[Any], stop: Parser[Any])(p: => Parser[A]) =
-    start *> p <* stop
-
-  /** A parser that succeeds when given empty input. */
-  def eof: Parser[String] =
-    regex("\\z".r).label("unexpected trailing characters")
-
-  /** The root of the grammar, expects no further input following `p`. */
-  def root[A](p: Parser[A]): Parser[A] =
-    p <* eof
-
-  case class ParserOps[A](p: Parser[A]) {
-    def |[B>:A](p2: => Parser[B]): Parser[B] = self.or(p,p2) // use `self` to explicitly disambiguate reference to the `or` method on the `trait`
-    def or[B>:A](p2: => Parser[B]): Parser[B] = self.or(p,p2)
-
-    def map[B](f: A => B): Parser[B] = self.map(p)(f)
-    def many = self.many(p)
-
-    def slice: Parser[String] = self.slice(p)
-
-    def **[B](p2: => Parser[B]): Parser[(A,B)] =
-      self.product(p,p2)
-    def product[B](p2: => Parser[B]): Parser[(A,B)] =
-      self.product(p,p2)
-
-    def flatMap[B](f: A => Parser[B]): Parser[B] =
-      self.flatMap(p)(f)
-
-    def label(msg: String): Parser[A] = self.label(msg)(p)
-
-    def scope(msg: String): Parser[A] = self.scope(msg)(p)
-
-    def *>[B](p2: => Parser[B]) = self.skipL(p, p2)
-    def <*(p2: => Parser[Any]) = self.skipR(p, p2)
-    def token = self.token(p)
-    def sep(separator: Parser[Any]) = self.sep(p, separator)
-    def sep1(separator: Parser[Any]) = self.sep1(p, separator)
-    def as[B](b: B): Parser[B] = self.map(self.slice(p))(_ => b)
-    def opL(op: Parser[(A,A) => A]): Parser[A] = self.opL(p)(op)
-  }
-  object Laws {
-    def equal[A](p1: Parser[A], p2: Parser[A])(in: Gen[String]): Prop =
-      forAll(in)(s => run(p1)(s) == run(p2)(s))
-
-    def mapLaw[A](p: Parser[A])(in: Gen[String]): Prop =
-      equal(p, p.map(a => a))(in)
-  }
-}
-
-case class Location(input: String, offset: Int = 0) {
-
-  lazy val line = input.slice(0,offset+1).count(_ == '\n') + 1
-  lazy val col = input.slice(0,offset+1).lastIndexOf('\n') match {
-    case -1 => offset + 1
-    case lineStart => offset - lineStart
-  }
-
-  def toError(msg: String): ParseError =
-    ParseError(List((this, msg)))
-
-  def advanceBy(n: Int) = copy(offset = offset+n)
-
-  /* Returns the line corresponding to this location */
-  def currentLine: String =
-    if (input.length > 1) input.lines.drop(line-1).next
-    else ""
-
-  def columnCaret = (" " * (col-1)) + "^"
-}
-
-case class ParseError(stack: List[(Location,String)] = List()) {
-  def push(loc: Location, msg: String): ParseError =
-    copy(stack = (loc,msg) :: stack)
-
-  def label[A](s: String): ParseError =
-    ParseError(latestLoc.map((_,s)).toList)
-
-  def latest: Option[(Location,String)] =
-    stack.lastOption
-
-  def latestLoc: Option[Location] =
-    latest map (_._1)
-
-  /**
-  Display collapsed error stack - any adjacent stack elements with the
-  same location are combined on one line. For the bottommost error, we
-  display the full line, with a caret pointing to the column of the error.
-  Example:
-
-  1.1 file 'companies.json'; array
-  5.1 object
-  5.2 key-value
-  5.10 ':'
-
-  { "MSFT" ; 24,
-  */
-  override def toString =
-    if (stack.isEmpty) "no error message"
-    else {
-      val collapsed = collapseStack(stack)
-      val context =
-        collapsed.lastOption.map("\n\n" + _._1.currentLine).getOrElse("") +
-        collapsed.lastOption.map("\n" + _._1.columnCaret).getOrElse("")
-      collapsed.map { case (loc,msg) => loc.line.toString + "." + loc.col + " " + msg }.mkString("\n") +
-      context
-    }
-
-  /* Builds a collapsed version of the given error stack -
-   * messages at the same location have their messages merged,
-   * separated by semicolons */
-  def collapseStack(s: List[(Location,String)]): List[(Location,String)] =
-    s.groupBy(_._1).
-      mapValues(_.map(_._2).mkString("; ")).
-      toList.sortBy(_._1.offset)
-
-  def formatLoc(l: Location): String = l.line + "." + l.col
-}
-
-object Parsers {
-
-}
diff --git a/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala b/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala
deleted file mode 100644
index 6a21394..0000000
--- a/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala
+++ /dev/null
@@ -1,148 +0,0 @@
-package fpinscala
-package parsing
-
-import ReferenceTypes._
-import scala.util.matching.Regex
-
-object ReferenceTypes {
-
-  /** A parser is a kind of state action that can fail. */
-  type Parser[+A] = ParseState => Result[A]
-
-  /** `ParseState` wraps a `Location` and provides some extra
-    * convenience functions. The sliceable parsers defined
-    * in `Sliceable.scala` add an `isSliced` `Boolean` flag
-    * to `ParseState`.
-    */
-  case class ParseState(loc: Location) {
-    def advanceBy(numChars: Int): ParseState =
-      copy(loc = loc.copy(offset = loc.offset + numChars))
-    def input: String = loc.input.substring(loc.offset)
-    def slice(n: Int) = loc.input.substring(loc.offset, loc.offset + n)
-  }
-
-  /* Likewise, we define a few helper functions on `Result`. */
-  sealed trait Result[+A] {
-    def extract: Either[ParseError,A] = this match {
-      case Failure(e,_) => Left(e)
-      case Success(a,_) => Right(a)
-    }
-    /* Used by `attempt`. */
-    def uncommit: Result[A] = this match {
-      case Failure(e,true) => Failure(e,false)
-      case _ => this
-    }
-    /* Used by `flatMap` */
-    def addCommit(isCommitted: Boolean): Result[A] = this match {
-      case Failure(e,c) => Failure(e, c || isCommitted)
-      case _ => this
-    }
-    /* Used by `scope`, `label`. */
-    def mapError(f: ParseError => ParseError): Result[A] = this match {
-      case Failure(e,c) => Failure(f(e),c)
-      case _ => this
-    }
-    def advanceSuccess(n: Int): Result[A] = this match {
-      case Success(a,m) => Success(a,n+m)
-      case _ => this
-    }
-  }
-  case class Success[+A](get: A, length: Int) extends Result[A]
-  case class Failure(get: ParseError, isCommitted: Boolean) extends Result[Nothing]
-
-  /** Returns -1 if s1.startsWith(s2), otherwise returns the
-    * first index where the two strings differed. If s2 is
-    * longer than s1, returns s1.length. */
-  def firstNonmatchingIndex(s1: String, s2: String, offset: Int): Int = {
-    var i = 0
-    while (i < s1.length && i < s2.length) {
-      if (s1.charAt(i+offset) != s2.charAt(i)) return i
-      i += 1
-    }
-    if (s1.length-offset >= s2.length) -1
-    else s1.length-offset
-  }
-}
-
-object Reference extends Parsers[Parser] {
-
-  def run[A](p: Parser[A])(s: String): Either[ParseError,A] = {
-    val s0 = ParseState(Location(s))
-    p(s0).extract
-  }
-
-  // consume no characters and succeed with the given value
-  def succeed[A](a: A): Parser[A] = s => Success(a, 0)
-
-  def or[A](p: Parser[A], p2: => Parser[A]): Parser[A] =
-    s => p(s) match {
-      case Failure(e,false) => p2(s)
-      case r => r // committed failure or success skips running `p2`
-    }
-
-  def flatMap[A,B](f: Parser[A])(g: A => Parser[B]): Parser[B] =
-    s => f(s) match {
-      case Success(a,n) => g(a)(s.advanceBy(n))
-                           .addCommit(n != 0)
-                           .advanceSuccess(n)
-      case f@Failure(_,_) => f
-    }
-
-  def string(w: String): Parser[String] = {
-    val msg = "'" + w + "'"
-    s => {
-      val i = firstNonmatchingIndex(s.loc.input, w, s.loc.offset)
-      if (i == -1) // they matched
-        Success(w, w.length)
-      else
-        Failure(s.loc.advanceBy(i).toError(msg), i != 0)
-    }
-  }
-
-  /* note, regex matching is 'all-or-nothing':
-   * failures are uncommitted */
-  def regex(r: Regex): Parser[String] = {
-    val msg = "regex " + r
-    s => r.findPrefixOf(s.input) match {
-      case None => Failure(s.loc.toError(msg), false)
-      case Some(m) => Success(m,m.length)
-    }
-  }
-
-  def scope[A](msg: String)(p: Parser[A]): Parser[A] =
-    s => p(s).mapError(_.push(s.loc,msg))
-
-  def label[A](msg: String)(p: Parser[A]): Parser[A] =
-    s => p(s).mapError(_.label(msg))
-
-  def fail[A](msg: String): Parser[A] =
-    s => Failure(s.loc.toError(msg), true)
-
-  def attempt[A](p: Parser[A]): Parser[A] =
-    s => p(s).uncommit
-
-  def slice[A](p: Parser[A]): Parser[String] =
-    s => p(s) match {
-      case Success(_,n) => Success(s.slice(n),n)
-      case f@Failure(_,_) => f
-    }
-
-  /* We provide an overridden version of `many` that accumulates
-   * the list of results using a monolithic loop. This avoids
-   * stack overflow errors for most grammars.
-   */
-  override def many[A](p: Parser[A]): Parser[List[A]] =
-    s => {
-      var nConsumed: Int = 0
-      val buf = new collection.mutable.ListBuffer[A]
-      def go(p: Parser[A], offset: Int): Result[List[A]] = {
-        p(s.advanceBy(offset)) match {
-          case Success(a,n) => buf += a; go(p, offset+n)
-          case f@Failure(e,true) => f
-          case Failure(e,_) => Success(buf.toList,offset)
-        }
-      }
-      go(p, 0)
-    }
-}
-
diff --git a/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala b/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala
deleted file mode 100644
index 6826b52..0000000
--- a/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala
+++ /dev/null
@@ -1,273 +0,0 @@
-package fpinscala
-package parsing
-
-import SliceableTypes._
-import scala.util.matching.Regex
-
-/*
-This implementation is a bit trickier than the one in `Reference.scala`.
-The main change is to add another piece of state to `ParseState`,
-an `isSliced` flag, and an additional `Slice` constructor to `Result`.
-If the `isSliced` flag is set, parsers avoid building a meaningful
-result--see in particular the overridden implementations for `map`,
-`map2`, and `many`.
-
-This implementation runs up against some limitations of Scala's
-type system--Scala does not appropriately refine type parameters when
-pattern matching. Keep reading for more details on this.
-*/
-object SliceableTypes {
-
-  /* A parser is a kind of state action that can fail.
-   * This type is slightly fancier than the one discussed in the chapter,
-   * to support efficient slicing. If the parser is surrounded by
-   * a `slice` combinator, the `isSliced` field of `ParseState` will
-   * be `true`, and we return a `Slice` output.
-   */
-  type Parser[+A] = ParseState => Result[A]
-
-  /** `isSliced` indicates if the current parser is surround by a
-    * `slice` combinator. This lets us avoid building up values that
-    * will end up getting thrown away.
-    *
-    * There are several convenience functions on `ParseState` to make
-    * implementing some of the combinators easier.
-    */
-  case class ParseState(loc: Location, isSliced: Boolean) {
-    // some convenience functions
-    def advanceBy(numChars: Int): ParseState =
-      copy(loc = loc.copy(offset = loc.offset + numChars))
-    def input: String = loc.input.substring(loc.offset)
-    def unslice = copy(isSliced = false)
-    def reslice(s: ParseState) = copy(isSliced = s.isSliced)
-    def slice(n: Int) = loc.input.substring(loc.offset, loc.offset + n)
-  }
-
-  /** The result of a parse--a `Parser[A]` returns a `Result[A]`.
-    *
-    * There are three cases:
-    *   - Success(a,n): a is the value, n is # of consumed characters
-    *   - Slice(n): a successful slice; n is the # of consumed characters
-    *   - Failure(n,isCommitted): a failing parse
-    *
-    * As usual, we define some helper functions on `Result`.
-    * Defining functions on `Result` gives us better type
-    * information--there are cases (see `map` and `map2` below) where
-    * Scala will not appropriately refine type information when
-    * pattern matching on `Result`.
-    */
-  sealed trait Result[+A] {
-    def extract(input: String): Either[ParseError,A]
-    def slice: Result[String]
-    /* Used by `attempt`. */
-    def uncommit: Result[A] = this match {
-      case Failure(e,true) => Failure(e,false)
-      case _ => this
-    }
-    /* Used by `flatMap` */
-    def addCommit(isCommitted: Boolean): Result[A] = this match {
-      case Failure(e,c) => Failure(e, c || isCommitted)
-      case _ => this
-    }
-    /* Used by `scope`, `label`. */
-    def mapError(f: ParseError => ParseError): Result[A] = this match {
-      case Failure(e,c) => Failure(f(e),c)
-      case _ => this
-    }
-    def advanceSuccess(n: Int): Result[A]
-  }
-  case class Slice(length: Int) extends Result[String] {
-    def extract(s: String) = Right(s.substring(0,length))
-    def slice = this
-    def advanceSuccess(n: Int) = Slice(length+n)
-  }
-  case class Success[+A](get: A, length: Int) extends Result[A] {
-    def extract(s: String) = Right(get)
-    def slice = Slice(length)
-    def advanceSuccess(n: Int) = Success(get, length+n)
-  }
-  case class Failure(get: ParseError, isCommitted: Boolean) extends Result[Nothing] {
-    def extract(s: String) = Left(get)
-    def slice = this
-    def advanceSuccess(n: Int) = this
-  }
-
-  /** Returns -1 if s.startsWith(s2), otherwise returns the
-    * first index where the two strings differed. If s2 is
-    * longer than s1, returns s.length. */
-  def firstNonmatchingIndex(s: String, s2: String, offset: Int): Int = {
-    var i = 0
-    while (i+offset < s.length && i < s2.length) {
-      if (s.charAt(i+offset) != s2.charAt(i)) return i
-      i += 1
-    }
-    if (s.length-offset >= s2.length) -1
-    else s.length-offset
-  }
-}
-
-object Sliceable extends Parsers[Parser] {
-
-  def run[A](p: Parser[A])(s: String): Either[ParseError,A] = {
-    val s0 = ParseState(Location(s), false)
-    p(s0).extract(s)
-  }
-
-  // consume no characters and succeed with the given value
-  def succeed[A](a: A): Parser[A] = s => Success(a, 0)
-
-  def or[A](p: Parser[A], p2: => Parser[A]): Parser[A] =
-    s => p(s) match {
-      case Failure(e,false) => p2(s)
-      case r => r // committed failure or success skips running `p2`
-    }
-
-  /*
-   * `Result` is an example of a Generalized Algebraic Data Type (GADT),
-   * which means that not all the data constructors of `Result` have
-   * the same type. In particular, `Slice` _refines_ the `A` type
-   * parameter to be `String`. If we pattern match on a `Result`
-   * and obtain a `Slice`, we expect to be able to assume that `A` was
-   * in fact `String` and use this type information elsewhere.
-   *
-   * Unfortunately, Scala doesn't quite support this. Let's look
-   * at an example, `map`.
-   */
-
-  /* Pattern matching on Slice should refine the type `A` to `String`,
-   * and allow us to call `f(s.slice(n))`, since `f` accepts an
-   * `A` which is known to be `String`. We resort to a cast here.
-   */
-  override def map[A,B](p: Parser[A])(f: A => B): Parser[B] =
-    s => p(s) match {
-      case Success(a,n) => Success(f(a),n)
-      case Slice(n) => Success(f(s.slice(n).asInstanceOf[A]),n)
-      case f@Failure(_,_) => f
-    }
-
-  /* See this gist for more information, examples, and discussion
-   * of Scala's GADT support:
-   * https://gist.github.com/1369239
-   */
-
-  /* This implementation is rather delicate. Since we need an `A`
-   * to generate the second parser, we need to run the first parser
-   * 'unsliced', even if the `flatMap` is wrapped in a `slice` call.
-   * Once we have the `A` and have generated the second parser to
-   * run, we can 'reslice' the second parser.
-   *
-   * Note that this implementation is less efficient than it could
-   * be in the case where the choice of the second parser does not
-   * depend on the first (as in `map2`). In that case, we could
-   * continue to run the first parser sliced.
-   *
-   * Again, note the cast needed.
-   */
-  def flatMap[A,B](f: Parser[A])(g: A => Parser[B]): Parser[B] =
-    s => f(s.unslice) match {
-      case Success(a,n) =>
-        g(a)(s.advanceBy(n).reslice(s))
-        .addCommit(n != 0)
-        .advanceSuccess(n)
-      case Slice(n) => g(s.slice(n).asInstanceOf[A])(s.advanceBy(n).reslice(s))
-                       .advanceSuccess(n)
-      case f@Failure(_,_) => f
-    }
-
-  // other functions are quite similar to impls in `Reference.scala`
-
-  def string(w: String): Parser[String] = {
-    val msg = "'" + w + "'"
-    s => {
-      val i = firstNonmatchingIndex(s.loc.input, w, s.loc.offset)
-      if (i == -1) { // they matched
-        if (s.isSliced) Slice(w.length)
-        else            Success(w, w.length)
-      }
-      else
-        Failure(s.loc.advanceBy(i).toError(msg), i != 0)
-    }
-  }
-
-  // note, regex matching is 'all-or-nothing' - failures are
-  // uncommitted
-  def regex(r: Regex): Parser[String] = {
-    val msg = "regex " + r
-    s => r.findPrefixOf(s.input) match {
-      case None => Failure(s.loc.toError(msg), false)
-      case Some(m) =>
-        if (s.isSliced) Slice(m.length)
-        else            Success(m,m.length)
-    }
-  }
-
-  def scope[A](msg: String)(p: Parser[A]): Parser[A] =
-    s => p(s).mapError(_.push(s.loc,msg))
-
-  def label[A](msg: String)(p: Parser[A]): Parser[A] =
-    s => p(s).mapError(_.label(msg))
-
-  def fail[A](msg: String): Parser[A] =
-    s => Failure(s.loc.toError(msg), true)
-
-  def attempt[A](p: Parser[A]): Parser[A] =
-    s => p(s).uncommit
-
-  def slice[A](p: Parser[A]): Parser[String] =
-    s => p(s.copy(isSliced = true)).slice
-
-  /* As with `map`, we require casts in a few places. */
-  override def map2[A,B,C](p: Parser[A], p2: => Parser[B])(f: (A,B) => C): Parser[C] =
-    s => p(s) match {
-      case Success(a,n) => val s2 = s.advanceBy(n); p2(s2) match {
-        case Success(b,m) => Success(f(a,b),n+m)
-        case Slice(m) => Success(f(a,s2.slice(m).asInstanceOf[B]), n+m)
-        case f@Failure(_,_) => f
-      }
-      case Slice(n) => val s2 = s.advanceBy(n); p2(s2) match {
-        case Success(b,m) => Success(f(s.slice(n).asInstanceOf[A],b),n+m)
-        case Slice(m) =>
-          if (s.isSliced) Slice(n+m).asInstanceOf[Result[C]]
-          else Success(f(s.slice(n).asInstanceOf[A],s2.slice(m).asInstanceOf[B]), n+m)
-        case f@Failure(_,_) => f
-      }
-      case f@Failure(_,_) => f
-    }
-
-  override def product[A,B](p: Parser[A], p2: => Parser[B]): Parser[(A,B)] =
-    map2(p,p2)((_,_))
-
-  /* We provide an overridden version of `many` that accumulates
-   * the list of results using a monolithic loop. This avoids
-   * stack overflow errors.
-   */
-  override def many[A](p: Parser[A]): Parser[List[A]] =
-    s => {
-      var nConsumed: Int = 0
-      if (s.isSliced) {
-        def go(p: Parser[String], offset: Int): Result[String] =
-          p(s.advanceBy(offset)) match {
-            case f@Failure(e,true) => f
-            case Failure(e,_) => Slice(offset)
-            case Slice(n) => go(p, offset+n)
-            case Success(_,_) => sys.error("sliced parser should not return success, only slice")
-          }
-        go(p.slice, 0).asInstanceOf[Result[List[A]]]
-      }
-      else {
-        val buf = new collection.mutable.ListBuffer[A]
-        def go(p: Parser[A], offset: Int): Result[List[A]] = {
-          p(s.advanceBy(offset)) match {
-            case Success(a,n) => buf += a; go(p, offset+n)
-            case f@Failure(e,true) => f
-            case Failure(e,_) => Success(buf.toList,offset)
-            case Slice(n) =>
-              buf += s.input.substring(offset,offset+n).
-                     asInstanceOf[A]
-              go(p, offset+n)
-          }
-        }
-        go(p, 0)
-      }
-    }
-}
diff --git a/answers/src/main/scala/fpinscala/state/State.scala b/answers/src/main/scala/fpinscala/state/State.scala
deleted file mode 100644
index 88e7b48..0000000
--- a/answers/src/main/scala/fpinscala/state/State.scala
+++ /dev/null
@@ -1,241 +0,0 @@
-package fpinscala.state
-
-
-trait RNG {
-  def nextInt: (Int, RNG) // Should generate a random `Int`. We'll later define other functions in terms of `nextInt`.
-}
-
-object RNG {
-  // NB - this was called SimpleRNG in the book text
-
-  case class Simple(seed: Long) extends RNG {
-    def nextInt: (Int, RNG) = {
-      val newSeed = (seed * 0x5DEECE66DL + 0xBL) & 0xFFFFFFFFFFFFL // `&` is bitwise AND. We use the current seed to generate a new seed.
-      val nextRNG = Simple(newSeed) // The next state, which is an `RNG` instance created from the new seed.
-      val n = (newSeed >>> 16).toInt // `>>>` is right binary shift with zero fill. The value `n` is our new pseudo-random integer.
-      (n, nextRNG) // The return value is a tuple containing both a pseudo-random integer and the next `RNG` state.
-    }
-  }
-
-  // We need to be quite careful not to skew the generator.
-  // Since `Int.Minvalue` is 1 smaller than `-(Int.MaxValue)`,
-  // it suffices to increment the negative numbers by 1 and make them positive.
-  // This maps Int.MinValue to Int.MaxValue and -1 to 0.
-  def nonNegativeInt(rng: RNG): (Int, RNG) = {
-    val (i, r) = rng.nextInt
-    (if (i < 0) -(i + 1) else i, r)
-  }
-
-  // We generate an integer >= 0 and divide it by one higher than the
-  // maximum. This is just one possible solution.
-  def double(rng: RNG): (Double, RNG) = {
-    val (i, r) = nonNegativeInt(rng)
-    (i / (Int.MaxValue.toDouble + 1), r)
-  }
-
-  def boolean(rng: RNG): (Boolean, RNG) =
-    rng.nextInt match { case (i,rng2) => (i%2==0,rng2) }
-
-  def intDouble(rng: RNG): ((Int, Double), RNG) = {
-    val (i, r1) = rng.nextInt
-    val (d, r2) = double(r1)
-    ((i, d), r2)
-  }
-
-  def doubleInt(rng: RNG): ((Double, Int), RNG) = {
-    val ((i, d), r) = intDouble(rng)
-    ((d, i), r)
-  }
-
-  def double3(rng: RNG): ((Double, Double, Double), RNG) = {
-    val (d1, r1) = double(rng)
-    val (d2, r2) = double(r1)
-    val (d3, r3) = double(r2)
-    ((d1, d2, d3), r3)
-  }
-
-  // There is something terribly repetitive about passing the RNG along
-  // every time. What could we do to eliminate some of this duplication
-  // of effort?
-
-  // A simple recursive solution
-  def ints(count: Int)(rng: RNG): (List[Int], RNG) =
-    if (count == 0)
-      (List(), rng)
-    else {
-      val (x, r1)  = rng.nextInt
-      val (xs, r2) = ints(count - 1)(r1)
-      (x :: xs, r2)
-    }
-
-  // A tail-recursive solution
-  def ints2(count: Int)(rng: RNG): (List[Int], RNG) = {
-    def go(count: Int, r: RNG, xs: List[Int]): (List[Int], RNG) =
-      if (count == 0)
-        (xs, r)
-      else {
-        val (x, r2) = r.nextInt
-        go(count - 1, r2, x :: xs)
-      }
-    go(count, rng, List())
-  }
-
-  type Rand[+A] = RNG => (A, RNG)
-
-  val int: Rand[Int] = _.nextInt
-
-  def unit[A](a: A): Rand[A] =
-    rng => (a, rng)
-
-  def map[A,B](s: Rand[A])(f: A => B): Rand[B] =
-    rng => {
-      val (a, rng2) = s(rng)
-      (f(a), rng2)
-    }
-
-  val _double: Rand[Double] =
-    map(nonNegativeInt)(_ / (Int.MaxValue.toDouble + 1))
-
-  // This implementation of map2 passes the initial RNG to the first argument
-  // and the resulting RNG to the second argument. It's not necessarily wrong
-  // to do this the other way around, since the results are random anyway.
-  // We could even pass the initial RNG to both `f` and `g`, but that might
-  // have unexpected results. E.g. if both arguments are `RNG.int` then we would
-  // always get two of the same `Int` in the result. When implementing functions
-  // like this, it's important to consider how we would test them for
-  // correctness.
-  def map2[A,B,C](ra: Rand[A], rb: Rand[B])(f: (A, B) => C): Rand[C] =
-    rng => {
-      val (a, r1) = ra(rng)
-      val (b, r2) = rb(r1)
-      (f(a, b), r2)
-    }
-
-  def both[A,B](ra: Rand[A], rb: Rand[B]): Rand[(A,B)] =
-    map2(ra, rb)((_, _))
-
-  val randIntDouble: Rand[(Int, Double)] =
-    both(int, double)
-
-  val randDoubleInt: Rand[(Double, Int)] =
-    both(double, int)
-
-  // In `sequence`, the base case of the fold is a `unit` action that returns
-  // the empty list. At each step in the fold, we accumulate in `acc`
-  // and `f` is the current element in the list.
-  // `map2(f, acc)(_ :: _)` results in a value of type `Rand[List[A]]`
-  // We map over that to prepend (cons) the element onto the accumulated list.
-  //
-  // We are using `foldRight`. If we used `foldLeft` then the values in the
-  // resulting list would appear in reverse order. It would be arguably better
-  // to use `foldLeft` followed by `reverse`. What do you think?
-  def sequence[A](fs: List[Rand[A]]): Rand[List[A]] =
-    fs.foldRight(unit(List[A]()))((f, acc) => map2(f, acc)(_ :: _))
-
-  // It's interesting that we never actually need to talk about the `RNG` value
-  // in `sequence`. This is a strong hint that we could make this function
-  // polymorphic in that type.
-
-  def _ints(count: Int): Rand[List[Int]] =
-    sequence(List.fill(count)(int))
-
-  def flatMap[A,B](f: Rand[A])(g: A => Rand[B]): Rand[B] =
-    rng => {
-      val (a, r1) = f(rng)
-      g(a)(r1) // We pass the new state along
-    }
-
-  def nonNegativeLessThan(n: Int): Rand[Int] = {
-    flatMap(nonNegativeInt) { i =>
-      val mod = i % n
-      if (i + (n-1) - mod >= 0) unit(mod) else nonNegativeLessThan(n)
-    }
-  }
-
-  def _map[A,B](s: Rand[A])(f: A => B): Rand[B] =
-    flatMap(s)(a => unit(f(a)))
-
-  def _map2[A,B,C](ra: Rand[A], rb: Rand[B])(f: (A, B) => C): Rand[C] =
-    flatMap(ra)(a => map(rb)(b => f(a, b)))
-}
-
-import State._
-
-case class State[S, +A](run: S => (A, S)) {
-  def map[B](f: A => B): State[S, B] =
-    flatMap(a => unit(f(a)))
-  def map2[B,C](sb: State[S, B])(f: (A, B) => C): State[S, C] =
-    flatMap(a => sb.map(b => f(a, b)))
-  def flatMap[B](f: A => State[S, B]): State[S, B] = State(s => {
-    val (a, s1) = run(s)
-    f(a).run(s1)
-  })
-}
-
-object State {
-  type Rand[A] = State[RNG, A]
-
-  def unit[S, A](a: A): State[S, A] =
-    State(s => (a, s))
-
-  // The idiomatic solution is expressed via foldRight
-  def sequenceViaFoldRight[S,A](sas: List[State[S, A]]): State[S, List[A]] =
-    sas.foldRight(unit[S, List[A]](List()))((f, acc) => f.map2(acc)(_ :: _))
-
-  // This implementation uses a loop internally and is the same recursion
-  // pattern as a left fold. It is quite common with left folds to build
-  // up a list in reverse order, then reverse it at the end.
-  // (We could also use a collection.mutable.ListBuffer internally.)
-  def sequence[S, A](sas: List[State[S, A]]): State[S, List[A]] = {
-    def go(s: S, actions: List[State[S,A]], acc: List[A]): (List[A],S) =
-      actions match {
-        case Nil => (acc.reverse,s)
-        case h :: t => h.run(s) match { case (a,s2) => go(s2, t, a :: acc) }
-      }
-    State((s: S) => go(s,sas,List()))
-  }
-
-  // We can also write the loop using a left fold. This is tail recursive like the
-  // previous solution, but it reverses the list _before_ folding it instead of after.
-  // You might think that this is slower than the `foldRight` solution since it
-  // walks over the list twice, but it's actually faster! The `foldRight` solution
-  // technically has to also walk the list twice, since it has to unravel the call
-  // stack, not being tail recursive. And the call stack will be as tall as the list
-  // is long.
-  def sequenceViaFoldLeft[S,A](l: List[State[S, A]]): State[S, List[A]] =
-    l.reverse.foldLeft(unit[S, List[A]](List()))((acc, f) => f.map2(acc)( _ :: _ ))
-
-  def modify[S](f: S => S): State[S, Unit] = for {
-    s <- get // Gets the current state and assigns it to `s`.
-    _ <- set(f(s)) // Sets the new state to `f` applied to `s`.
-  } yield ()
-
-  def get[S]: State[S, S] = State(s => (s, s))
-
-  def set[S](s: S): State[S, Unit] = State(_ => ((), s))
-}
-
-sealed trait Input
-case object Coin extends Input
-case object Turn extends Input
-
-case class Machine(locked: Boolean, candies: Int, coins: Int)
-
-object Candy {
-  def update = (i: Input) => (s: Machine) =>
-    (i, s) match {
-      case (_, Machine(_, 0, _)) => s
-      case (Coin, Machine(false, _, _)) => s
-      case (Turn, Machine(true, _, _)) => s
-      case (Coin, Machine(true, candy, coin)) =>
-        Machine(false, candy, coin + 1)
-      case (Turn, Machine(false, candy, coin)) =>
-        Machine(true, candy - 1, coin)
-    }
-
-  def simulateMachine(inputs: List[Input]): State[Machine, (Int, Int)] = for {
-    _ <- sequence(inputs map (modify[Machine] _ compose update))
-    s <- get
-  } yield (s.coins, s.candies)
-}
-
diff --git a/answers/src/main/scala/fpinscala/streamingio/Eq.scala b/answers/src/main/scala/fpinscala/streamingio/Eq.scala
deleted file mode 100644
index da555f8..0000000
--- a/answers/src/main/scala/fpinscala/streamingio/Eq.scala
+++ /dev/null
@@ -1,16 +0,0 @@
-package fpinscala.streamingio
-
-/* 
- * `Eq[A,B]` provides evidence that types `A` and `B` are equal. 
- * There is just one public constructor, `Eq.refl`, ensuring that
- * we cannot construct an `Eq` instance in which the `A` and `B`
- * differ.
- * 
- * There is a version of this in the scala standard library, 
- * called =:=[A,B] (and usually written infix as `A =:= B`) but
- * we include a version here just to show that it is not magic.
- */
-case class Eq[A,B] private(to: A => B, from: B => A)
-
-object Eq { def refl[A]: Eq[A,A] = Eq(identity, identity) } 
-
diff --git a/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala b/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala
deleted file mode 100644
index b292fe5..0000000
--- a/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala
+++ /dev/null
@@ -1,23 +0,0 @@
-package fpinscala.streamingio
-
-import fpinscala.iomonad._
-
-import language.higherKinds
-
-/*
- * A context in which exceptions can be caught and
- * thrown.
- */
-trait MonadCatch[F[_]] extends Monad[F] {
-  def attempt[A](a: F[A]): F[Either[Throwable,A]]
-  def fail[A](t: Throwable): F[A]
-}
-
-object MonadCatch {
-  implicit def task = new MonadCatch[Task] {
-    def unit[A](a: => A): Task[A] = Task.unit(a)
-    def flatMap[A,B](a: Task[A])(f: A => Task[B]): Task[B] = a flatMap f
-    def attempt[A](a: Task[A]): Task[Either[Throwable,A]] = a.attempt
-    def fail[A](err: Throwable): Task[A] = Task.fail(err)
-  }
-}
diff --git a/answers/src/main/scala/fpinscala/streamingio/Partial.scala b/answers/src/main/scala/fpinscala/streamingio/Partial.scala
deleted file mode 100644
index 4ead887..0000000
--- a/answers/src/main/scala/fpinscala/streamingio/Partial.scala
+++ /dev/null
@@ -1,13 +0,0 @@
-package fpinscala.streamingio
-
-import language.higherKinds
-
-/* 
- * A context in which exceptions can be caught and
- * thrown. 
- */
-trait Partial[F[_]] { 
-  def attempt[A](a: F[A]): F[Either[Throwable,A]]
-  def fail[A](t: Throwable): F[A]
-}
-
diff --git a/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala b/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala
deleted file mode 100644
index d11903a..0000000
--- a/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala
+++ /dev/null
@@ -1,1133 +0,0 @@
-package fpinscala.streamingio
-
-import fpinscala.iomonad.{IO,Monad,Free,unsafePerformIO}
-import language.implicitConversions
-import language.higherKinds
-import language.postfixOps
-
-object ImperativeAndLazyIO {
-
-                            /*
-
-  We are going to consider various approaches to the simple task of
-  checking whether a file contains more than 40,000 lines.
-
-  Our first implementation is an imperative implementation, embedded
-  into `IO`.
-                             */
-
-  import java.io._
-
-  def linesGt40k(filename: String): IO[Boolean] = IO {
-    // There are a number of convenience functions in scala.io.Source
-    // for reading from external sources such as files.
-    val src = io.Source.fromFile(filename)
-    try {
-      var count = 0
-      // Obtain a stateful iterator from the Source
-      val lines: Iterator[String] = src.getLines
-      while (count <= 40000 && lines.hasNext) {
-        lines.next // has side effect of advancing to next element
-        count += 1
-      }
-      count > 40000
-    }
-    finally src.close
-  }
-
-                            /*
-
-  The above code is rather low-level, and it's not compositional,
-  either. Consider the following scenarios:
-
-  * Check whether the number of _nonempty_ lines in the file exceeds
-    40,000
-  * Find a line index before 40,000 where the first letter of
-    consecutive lines spells out `"abracadabra"`.
-
-  We cannot just compose our existing implementation with some
-  other combinator(s) to implement these tasks. Our implementation is
-  a monolithic loop, and we must modify this loop directly if we want
-  to change its behavior.
-
-  Now imagine if we had a `Stream[String]` for the lines of the file
-  and we could assemble functionality using all the `Stream` functions
-  we know and love.
-                             */
-
-  object Examples {
-    val lines: Stream[String] = sys.error("defined elsewhere")
-    val ex1 = lines.zipWithIndex.exists(_._2 + 1 >= 40000)
-    val ex2 = lines.filter(!_.trim.isEmpty).zipWithIndex.exists(_._2 + 1 >= 40000)
-    val ex3 = lines.take(40000).map(_.head).indexOfSlice("abracadabra".toList)
-  }
-
-                            /*
-
-  Could we actually write the above? Not quite. We could 'cheat' and
-  return an `IO[Stream[String]]` representing the lines of a file:
-
-                             */
-
-  def lines(filename: String): IO[Stream[String]] = IO {
-    val src = io.Source.fromFile(filename)
-    src.getLines.toStream append { src.close; Stream.empty }
-  }
-                            /*
-
-  This is called _lazy I/O_, and it's problematic for a number of
-  reasons, discussed in the book text. However, it would be nice to
-  recover the same high-level, compositional style we are used to
-  from our use of `List` and `Stream`.
-
-                             */
-}
-
-object SimpleStreamTransducers {
-
-                            /*
-
-  We now introduce a type, `Process`, representing pure, single-input
-  stream transducers. It can be in of three states - it can be
-  emitting a value to the output (`Emit`), reading a value from its
-  input (`Await`) or signaling termination via `Halt`.
-
-                             */
-
-  sealed trait Process[I,O] {
-    import Process._
-
-    /*
-     * A `Process[I,O]` can be used to transform a `Stream[I]` to a
-     * `Stream[O]`.
-     */
-    def apply(s: Stream[I]): Stream[O] = this match {
-      case Halt() => Stream()
-      case Await(recv) => s match {
-        case h #:: t => recv(Some(h))(t)
-        case xs => recv(None)(xs) // Stream is empty
-      }
-      case Emit(h,t) => h #:: t(s)
-    }
-
-    /*
-     * `Process` can be thought of as a sequence of values of type `O`
-     * and many of the operations that would be defined for `List[O]`
-     * can be defined for `Process[I,O]`, for instance `map`, `++` and
-     * `flatMap`. The definitions are analogous.
-     */
-
-    def map[O2](f: O => O2): Process[I,O2] = this match {
-      case Halt() => Halt()
-      case Emit(h, t) => Emit(f(h), t map f)
-      case Await(recv) => Await(recv andThen (_ map f))
-    }
-    def ++(p: => Process[I,O]): Process[I,O] = this match {
-      case Halt() => p
-      case Emit(h, t) => Emit(h, t ++ p)
-      case Await(recv) => Await(recv andThen (_ ++ p))
-    }
-    def flatMap[O2](f: O => Process[I,O2]): Process[I,O2] = this match {
-      case Halt() => Halt()
-      case Emit(h, t) => f(h) ++ t.flatMap(f)
-      case Await(recv) => Await(recv andThen (_ flatMap f))
-    }
-
-    /*
-     * Exercise 5: Implement `|>`. Let the types guide your implementation.
-     */
-    def |>[O2](p2: Process[O,O2]): Process[I,O2] = {
-      p2 match {
-        case Halt() => Halt()
-        case Emit(h,t) => Emit(h, this |> t)
-        case Await(f) => this match {
-          case Emit(h,t) => t |> f(Some(h))
-          case Halt() => Halt() |> f(None)
-          case Await(g) => Await((i: Option[I]) => g(i) |> p2)
-        }
-      }
-    }
-
-    /*
-     * Feed `in` to this `Process`. Uses a tail recursive loop as long
-     * as `this` is in the `Await` state.
-     */
-    def feed(in: Seq[I]): Process[I,O] = {
-      @annotation.tailrec
-      def go(in: Seq[I], cur: Process[I,O]): Process[I,O] =
-        cur match {
-          case Halt() => Halt()
-          case Await(recv) =>
-            if (in.nonEmpty) go(in.tail, recv(Some(in.head)))
-            else cur
-          case Emit(h, t) => Emit(h, t.feed(in))
-        }
-      go(in, this)
-    }
-
-
-    /*
-     * See `Process.lift` for a typical repeating `Process`
-     * definition expressed with explicit recursion.
-     */
-
-    /*
-     * `Process` definitions can often be expressed without explicit
-     * recursion, by repeating some simpler `Process` forever.
-     */
-    def repeat: Process[I,O] = {
-      def go(p: Process[I,O]): Process[I,O] = p match {
-        case Halt() => go(this)
-        case Await(recv) => Await {
-          case None => recv(None)
-          case i => go(recv(i))
-        }
-        case Emit(h, t) => Emit(h, go(t))
-      }
-      go(this)
-    }
-
-    def repeatN(n: Int): Process[I,O] = {
-      def go(n: Int, p: Process[I,O]): Process[I,O] = p match {
-        case Halt() => if (n > 0) go(n-1, this) else Halt()
-        case Await(recv) => Await {
-          case None => recv(None)
-          case i => go(n,recv(i))
-        }
-        case Emit(h, t) => Emit(h, go(n,t))
-      }
-      go(n, this)
-    }
-
-    /*
-     * As an example of `repeat`, see `Process.filter`. We define
-     * a convenience function here for composing this `Process`
-     * with a `Process` that filters the output type `O`.
-     */
-    def filter(f: O => Boolean): Process[I,O] =
-      this |> Process.filter(f)
-
-    /** Exercise 7: see definition below. */
-    def zip[O2](p: Process[I,O2]): Process[I,(O,O2)] =
-      Process.zip(this, p)
-
-    /*
-     * Exercise 6: Implement `zipWithIndex`.
-     */
-    def zipWithIndex: Process[I,(O,Int)] =
-      this zip (count map (_ - 1))
-
-    /* Add `p` to the fallback branch of this process */
-    def orElse(p: Process[I,O]): Process[I,O] = this match {
-      case Halt() => p
-      case Await(recv) => Await {
-        case None => p
-        case x => recv(x)
-      }
-      case _ => this
-    }
-  }
-
-  object Process {
-
-    case class Emit[I,O](
-        head: O,
-        tail: Process[I,O] = Halt[I,O]())
-      extends Process[I,O]
-
-    case class Await[I,O](
-        recv: Option[I] => Process[I,O])
-      extends Process[I,O]
-
-    case class Halt[I,O]() extends Process[I,O]
-
-    def emit[I,O](head: O,
-                  tail: Process[I,O] = Halt[I,O]()): Process[I,O] =
-      Emit(head, tail)
-
-    // Process forms a monad, and we provide monad syntax for it
-
-    import fpinscala.iomonad.Monad
-
-    def monad[I]: Monad[({ type f[x] = Process[I,x]})#f] =
-      new Monad[({ type f[x] = Process[I,x]})#f] {
-        def unit[O](o: => O): Process[I,O] = emit(o)
-        def flatMap[O,O2](p: Process[I,O])(f: O => Process[I,O2]): Process[I,O2] =
-          p flatMap f
-      }
-
-    // enable monadic syntax for `Process` type
-    implicit def toMonadic[I,O](a: Process[I,O]) = monad[I].toMonadic(a)
-
-    /**
-     * A helper function to await an element or fall back to another process
-     * if there is no input.
-     */
-    def await[I,O](f: I => Process[I,O],
-                   fallback: Process[I,O] = Halt[I,O]()): Process[I,O] =
-      Await[I,O] {
-        case Some(i) => f(i)
-        case None => fallback
-      }
-
-    /*
-     * We can convert any function `f: I => O` to a `Process[I,O]`. We
-     * simply `Await`, then `Emit` the value received, transformed by
-     * `f`.
-     */
-    def liftOne[I,O](f: I => O): Process[I,O] =
-      Await {
-        case Some(i) => emit(f(i))
-        case None => Halt()
-      }
-
-    def lift[I,O](f: I => O): Process[I,O] =
-      liftOne(f).repeat
-
-    /*
-     * As an example of `repeat`, here's a definition of `filter` that
-     * uses `repeat`.
-     */
-    def filter[I](f: I => Boolean): Process[I,I] =
-      Await[I,I] {
-        case Some(i) if f(i) => emit(i)
-        case _ => Halt()
-      }.repeat
-
-    /*
-     * Here's a typical `Process` definition that requires tracking some
-     * piece of state (in this case, the running total):
-     */
-    def sum: Process[Double,Double] = {
-      def go(acc: Double): Process[Double,Double] =
-        await(d => emit(d+acc, go(d+acc)))
-      go(0.0)
-    }
-
-    /*
-     * Exercise 1: Implement `take`, `drop`, `takeWhile`, and `dropWhile`.
-     */
-    def take[I](n: Int): Process[I,I] =
-      if (n <= 0) Halt()
-      else await(i => emit(i, take[I](n-1)))
-
-    def drop[I](n: Int): Process[I,I] =
-      if (n <= 0) id
-      else await(i => drop[I](n-1))
-
-    def takeWhile[I](f: I => Boolean): Process[I,I] =
-      await(i =>
-        if (f(i)) emit(i, takeWhile(f))
-        else      Halt())
-
-    def dropWhile[I](f: I => Boolean): Process[I,I] =
-      await(i =>
-        if (f(i)) dropWhile(f)
-        else      emit(i,id))
-
-    /* The identity `Process`, just repeatedly echos its input. */
-    def id[I]: Process[I,I] = lift(identity)
-
-    /*
-     * Exercise 2: Implement `count`.
-     *
-     * Here's one implementation, with three stages - we map all inputs
-     * to 1.0, compute a running sum, then finally convert the output
-     * back to `Int`. The three stages will be interleaved - as soon
-     * as the first element is examined, it will be converted to 1.0,
-     * then added to the running total, and then this running total
-     * will be converted back to `Int`, then the `Process` will examine
-     * the next element, and so on.
-     */
-    def count[I]: Process[I,Int] =
-      lift((i: I) => 1.0) |> sum |> lift(_.toInt)
-
-    /* For comparison, here is an explicit recursive implementation. */
-    def count2[I]: Process[I,Int] = {
-      def go(n: Int): Process[I,Int] =
-        await((i: I) => emit(n+1, go(n+1)))
-      go(0)
-    }
-
-    /*
-     * Exercise 3: Implement `mean`.
-     *
-     * This is an explicit recursive definition. We'll factor out a
-     * generic combinator shortly.
-     */
-    def mean: Process[Double,Double] = {
-      def go(sum: Double, count: Double): Process[Double,Double] =
-        await((d: Double) => emit((sum+d) / (count+1), go(sum+d,count+1)))
-      go(0.0, 0.0)
-    }
-
-    def loop[S,I,O](z: S)(f: (I,S) => (O,S)): Process[I,O] =
-      await((i: I) => f(i,z) match {
-        case (o,s2) => emit(o, loop(s2)(f))
-      })
-
-    /* Exercise 4: Implement `sum` and `count` in terms of `loop` */
-
-    def sum2: Process[Double,Double] =
-      loop(0.0)((d:Double, acc) => (acc+d,acc+d))
-
-    def count3[I]: Process[I,Int] =
-      loop(0)((_:I,n) => (n+1,n+1))
-
-    /*
-     * Exercise 7: Can you think of a generic combinator that would
-     * allow for the definition of `mean` in terms of `sum` and
-     * `count`?
-     *
-     * Yes, it is `zip`, which feeds the same input to two processes.
-     * The implementation is a bit tricky, as we have to make sure
-     * that input gets fed to both `p1` and `p2`.
-     */
-    def zip[A,B,C](p1: Process[A,B], p2: Process[A,C]): Process[A,(B,C)] =
-      (p1, p2) match {
-        case (Halt(), _) => Halt()
-        case (_, Halt()) => Halt()
-        case (Emit(b, t1), Emit(c, t2)) => Emit((b,c), zip(t1, t2))
-        case (Await(recv1), _) =>
-          Await((oa: Option[A]) => zip(recv1(oa), feed(oa)(p2)))
-        case (_, Await(recv2)) =>
-          Await((oa: Option[A]) => zip(feed(oa)(p1), recv2(oa)))
-      }
-
-    def feed[A,B](oa: Option[A])(p: Process[A,B]): Process[A,B] =
-      p match {
-        case Halt() => p
-        case Emit(h,t) => Emit(h, feed(oa)(t))
-        case Await(recv) => recv(oa)
-      }
-
-    /*
-     * Using zip, we can then define `mean`. Again, this definition
-     * operates in a single pass.
-     */
-    val mean2 = (sum zip count) |> lift { case (s,n) => s / n }
-
-    /*
-     * Exercise 6: Implement `zipWithIndex`.
-     *
-     * See definition on `Process` above.
-     */
-
-    /*
-     * Exercise 8: Implement `exists`
-     *
-     * We choose to emit all intermediate values, and not halt.
-     * See `existsResult` below for a trimmed version.
-     */
-    def exists[I](f: I => Boolean): Process[I,Boolean] =
-      lift(f) |> any
-
-    /* Emits whether a `true` input has ever been received. */
-    def any: Process[Boolean,Boolean] =
-      loop(false)((b:Boolean,s) => (s || b, s || b))
-
-    /* A trimmed `exists`, containing just the final result. */
-    def existsResult[I](f: I => Boolean) =
-      exists(f) |> takeThrough(!_) |> dropWhile(!_) |> echo.orElse(emit(false))
-
-    /*
-     * Like `takeWhile`, but includes the first element that tests
-     * false.
-     */
-    def takeThrough[I](f: I => Boolean): Process[I,I] =
-      takeWhile(f) ++ echo
-
-    /* Awaits then emits a single value, then halts. */
-    def echo[I]: Process[I,I] = await(i => emit(i))
-
-    def skip[I,O]: Process[I,O] = await(i => Halt())
-    def ignore[I,O]: Process[I,O] = skip.repeat
-
-    def terminated[I]: Process[I,Option[I]] =
-      await((i: I) => emit(Some(i), terminated[I]), emit(None))
-
-    def processFile[A,B](f: java.io.File,
-                         p: Process[String, A],
-                         z: B)(g: (B, A) => B): IO[B] = IO {
-      @annotation.tailrec
-      def go(ss: Iterator[String], cur: Process[String, A], acc: B): B =
-        cur match {
-          case Halt() => acc
-          case Await(recv) =>
-            val next = if (ss.hasNext) recv(Some(ss.next))
-                       else recv(None)
-            go(ss, next, acc)
-          case Emit(h, t) => go(ss, t, g(acc, h))
-        }
-      val s = io.Source.fromFile(f)
-      try go(s.getLines, p, z)
-      finally s.close
-    }
-
-    /*
-     * Exercise 9: Write a program that reads degrees fahrenheit as `Double` values from a file,
-     * converts each temperature to celsius, and writes results to another file.
-     */
-
-    // This process defines the here is core logic, a transducer that converts input lines
-    // (assumed to be temperatures in degrees fahrenheit) to output lines (temperatures in
-    // degress celsius). Left as an exercise to supply another wrapper like `processFile`
-    // to actually do the IO and drive the process.
-    def convertFahrenheit: Process[String,String] =
-      filter((line: String) => !line.startsWith("#")) |>
-      filter(line => line.trim.nonEmpty) |>
-      lift(line => toCelsius(line.toDouble).toString)
-
-    def toCelsius(fahrenheit: Double): Double =
-      (5.0 / 9.0) * (fahrenheit - 32.0)
-  }
-}
-
-object GeneralizedStreamTransducers {
-
-                            /*
-
-  Our generalized process type is parameterized on the protocol used for
-  communicating with the driver. This works similarly to the `IO` type
-  we defined in chapter 13. The `Await` constructor emits a request of
-  type `F[A]`, and receives a response of type `Either[Throwable,A]`:
-
-    trait Process[F,A]
-    case class Await[F[_],A,O](
-      req: F[A],
-      recv: Either[Throwable,A] => Process[F,O]) extends Process[F,O]
-    case class Halt[F[_],O](err: Throwable) extends Process[F,O]
-    case class Emit[F[_],O](head: O, tail: Process[F,O]) extends Process[F,O]
-
-  The `Await` constructor may now receive a successful result or an error.
-
-  The `Halt` constructor now has a _reason_ for termination, which may be
-  either normal termination indicated by the special exception `End`,
-  forceful terimation, indicated by the special exception `Kill`,
-  or some other error.
-
-  We'll use the improved `Await` and `Halt` cases together to ensure
-  that all resources get released, even in the event of exceptions.
-
-                             */
-
-  trait Process[F[_],O] {
-    import Process._
-
-    /*
-     * Many of the same operations can be defined for this generalized
-     * `Process` type, regardless of the choice of `F`.
-     */
-
-    def map[O2](f: O => O2): Process[F,O2] = this match {
-      case Await(req,recv) =>
-        Await(req, recv andThen (_ map f))
-      case Emit(h, t) => Try { Emit(f(h), t map f) }
-      case Halt(err) => Halt(err)
-    }
-
-    def ++(p: => Process[F,O]): Process[F,O] =
-      this.onHalt {
-        case End => Try(p) // we consult `p` only on normal termination
-        case err => Halt(err)
-      }
-
-    /*
-     * Like `++`, but _always_ runs `p`, even if `this` halts with an error.
-     */
-    def onComplete(p: => Process[F,O]): Process[F,O] =
-      this.onHalt {
-        case End => p.asFinalizer
-        case err => p.asFinalizer ++ Halt(err) // we always run `p`, but preserve any errors
-      }
-
-    def asFinalizer: Process[F,O] = this match {
-      case Emit(h, t) => Emit(h, t.asFinalizer)
-      case Halt(e) => Halt(e)
-      case Await(req,recv) => await(req) {
-        case Left(Kill) => this.asFinalizer
-        case x => recv(x)
-      }
-    }
-
-    def onHalt(f: Throwable => Process[F,O]): Process[F,O] = this match {
-      case Halt(e) => Try(f(e))
-      case Emit(h, t) => Emit(h, t.onHalt(f))
-      case Await(req,recv) => Await(req, recv andThen (_.onHalt(f)))
-    }
-
-    /*
-     * Anywhere we _call_ `f`, we catch exceptions and convert them to `Halt`.
-     * See the helper function `Try` defined below.
-     */
-    def flatMap[O2](f: O => Process[F,O2]): Process[F,O2] =
-      this match {
-        case Halt(err) => Halt(err)
-        case Emit(o, t) => Try(f(o)) ++ t.flatMap(f)
-        case Await(req,recv) =>
-          Await(req, recv andThen (_ flatMap f))
-      }
-
-    def repeat: Process[F,O] =
-      this ++ this.repeat
-
-    def repeatNonempty: Process[F,O] = {
-      val cycle = (this.map(o => Some(o): Option[O]) ++ emit(None)).repeat
-      // cut off the cycle when we see two `None` values in a row, as this
-      // implies `this` has produced no values during an iteration
-      val trimmed = cycle |> window2 |> (takeWhile {
-        case (Some(None), None) => false
-        case _ => true
-      })
-      trimmed.map(_._2).flatMap {
-        case None => Halt(End)
-        case Some(o) => emit(o)
-      }
-    }
-
-    /*
-     * Exercise 10: This function is defined only if given a `MonadCatch[F]`.
-     * Unlike the simple `runLog` interpreter defined in the companion object
-     * below, this is not tail recursive and responsibility for stack safety
-     * is placed on the `Monad` instance.
-     */
-    def runLog(implicit F: MonadCatch[F]): F[IndexedSeq[O]] = {
-      def go(cur: Process[F,O], acc: IndexedSeq[O]): F[IndexedSeq[O]] =
-        cur match {
-          case Emit(h,t) => go(t, acc :+ h)
-          case Halt(End) => F.unit(acc)
-          case Halt(err) => F.fail(err)
-          case Await(req,recv) => F.flatMap (F.attempt(req)) { e => go(Try(recv(e)), acc) }
-        }
-      go(this, IndexedSeq())
-    }
-
-    /*
-     * We define `Process1` as a type alias - see the companion object
-     * for `Process` below. Using that, we can then define `|>` once
-     * more. The definition is extremely similar to our previous
-     * definition. We again use the helper function, `feed`, to take
-     * care of the case where `this` is emitting values while `p2`
-     * is awaiting these values.
-     *
-     * The one subtlety is we make sure that if `p2` halts, we
-     * `kill` this process, giving it a chance to run any cleanup
-     * actions (like closing file handles, etc).
-     */
-    def |>[O2](p2: Process1[O,O2]): Process[F,O2] = {
-      p2 match {
-        case Halt(e) => this.kill onHalt { e2 => Halt(e) ++ Halt(e2) }
-        case Emit(h, t) => Emit(h, this |> t)
-        case Await(req,recv) => this match {
-          case Halt(err) => Halt(err) |> recv(Left(err))
-          case Emit(h,t) => t |> Try(recv(Right(h)))
-          case Await(req0,recv0) => await(req0)(recv0 andThen (_ |> p2))
-        }
-      }
-    }
-
-    @annotation.tailrec
-    final def kill[O2]: Process[F,O2] = this match {
-      case Await(req,recv) => recv(Left(Kill)).drain.onHalt {
-        case Kill => Halt(End) // we convert the `Kill` exception back to normal termination
-        case e => Halt(e)
-      }
-      case Halt(e) => Halt(e)
-      case Emit(h, t) => t.kill
-    }
-
-    /** Alias for `this |> p2`. */
-    def pipe[O2](p2: Process1[O,O2]): Process[F,O2] =
-      this |> p2
-
-    final def drain[O2]: Process[F,O2] = this match {
-      case Halt(e) => Halt(e)
-      case Emit(h, t) => t.drain
-      case Await(req,recv) => Await(req, recv andThen (_.drain))
-    }
-
-    def filter(f: O => Boolean): Process[F,O] =
-      this |> Process.filter(f)
-
-    def take(n: Int): Process[F,O] =
-      this |> Process.take(n)
-
-    def once: Process[F,O] = take(1)
-
-    /*
-     * Use a `Tee` to interleave or combine the outputs of `this` and
-     * `p2`. This can be used for zipping, interleaving, and so forth.
-     * Nothing requires that the `Tee` read elements from each
-     * `Process` in lockstep. It could read fifty elements from one
-     * side, then two elements from the other, then combine or
-     * interleave these values in some way, etc.
-     *
-     * This definition uses two helper functions, `feedL` and `feedR`,
-     * which feed the `Tee` in a tail-recursive loop as long as
-     * it is awaiting input.
-     */
-    def tee[O2,O3](p2: Process[F,O2])(t: Tee[O,O2,O3]): Process[F,O3] = {
-      t match {
-        case Halt(e) => this.kill onComplete p2.kill onComplete Halt(e)
-        case Emit(h,t) => Emit(h, (this tee p2)(t))
-        case Await(side, recv) => side.get match {
-          case Left(isO) => this match {
-            case Halt(e) => p2.kill onComplete Halt(e)
-            case Emit(o,ot) => (ot tee p2)(Try(recv(Right(o))))
-            case Await(reqL, recvL) =>
-              await(reqL)(recvL andThen (this2 => this2.tee(p2)(t)))
-          }
-          case Right(isO2) => p2 match {
-            case Halt(e) => this.kill onComplete Halt(e)
-            case Emit(o2,ot) => (this tee ot)(Try(recv(Right(o2))))
-            case Await(reqR, recvR) =>
-              await(reqR)(recvR andThen (p3 => this.tee(p3)(t)))
-          }
-        }
-      }
-    }
-
-    def zipWith[O2,O3](p2: Process[F,O2])(f: (O,O2) => O3): Process[F,O3] =
-      (this tee p2)(Process.zipWith(f))
-
-    def zip[O2](p2: Process[F,O2]): Process[F,(O,O2)] =
-      zipWith(p2)((_,_))
-
-    def to[O2](sink: Sink[F,O]): Process[F,Unit] =
-      join { (this zipWith sink)((o,f) => f(o)) }
-
-    def through[O2](p2: Channel[F, O, O2]): Process[F,O2] =
-      join { (this zipWith p2)((o,f) => f(o)) }
-  }
-
-  object Process {
-    case class Await[F[_],A,O](
-      req: F[A],
-      recv: Either[Throwable,A] => Process[F,O]) extends Process[F,O]
-
-    case class Emit[F[_],O](
-      head: O,
-      tail: Process[F,O]) extends Process[F,O]
-
-    case class Halt[F[_],O](err: Throwable) extends Process[F,O]
-
-    def emit[F[_],O](
-        head: O,
-        tail: Process[F,O] = Halt[F,O](End)): Process[F,O] =
-      Emit(head, tail)
-
-    def await[F[_],A,O](req: F[A])(recv: Either[Throwable,A] => Process[F,O]): Process[F,O] =
-      Await(req, recv)
-
-    /**
-     * Helper function to safely produce `p`, or gracefully halt
-     * with an error if an exception is thrown.
-     */
-    def Try[F[_],O](p: => Process[F,O]): Process[F,O] =
-      try p
-      catch { case e: Throwable => Halt(e) }
-
-    /*
-     * Safely produce `p`, or run `cleanup` and halt gracefully with the
-     * exception thrown while evaluating `p`.
-     */
-    def TryOr[F[_],O](p: => Process[F,O])(cleanup: Process[F,O]): Process[F,O] =
-      try p
-      catch { case e: Throwable => cleanup ++ Halt(e) }
-
-    /*
-     * Safely produce `p`, or run `cleanup` or `fallback` if an exception
-     * occurs while evaluating `p`.
-     */
-    def TryAwait[F[_],O](p: => Process[F,O])(fallback: Process[F,O], cleanup: Process[F,O]): Process[F,O] =
-      try p
-      catch {
-        case End => fallback
-        case e: Throwable => cleanup ++ Halt(e)
-      }
-
-    /* Our generalized `Process` type can represent sources! */
-
-    import fpinscala.iomonad.IO
-
-    /* Special exception indicating normal termination */
-    case object End extends Exception
-
-    /* Special exception indicating forceful termination */
-    case object Kill extends Exception
-
-    /*
-     * A `Process[F,O]` where `F` is a monad like `IO` can be thought of
-     * as a source.
-     */
-
-    /*
-     * Here is a simple tail recursive function to collect all the
-     * output of a `Process[IO,O]`. Notice we are using the fact
-     * that `IO` can be `run` to produce either a result or an
-     * exception.
-     */
-    def runLog[O](src: Process[IO,O]): IO[IndexedSeq[O]] = IO {
-      val E = java.util.concurrent.Executors.newFixedThreadPool(4)
-      @annotation.tailrec
-      def go(cur: Process[IO,O], acc: IndexedSeq[O]): IndexedSeq[O] =
-        cur match {
-          case Emit(h,t) => go(t, acc :+ h)
-          case Halt(End) => acc
-          case Halt(err) => throw err
-          case Await(req,recv) =>
-            val next =
-              try recv(Right(fpinscala.iomonad.unsafePerformIO(req)(E)))
-              catch { case err: Throwable => recv(Left(err)) }
-            go(next, acc)
-        }
-      try go(src, IndexedSeq())
-      finally E.shutdown
-    }
-
-    /*
-     * We can write a version of collect that works for any `Monad`.
-     * See the definition in the body of `Process`.
-     */
-
-    import java.io.{BufferedReader,FileReader}
-    val p: Process[IO, String] =
-      await(IO(new BufferedReader(new FileReader("lines.txt")))) {
-        case Right(b) =>
-          lazy val next: Process[IO,String] = await(IO(b.readLine)) {
-            case Left(e) => await(IO(b.close))(_ => Halt(e))
-            case Right(line) => Emit(line, next)
-          }
-          next
-        case Left(e) => Halt(e)
-      }
-
-    /*
-     * Generic combinator for producing a `Process[IO,O]` from some
-     * effectful `O` source. The source is tied to some resource,
-     * `R` (like a file handle) that we want to ensure is released.
-     * See `lines` below for an example use.
-     */
-    def resource[R,O](acquire: IO[R])(
-                      use: R => Process[IO,O])(
-                      release: R => Process[IO,O]): Process[IO,O] =
-      eval(acquire) flatMap { r => use(r).onComplete(release(r)) }
-
-    /*
-     * Like `resource`, but `release` is a single `IO` action.
-     */
-    def resource_[R,O](acquire: IO[R])(
-                       use: R => Process[IO,O])(
-                       release: R => IO[Unit]): Process[IO,O] =
-      resource(acquire)(use)(release andThen (eval_[IO,Unit,O]))
-
-    /*
-     * Create a `Process[IO,O]` from the lines of a file, using
-     * the `resource` combinator above to ensure the file is closed
-     * when processing the stream of lines is finished.
-     */
-    def lines(filename: String): Process[IO,String] =
-      resource
-        { IO(io.Source.fromFile(filename)) }
-        { src =>
-            lazy val iter = src.getLines // a stateful iterator
-            def step = if (iter.hasNext) Some(iter.next) else None
-            lazy val lines: Process[IO,String] = eval(IO(step)).flatMap {
-              case None => Halt(End)
-              case Some(line) => Emit(line, lines)
-            }
-            lines
-        }
-        { src => eval_ { IO(src.close) } }
-
-    /* Exercise 11: Implement `eval`, `eval_`, and use these to implement `lines`. */
-    def eval[F[_],A](a: F[A]): Process[F,A] =
-      await[F,A,A](a) {
-        case Left(err) => Halt(err)
-        case Right(a) => Emit(a, Halt(End))
-      }
-
-    /* Evaluate the action purely for its effects. */
-    def eval_[F[_],A,B](a: F[A]): Process[F,B] =
-      eval[F,A](a).drain[B]
-
-    /* Helper function with better type inference. */
-    def evalIO[A](a: IO[A]): Process[IO,A] =
-      eval[IO,A](a)
-
-    /*
-     * We now have nice, resource safe effectful sources, but we don't
-     * have any way to transform them or filter them. Luckily we can
-     * still represent the single-input `Process` type we introduced
-     * earlier, which we'll now call `Process1`.
-     */
-
-    case class Is[I]() {
-      sealed trait f[X]
-      val Get = new f[I] {}
-    }
-    def Get[I] = Is[I]().Get
-
-    type Process1[I,O] = Process[Is[I]#f, O]
-
-    /* Some helper functions to improve type inference. */
-
-    def await1[I,O](
-        recv: I => Process1[I,O],
-        fallback: => Process1[I,O] = halt1[I,O]): Process1[I, O] =
-      Await(Get[I], (e: Either[Throwable,I]) => e match {
-        case Left(End) => fallback
-        case Left(err) => Halt(err)
-        case Right(i) => Try(recv(i))
-      })
-
-    def emit1[I,O](h: O, tl: Process1[I,O] = halt1[I,O]): Process1[I,O] =
-      emit(h, tl)
-
-    def halt1[I,O]: Process1[I,O] = Halt[Is[I]#f, O](End)
-
-    def lift[I,O](f: I => O): Process1[I,O] =
-      await1[I,O]((i:I) => emit(f(i))) repeat
-
-    def filter[I](f: I => Boolean): Process1[I,I] =
-      await1[I,I](i => if (f(i)) emit(i) else halt1) repeat
-
-    // we can define take, takeWhile, and so on as before
-
-    def take[I](n: Int): Process1[I,I] =
-      if (n <= 0) halt1
-      else await1[I,I](i => emit(i, take(n-1)))
-
-    def takeWhile[I](f: I => Boolean): Process1[I,I] =
-      await1(i =>
-        if (f(i)) emit(i, takeWhile(f))
-        else      halt1)
-
-    def dropWhile[I](f: I => Boolean): Process1[I,I] =
-      await1(i =>
-        if (f(i)) dropWhile(f)
-        else      emit(i,id))
-
-    def id[I]: Process1[I,I] =
-      await1((i: I) => emit(i, id))
-
-    def window2[I]: Process1[I,(Option[I],I)] = {
-      def go(prev: Option[I]): Process1[I,(Option[I],I)] =
-        await1[I,(Option[I],I)](i => emit(prev -> i) ++ go(Some(i)))
-      go(None)
-    }
-
-    /** Emits `sep` in between each input received. */
-    def intersperse[I](sep: I): Process1[I,I] =
-      await1[I,I](i => emit1(i) ++ id.flatMap(i => emit1(sep) ++ emit1(i)))
-
-                            /*
-
-    We sometimes need to construct a `Process` that will pull values
-    from multiple input sources. For instance, suppose we want to
-    'zip' together two files, `f1.txt` and `f2.txt`, combining
-    corresponding lines in some way. Using the same trick we used for
-    `Process1`, we can create a two-input `Process` which can request
-    values from either the 'left' stream or the 'right' stream. We'll
-    call this a `Tee`, after the letter 'T', which looks like a
-    little diagram of two inputs being combined into one output.
-
-                             */
-
-    case class T[I,I2]() {
-      sealed trait f[X] { def get: Either[I => X, I2 => X] }
-      val L = new f[I] { def get = Left(identity) }
-      val R = new f[I2] { def get = Right(identity) }
-    }
-    def L[I,I2] = T[I,I2]().L
-    def R[I,I2] = T[I,I2]().R
-
-    type Tee[I,I2,O] = Process[T[I,I2]#f, O]
-
-    /* Again some helper functions to improve type inference. */
-
-    def haltT[I,I2,O]: Tee[I,I2,O] =
-      Halt[T[I,I2]#f,O](End)
-
-    def awaitL[I,I2,O](recv: I => Tee[I,I2,O],
-                       fallback: => Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
-      await[T[I,I2]#f,I,O](L) {
-        case Left(End) => fallback
-        case Left(err) => Halt(err)
-        case Right(a) => Try(recv(a))
-      }
-
-    def awaitR[I,I2,O](recv: I2 => Tee[I,I2,O],
-                       fallback: => Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
-      await[T[I,I2]#f,I2,O](R) {
-        case Left(End) => fallback
-        case Left(err) => Halt(err)
-        case Right(a) => Try(recv(a))
-      }
-
-    def emitT[I,I2,O](h: O, tl: Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
-      emit(h, tl)
-
-    def zipWith[I,I2,O](f: (I,I2) => O): Tee[I,I2,O] =
-      awaitL[I,I2,O](i  =>
-      awaitR        (i2 => emitT(f(i,i2)))) repeat
-
-    def zip[I,I2]: Tee[I,I2,(I,I2)] = zipWith((_,_))
-
-    /* Ignores all input from left. */
-    def passR[I,I2]: Tee[I,I2,I2] = awaitR(emitT(_, passR))
-
-    /* Ignores input from the right. */
-    def passL[I,I2]: Tee[I,I2,I] = awaitL(emitT(_, passL))
-
-    /* Alternate pulling values from the left and the right inputs. */
-    def interleaveT[I]: Tee[I,I,I] =
-      awaitL[I,I,I](i =>
-      awaitR       (i2 => emitT(i) ++ emitT(i2))) repeat
-
-                            /*
-
-    Our `Process` type can also represent effectful sinks (like a file).
-    A `Sink` is simply a source of effectful functions! See the
-    definition of `to` in `Process` for an example of how to feed a
-    `Process` to a `Sink`.
-
-                             */
-
-    type Sink[F[_],O] = Process[F, O => Process[F,Unit]]
-
-    import java.io.FileWriter
-
-    /* A `Sink` which writes input strings to the given file. */
-    def fileW(file: String, append: Boolean = false): Sink[IO,String] =
-      resource[FileWriter, String => Process[IO,Unit]]
-        { IO { new FileWriter(file, append) }}
-        { w => constant { (s: String) => eval[IO,Unit](IO(w.write(s))) }}
-        { w => eval_(IO(w.close)) }
-
-    /* The infinite, constant stream. */
-    def constant[A](a: A): Process[IO,A] =
-      eval(IO(a)).flatMap { a => Emit(a, constant(a)) }
-
-    /* Exercise 12: Implement `join`. Notice this is the standard monadic combinator! */
-    def join[F[_],A](p: Process[F,Process[F,A]]): Process[F,A] =
-      p.flatMap(pa => pa)
-
-    /*
-     * An example use of the combinators we have so far: incrementally
-     * convert the lines of a file from fahrenheit to celsius.
-     */
-
-    import fpinscala.iomonad.IO0.fahrenheitToCelsius
-
-    val converter: Process[IO,Unit] =
-      lines("fahrenheit.txt").
-      filter(line => !line.startsWith("#") && !line.trim.isEmpty).
-      map(line => fahrenheitToCelsius(line.toDouble).toString).
-      pipe(intersperse("\n")).
-      to(fileW("celsius.txt")).
-      drain
-
-                            /*
-
-    More generally, we can feed a `Process` through an effectful
-    channel which returns a value other than `Unit`.
-
-                             */
-
-    type Channel[F[_],I,O] = Process[F, I => Process[F,O]]
-
-    /*
-     * Here is an example, a JDBC query runner which returns the
-     * stream of rows from the result set of the query. We have
-     * the channel take a `Connection => PreparedStatement` as
-     * input, so code that uses this channel does not need to be
-     * responsible for knowing how to obtain a `Connection`.
-     */
-    import java.sql.{Connection, PreparedStatement, ResultSet}
-
-    def query(conn: IO[Connection]):
-        Channel[IO, Connection => PreparedStatement, Map[String,Any]] =
-      resource_
-        { conn }
-        { conn => constant { (q: Connection => PreparedStatement) =>
-          resource_
-            { IO {
-                val rs = q(conn).executeQuery
-                val ncols = rs.getMetaData.getColumnCount
-                val cols = (1 to ncols).map(rs.getMetaData.getColumnName)
-                (rs, cols)
-            }}
-            { case (rs, cols) =>
-                def step =
-                  if (!rs.next) None
-                  else Some(cols.map(c => (c, rs.getObject(c): Any)).toMap)
-                lazy val rows: Process[IO,Map[String,Any]] =
-                  eval(IO(step)).flatMap {
-                    case None => Halt(End)
-                    case Some(row) => Emit(row, rows)
-                  }
-                rows
-            }
-            { p => IO { p._1.close } } // close the ResultSet
-        }}
-        { c => IO(c.close) }
-
-    /*
-     * We can allocate resources dynamically when defining a `Process`.
-     * As an example, this program reads a list of filenames to process
-     * _from another file_, opening each file, processing it and closing
-     * it promptly.
-     */
-
-    val convertAll: Process[IO,Unit] = (for {
-      out <- fileW("celsius.txt").once
-      file <- lines("fahrenheits.txt")
-      _ <- lines(file).
-           map(line => fahrenheitToCelsius(line.toDouble)).
-           flatMap(celsius => out(celsius.toString))
-    } yield ()) drain
-
-    /*
-     * Just by switching the order of the `flatMap` calls, we can output
-     * to multiple files.
-     */
-    val convertMultisink: Process[IO,Unit] = (for {
-      file <- lines("fahrenheits.txt")
-      _ <- lines(file).
-           map(line => fahrenheitToCelsius(line.toDouble)).
-           map(_ toString).
-           to(fileW(file + ".celsius"))
-    } yield ()) drain
-
-    /*
-     * We can attach filters or other transformations at any point in the
-     * program, for example:
-     */
-    val convertMultisink2: Process[IO,Unit] = (for {
-      file <- lines("fahrenheits.txt")
-      _ <- lines(file).
-           filter(!_.startsWith("#")).
-           map(line => fahrenheitToCelsius(line.toDouble)).
-           filter(_ > 0). // ignore below zero temperatures
-           map(_ toString).
-           to(fileW(file + ".celsius"))
-    } yield ()) drain
-  }
-}
-
-object ProcessTest extends App {
-  import GeneralizedStreamTransducers._
-  import fpinscala.iomonad.IO
-  import Process._
-
-  val p = eval(IO { println("woot"); 1 }).repeat
-  val p2 = eval(IO { println("cleanup"); 2 } ).onHalt {
-    case Kill => println { "cleanup was killed, instead of bring run" }; Halt(Kill)
-    case e => Halt(e)
-  }
-
-  println { Process.runLog { p2.onComplete(p2).onComplete(p2).take(1).take(1) } }
-  println { Process.runLog(converter) }
-  // println { Process.collect(Process.convertAll) }
-}
diff --git a/answers/src/main/scala/fpinscala/streamingio/These.scala b/answers/src/main/scala/fpinscala/streamingio/These.scala
deleted file mode 100644
index ade1a0b..0000000
--- a/answers/src/main/scala/fpinscala/streamingio/These.scala
+++ /dev/null
@@ -1,48 +0,0 @@
-package fpinscala.streamingio
-
-import language.postfixOps
-
-/* Data type representing either A, B, or both A and B. */
-trait These[+A,+B] {
-  import These._
-
-  def bimap[A2,B2](f: A => A2, g: B => B2): These[A2,B2] = 
-    this match {
-      case This(a) => This(f(a)) 
-      case That(b) => That(g(b)) 
-      case Both(a,b) => Both(f(a), g(b)) 
-    }
-
-  def mapL[A2,B2>:B](f: A => A2): These[A2,B2] = 
-    bimap(f, identity)
-
-  def mapR[A2>:A,B2](f: B => B2): These[A2,B2] = 
-    bimap(identity, f)
-
-  def isBoth = this match {
-    case Both(_,_) => true
-    case _ => false
-  }
-}
-
-object These {
-  case class This[+A](a: A) extends These[A,Nothing]
-  case class That[+B](b: B) extends These[Nothing,B]
-  case class Both[+A,+B](a: A, b: B) extends These[A,B]
-
-  def zipAll[A,B,C](a: Seq[A], b: Seq[B]): Stream[These[A,B]] = 
-    if (a isEmpty) b.toStream.map(That(_))
-    else if (b isEmpty) a.toStream.map(This(_))
-    else Both(a.head, b.head) #:: zipAll(a.tail, b.tail)
-  
-  /* 
-   * Zips together the two `Seq`s, returning the remaining elemnts 
-   * of each (possibly empty). 
-   */
-  def zipResidual[A,B,C](a: Seq[A], b: Seq[B]): 
-     (Seq[(A,B)], Seq[A], Seq[B]) = {
-    val z = a zip b
-    val len = z.length
-    (z, a drop len, b drop len)
-  }
-}
diff --git a/answers/src/main/scala/fpinscala/testing/Exhaustive.scala b/answers/src/main/scala/fpinscala/testing/Exhaustive.scala
deleted file mode 100644
index 476d71a..0000000
--- a/answers/src/main/scala/fpinscala/testing/Exhaustive.scala
+++ /dev/null
@@ -1,419 +0,0 @@
-package fpinscala.testing.exhaustive
-
-import language.implicitConversions
-import language.postfixOps
-
-/*
-This source file contains the answers to the last two exercises in the section
-"Test Case Minimization" of chapter 8 on property-based testing.
-
-The Gen data type in this file incorporates exhaustive checking of finite domains.
-*/
-
-import fpinscala.laziness.{Stream,Cons,Empty}
-import fpinscala.state._
-import fpinscala.parallelism._
-import fpinscala.parallelism.Par.Par
-import Gen._
-import Prop._
-import Status._
-import java.util.concurrent.{Executors,ExecutorService}
-
-
-case class Prop(run: (MaxSize,TestCases,RNG) => Result) {
-  def &&(p: Prop) = Prop {
-    (max,n,rng) => run(max,n,rng) match {
-      case Right((a,n)) => p.run(max,n,rng).right.map { case (s,m) => (s,n+m) }
-      case l => l
-    }
-  }
-  def ||(p: Prop) = Prop {
-    (max,n,rng) => run(max,n,rng) match {
-      case Left(msg) => p.tag(msg).run(max,n,rng)
-      case r => r
-    }
-  }
-  /* This is rather simplistic - in the event of failure, we simply prepend
-   * the given message on a newline in front of the existing message.
-   */
-  def tag(msg: String) = Prop {
-    (max,n,rng) => run(max,n,rng) match {
-      case Left(e) => Left(msg + "\n" + e)
-      case r => r
-    }
-  }
-}
-
-object Prop {
-  type TestCases = Int
-  type MaxSize = Int
-  type FailedCase = String
-  type Result = Either[FailedCase,(Status,TestCases)]
-  def forAll[A](a: Gen[A])(f: A => Boolean): Prop = Prop {
-    (n,rng) => {
-      def go(i: Int, j: Int, s: Stream[Option[A]], onEnd: Int => Result): Result =
-        if (i == j) Right((Unfalsified, i))
-        else s match {
-          case Cons(h,t) => h() match {
-            case Some(h) =>
-              try {
-                if (f(h)) go(i+1,j,t(),onEnd)
-                else Left(h.toString) }
-              catch { case e: Exception => Left(buildMsg(h, e)) }
-            case None => Right((Unfalsified,i))
-          }
-          case _ => onEnd(i)
-        }
-      go(0, n/3, a.exhaustive, i => Right((Proven, i))) match {
-        case Right((Unfalsified,_)) =>
-          val rands = randomStream(a)(rng).map(Some(_))
-          go(n/3, n, rands, i => Right((Unfalsified, i)))
-        case s => s // If proven or failed, stop immediately
-      }
-    }
-  }
-
-  def buildMsg[A](s: A, e: Exception): String =
-    "test case: " + s + "\n" +
-    "generated an exception: " + e.getMessage + "\n" +
-    "stack trace:\n" + e.getStackTrace.mkString("\n")
-
-  def apply(f: (TestCases,RNG) => Result): Prop =
-    Prop { (_,n,rng) => f(n,rng) }
-
-  /* We pattern match on the `SGen`, and delegate to our `Gen` version of `forAll`
-   * if `g` is unsized; otherwise, we call the sized version of `forAll` (below).
-   */
-  def forAll[A](g: SGen[A])(f: A => Boolean): Prop = g match {
-    case Unsized(g2) => forAll(g2)(f)
-    case Sized(gs) => forAll(gs)(f)
-  }
-
-  /* The sized case of `forAll` is as before, though we convert from `Proven` to
-   * `Exhausted`. A sized generator can never be proven, since there are always
-   * larger-sized tests that were not run which may have failed.
-   */
-  def forAll[A](g: Int => Gen[A])(f: A => Boolean): Prop = Prop {
-    (max,n,rng) =>
-      val casesPerSize = n / max + 1
-      val props: List[Prop] =
-        Stream.from(0).take(max+1).map(i => forAll(g(i))(f)).toList
-      val p: Prop = props.map(p => Prop((max,n,rng) => p.run(max,casesPerSize,rng))).
-            reduceLeft(_ && _)
-      p.run(max,n,rng).right.map {
-        case (Proven,n) => (Exhausted,n)
-        case x => x
-      }
-  }
-
-  def run(p: Prop,
-          maxSize: Int = 100, // A default argument of `200`
-          testCases: Int = 100,
-          rng: RNG = RNG.Simple(System.currentTimeMillis)): Unit = {
-    p.run(maxSize, testCases, rng) match {
-      case Left(msg) => println("! test failed:\n" + msg)
-      case Right((Unfalsified,n)) =>
-        println("+ property unfalsified, ran " + n + " tests")
-      case Right((Proven,n)) =>
-        println("+ property proven, ran " + n + " tests")
-      case Right((Exhausted,n)) =>
-        println("+ property unfalsified up to max size, ran " +
-                 n + " tests")
-    }
-  }
-
-  val ES: ExecutorService = Executors.newCachedThreadPool
-  val p1 = Prop.forAll(Gen.unit(Par.unit(1)))(i =>
-    Par.map(i)(_ + 1)(ES).get == Par.unit(2)(ES).get)
-
-  def check(p: => Boolean): Prop = // Note that we are non-strict here
-    forAll(unit(()))(_ => p)
-
-  val p2 = check {
-    val p = Par.map(Par.unit(1))(_ + 1)
-    val p2 = Par.unit(2)
-    p(ES).get == p2(ES).get
-  }
-
-  def equal[A](p: Par[A], p2: Par[A]): Par[Boolean] =
-    Par.map2(p,p2)(_ == _)
-
-  val p3 = check {
-    equal (
-      Par.map(Par.unit(1))(_ + 1),
-      Par.unit(2)
-    ) (ES) get
-  }
-
-  val S = weighted(
-    choose(1,4).map(Executors.newFixedThreadPool) -> .75,
-    unit(Executors.newCachedThreadPool) -> .25) // `a -> b` is syntax sugar for `(a,b)`
-
-  def forAllPar[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
-    forAll(S.map2(g)((_,_))) { case (s,a) => f(a)(s).get }
-
-  def checkPar(p: Par[Boolean]): Prop =
-    forAllPar(Gen.unit(()))(_ => p)
-
-  def forAllPar2[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
-    forAll(S ** g) { case (s,a) => f(a)(s).get }
-
-  def forAllPar3[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
-    forAll(S ** g) { case s ** a => f(a)(s).get }
-
-  val pint = Gen.choose(0,10) map (Par.unit(_))
-  val p4 =
-    forAllPar(pint)(n => equal(Par.map(n)(y => y), n))
-
-  val forkProp = Prop.forAllPar(pint2)(i => equal(Par.fork(i), i)) tag "fork"
-}
-
-sealed trait Status {}
-
-object Status {
-  case object Exhausted extends Status
-  case object Proven extends Status
-  case object Unfalsified extends Status
-}
-
-/*
-The `Gen` type now has a random generator as well as an exhaustive stream.
-Infinite domains will simply generate infinite streams of None.
-A finite domain is exhausted when the stream reaches empty.
-*/
-case class Gen[+A](sample: State[RNG,A], exhaustive: Stream[Option[A]]) {
-  def map[B](f: A => B): Gen[B] =
-    Gen(sample.map(f), exhaustive.map(_.map(f)))
-
-  def map2[B,C](g: Gen[B])(f: (A,B) => C): Gen[C] =
-    Gen(sample.map2(g.sample)(f),
-        map2Stream(exhaustive,g.exhaustive)(map2Option(_,_)(f)))
-
-  def flatMap[B](f: A => Gen[B]): Gen[B] =
-    Gen(sample.flatMap(a => f(a).sample),
-        exhaustive.flatMap {
-          case None => unbounded
-          case Some(a) => f(a).exhaustive
-        })
-
-  /* A method alias for the function we wrote earlier. */
-  def listOfN(size: Int): Gen[List[A]] =
-    Gen.listOfN(size, this)
-
-  /* A version of `listOfN` that generates the size to use dynamically. */
-  def listOfN(size: Gen[Int]): Gen[List[A]] =
-    size flatMap (n => this.listOfN(n))
-
-  def listOf: SGen[List[A]] = Gen.listOf(this)
-  def listOf1: SGen[List[A]] = Gen.listOf1(this)
-
-  def unsized = Unsized(this)
-
-  def **[B](g: Gen[B]): Gen[(A,B)] =
-    (this map2 g)((_,_))
-}
-
-object Gen {
-  type Domain[+A] = Stream[Option[A]]
-
-  def bounded[A](a: Stream[A]): Domain[A] = a map (Some(_))
-  def unbounded: Domain[Nothing] = Stream(None)
-
-  def unit[A](a: => A): Gen[A] =
-    Gen(State.unit(a), bounded(Stream(a)))
-
-  def boolean: Gen[Boolean] =
-    Gen(State(RNG.boolean), bounded(Stream(true,false)))
-
-  def choose(start: Int, stopExclusive: Int): Gen[Int] =
-    Gen(State(RNG.nonNegativeInt).map(n => start + n % (stopExclusive-start)),
-        bounded(Stream.from(start).take(stopExclusive-start)))
-
-  /* This implementation is rather tricky, but almost impossible to get wrong
-   * if you follow the types. It relies on several helper functions (see below).
-   */
-  def listOfN[A](n: Int, g: Gen[A]): Gen[List[A]] =
-    Gen(State.sequence(List.fill(n)(g.sample)),
-        cartesian(Stream.constant(g.exhaustive).take(n)).
-        map(l => sequenceOption(l.toList)))
-
-  /* `cartesian` generates all possible combinations of a `Stream[Stream[A]]`. For instance:
-   *
-   *    cartesian(Stream(Stream(1,2), Stream(3), Stream(4,5))) ==
-   *    Stream(Stream(1,3,4), Stream(1,3,5), Stream(2,3,4), Stream(2,3,5))
-  */
-  def cartesian[A](s: Stream[Stream[A]]): Stream[Stream[A]] =
-    s.foldRight(Stream(Stream[A]()))((hs,ts) => map2Stream(hs,ts)(Stream.cons(_,_)))
-
-  /* `map2Option` and `map2Stream`. Notice the duplication! */
-  def map2Option[A,B,C](oa: Option[A], ob: Option[B])(f: (A,B) => C): Option[C] =
-    for { a <- oa; b <- ob } yield f(a,b)
-
-  /* This is not the same as `zipWith`, a function we've implemented before.
-   * We are generating all (A,B) combinations and using each to produce a `C`.
-   * This implementation desugars to sa.flatMap(a => sb.map(b => f(a,b))).
-   */
-  def map2Stream[A,B,C](sa: Stream[A], sb: => Stream[B])(f: (A,=>B) => C): Stream[C] =
-    for { a <- sa; b <- sb } yield f(a,b)
-
-  /* This is a function we've implemented before. Unfortunately, it does not
-   * exist in the standard library. This implementation is uses a foldLeft,
-   * followed by a reverse, which is equivalent to a foldRight, but does not
-   * use any stack space.
-   */
-  def sequenceOption[A](o: List[Option[A]]): Option[List[A]] =
-    o.foldLeft[Option[List[A]]](Some(List()))(
-      (t,h) => map2Option(h,t)(_ :: _)).map(_.reverse)
-
-  /* Notice we are using the `unbounded` definition here, which is just
-   * `Stream(None)` in our current representation of `exhaustive`.
-   */
-  def uniform: Gen[Double] =
-    Gen(State(RNG.double), unbounded)
-
-  def choose(i: Double, j: Double): Gen[Double] =
-    Gen(State(RNG.double).map(d => i + d*(j-i)), unbounded)
-
-  /* Basic idea is add 1 to the result of `choose` if it is of the wrong
-   * parity, but we require some special handling to deal with the maximum
-   * integer in the range.
-   */
-  def even(start: Int, stopExclusive: Int): Gen[Int] =
-    choose(start, if (stopExclusive%2 == 0) stopExclusive - 1 else stopExclusive).
-    map (n => if (n%2 != 0) n+1 else n)
-
-  def odd(start: Int, stopExclusive: Int): Gen[Int] =
-    choose(start, if (stopExclusive%2 != 0) stopExclusive - 1 else stopExclusive).
-    map (n => if (n%2 == 0) n+1 else n)
-
-  def sameParity(from: Int, to: Int): Gen[(Int,Int)] = for {
-    i <- choose(from,to)
-    j <- if (i%2 == 0) even(from,to) else odd(from,to)
-  } yield (i,j)
-
-  def listOfN_1[A](n: Int, g: Gen[A]): Gen[List[A]] =
-    List.fill(n)(g).foldRight(unit(List[A]()))((a,b) => a.map2(b)(_ :: _))
-
-  /* The simplest possible implementation. This will put all elements of one
-   * `Gen` before the other in the exhaustive traversal. It might be nice to
-   * interleave the two streams, so we get a more representative sample if we
-   * don't get to examine the entire exhaustive stream.
-   */
-  def union_1[A](g1: Gen[A], g2: Gen[A]): Gen[A] =
-    boolean.flatMap(b => if (b) g1 else g2)
-
-  def union[A](g1: Gen[A], g2: Gen[A]): Gen[A] =
-    Gen(
-      State(RNG.boolean).flatMap(b => if (b) g1.sample else g2.sample),
-      interleave(g1.exhaustive, g2.exhaustive)
-    )
-
-  def interleave[A](s1: Stream[A], s2: Stream[A]): Stream[A] =
-    s1.zipAll(s2).flatMap { case (a,a2) => Stream((a.toList ++ a2.toList): _*) }
-
-  /* The random case is simple - we generate a double and use this to choose between
-   * the two random samplers. The exhaustive case is trickier if we want to try
-   * to produce a stream that does a weighted interleave of the two exhaustive streams.
-   */
-  def weighted[A](g1: (Gen[A],Double), g2: (Gen[A],Double)): Gen[A] = {
-    /* The probability we should pull from `g1`. */
-    val g1Threshold = g1._2.abs / (g1._2.abs + g2._2.abs)
-
-    /* Some random booleans to use for selecting between g1 and g2 in the exhaustive case.
-     * Making up a seed locally is fine here, since we just want a deterministic schedule
-     * with the right distribution. */
-    def bools: Stream[Boolean] =
-      randomStream(uniform.map(_ < g1Threshold))(RNG.Simple(302837L))
-
-    Gen(State(RNG.double).flatMap(d => if (d < g1Threshold) g1._1.sample else g2._1.sample),
-        interleave(bools, g1._1.exhaustive, g2._1.exhaustive))
-  }
-
-  /* Produce an infinite random stream from a `Gen` and a starting `RNG`. */
-  def randomStream[A](g: Gen[A])(rng: RNG): Stream[A] =
-    Stream.unfold(rng)(rng => Some(g.sample.run(rng)))
-
-  /* Interleave the two streams, using `b` to control which stream to pull from at each step.
-   * A value of `true` attempts to pull from `s1`; `false` attempts to pull from `s1`.
-   * When either stream is exhausted, insert all remaining elements from the other stream.
-   */
-  def interleave[A](b: Stream[Boolean], s1: Stream[A], s2: Stream[A]): Stream[A] =
-    b.headOption map { hd =>
-      if (hd) s1 match {
-        case Cons(h, t) => Stream.cons(h(), interleave(b drop 1, t(), s2))
-        case _ => s2
-      }
-      else s2 match {
-        case Cons(h, t) => Stream.cons(h(), interleave(b drop 1, s1, t()))
-        case _ => s1
-      }
-    } getOrElse Stream.empty
-
-  def listOf[A](g: Gen[A]): SGen[List[A]] =
-    Sized(n => g.listOfN(n))
-
-  /* Not the most efficient implementation, but it's simple.
-   * This generates ASCII strings.
-   */
-  def stringN(n: Int): Gen[String] =
-    listOfN(n, choose(0,127)).map(_.map(_.toChar).mkString)
-
-  def string: SGen[String] = Sized(stringN)
-
-  case class Sized[+A](forSize: Int => Gen[A]) extends SGen[A]
-  case class Unsized[+A](get: Gen[A]) extends SGen[A]
-
-  implicit def unsized[A](g: Gen[A]): SGen[A] = Unsized(g)
-
-  val smallInt = Gen.choose(-10,10)
-  val maxProp = forAll(listOf(smallInt)) { l =>
-    val max = l.max
-    !l.exists(_ > max) // No value greater than `max` should exist in `l`
-  }
-
-  def listOf1[A](g: Gen[A]): SGen[List[A]] =
-    Sized(n => g.listOfN(n max 1))
-
-  val maxProp1 = forAll(listOf1(smallInt)) { l =>
-    val max = l.max
-    !l.exists(_ > max) // No value greater than `max` should exist in `l`
-  }
-
-  val sortedProp = forAll(listOf(smallInt)) { l =>
-    val ls = l.sorted
-    l.isEmpty || ls.tail.isEmpty || !l.zip(ls.tail).exists { case (a,b) => a > b }
-  }
-
-  object ** {
-    def unapply[A,B](p: (A,B)) = Some(p)
-  }
-
-  /* A `Gen[Par[Int]]` generated from a list summation that spawns a new parallel
-   * computation for each element of the input list summed to produce the final
-   * result. This is not the most compelling example, but it provides at least some
-   * variation in structure to use for testing.
-   */
-  lazy val pint2: Gen[Par[Int]] = choose(-100,100).listOfN(choose(0,20)).map(l =>
-    l.foldLeft(Par.unit(0))((p,i) =>
-      Par.fork { Par.map2(p, Par.unit(i))(_ + _) }))
-
-  def genStringIntFn(g: Gen[Int]): Gen[String => Int] =
-    g map (i => (s => i))
-}
-
-trait SGen[+A] {
-  def map[B](f: A => B): SGen[B] = this match {
-    case Sized(g) => Sized(g andThen (_ map f))
-    case Unsized(g) => Unsized(g map f)
-  }
-  def flatMap[B](f: A => Gen[B]): SGen[B] = this match {
-    case Sized(g) => Sized(g andThen (_ flatMap f))
-    case Unsized(g) => Unsized(g flatMap f)
-  }
-  def **[B](s2: SGen[B]): SGen[(A,B)] = (this,s2) match {
-    case (Sized(g), Sized(g2)) => Sized(n => g(n) ** g2(n))
-    case (Unsized(g), Unsized(g2)) => Unsized(g ** g2)
-    case (Sized(g), Unsized(g2)) => Sized(n => g(n) ** g2)
-    case (Unsized(g), Sized(g2)) => Sized(n => g ** g2(n))
-  }
-}
diff --git a/answers/src/main/scala/fpinscala/testing/Gen.scala b/answers/src/main/scala/fpinscala/testing/Gen.scala
deleted file mode 100644
index d2610c2..0000000
--- a/answers/src/main/scala/fpinscala/testing/Gen.scala
+++ /dev/null
@@ -1,305 +0,0 @@
-package fpinscala.testing
-
-import fpinscala.laziness.Stream
-import fpinscala.state._
-import fpinscala.parallelism._
-import fpinscala.parallelism.Par.Par
-import Gen._
-import Prop._
-import java.util.concurrent.{Executors,ExecutorService}
-import language.postfixOps
-import language.implicitConversions
-
-case class Prop(run: (MaxSize,TestCases,RNG) => Result) {
-  def &&(p: Prop) = Prop {
-    (max,n,rng) => run(max,n,rng) match {
-      case Passed | Proved => p.run(max, n, rng)
-      case x => x
-    }
-  }
-
-  def ||(p: Prop) = Prop {
-    (max,n,rng) => run(max,n,rng) match {
-      // In case of failure, run the other prop.
-      case Falsified(msg, _) => p.tag(msg).run(max,n,rng)
-      case x => x
-    }
-  }
-
-  /* This is rather simplistic - in the event of failure, we simply prepend
-   * the given message on a newline in front of the existing message.
-   */
-  def tag(msg: String) = Prop {
-    (max,n,rng) => run(max,n,rng) match {
-      case Falsified(e, c) => Falsified(msg + "\n" + e, c)
-      case x => x
-    }
-  }
-}
-
-object Prop {
-  type SuccessCount = Int
-  type TestCases = Int
-  type MaxSize = Int
-  type FailedCase = String
-
-  sealed trait Result {
-    def isFalsified: Boolean
-  }
-  case object Passed extends Result {
-    def isFalsified = false
-  }
-  case class Falsified(failure: FailedCase,
-                       successes: SuccessCount) extends Result {
-    def isFalsified = true
-  }
-  case object Proved extends Result {
-    def isFalsified = false
-  }
-
-
-  /* Produce an infinite random stream from a `Gen` and a starting `RNG`. */
-  def randomStream[A](g: Gen[A])(rng: RNG): Stream[A] =
-    Stream.unfold(rng)(rng => Some(g.sample.run(rng)))
-
-  def forAll[A](as: Gen[A])(f: A => Boolean): Prop = Prop {
-    (n,rng) => randomStream(as)(rng).zip(Stream.from(0)).take(n).map {
-      case (a, i) => try {
-        if (f(a)) Passed else Falsified(a.toString, i)
-      } catch { case e: Exception => Falsified(buildMsg(a, e), i) }
-    }.find(_.isFalsified).getOrElse(Passed)
-  }
-
-
-  // String interpolation syntax. A string starting with `s"` can refer to
-  // a Scala value `v` as `$v` or `${v}` in the string.
-  // This will be expanded to `v.toString` by the Scala compiler.
-  def buildMsg[A](s: A, e: Exception): String =
-    s"test case: $s\n" +
-    s"generated an exception: ${e.getMessage}\n" +
-    s"stack trace:\n ${e.getStackTrace.mkString("\n")}"
-
-  def apply(f: (TestCases,RNG) => Result): Prop =
-    Prop { (_,n,rng) => f(n,rng) }
-
-  def forAll[A](g: SGen[A])(f: A => Boolean): Prop =
-    forAll(g(_))(f)
-
-  def forAll[A](g: Int => Gen[A])(f: A => Boolean): Prop = Prop {
-    (max,n,rng) =>
-      val casesPerSize = (n - 1) / max + 1
-      val props: Stream[Prop] =
-        Stream.from(0).take((n min max) + 1).map(i => forAll(g(i))(f))
-      val prop: Prop =
-        props.map(p => Prop { (max, n, rng) =>
-          p.run(max, casesPerSize, rng)
-        }).toList.reduce(_ && _)
-      prop.run(max,n,rng)
-  }
-
-  def run(p: Prop,
-          maxSize: Int = 100,
-          testCases: Int = 100,
-          rng: RNG = RNG.Simple(System.currentTimeMillis)): Unit =
-    p.run(maxSize, testCases, rng) match {
-      case Falsified(msg, n) =>
-        println(s"! Falsified after $n passed tests:\n $msg")
-      case Passed =>
-        println(s"+ OK, passed $testCases tests.")
-      case Proved =>
-        println(s"+ OK, proved property.")
-    }
-
-  val ES: ExecutorService = Executors.newCachedThreadPool
-  val p1 = Prop.forAll(Gen.unit(Par.unit(1)))(i =>
-    Par.map(i)(_ + 1)(ES).get == Par.unit(2)(ES).get)
-
-  def check(p: => Boolean): Prop = Prop { (_, _, _) =>
-    if (p) Passed else Falsified("()", 0)
-  }
-
-  val p2 = check {
-    val p = Par.map(Par.unit(1))(_ + 1)
-    val p2 = Par.unit(2)
-    p(ES).get == p2(ES).get
-  }
-
-  def equal[A](p: Par[A], p2: Par[A]): Par[Boolean] =
-    Par.map2(p,p2)(_ == _)
-
-  val p3 = check {
-    equal (
-      Par.map(Par.unit(1))(_ + 1),
-      Par.unit(2)
-    ) (ES) get
-  }
-
-  val S = weighted(
-    choose(1,4).map(Executors.newFixedThreadPool) -> .75,
-    unit(Executors.newCachedThreadPool) -> .25) // `a -> b` is syntax sugar for `(a,b)`
-
-  def forAllPar[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
-    forAll(S.map2(g)((_,_))) { case (s,a) => f(a)(s).get }
-
-  def checkPar(p: Par[Boolean]): Prop =
-    forAllPar(Gen.unit(()))(_ => p)
-
-  def forAllPar2[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
-    forAll(S ** g) { case (s,a) => f(a)(s).get }
-
-  def forAllPar3[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
-    forAll(S ** g) { case s ** a => f(a)(s).get }
-
-  val pint = Gen.choose(0,10) map (Par.unit(_))
-  val p4 =
-    forAllPar(pint)(n => equal(Par.map(n)(y => y), n))
-
-  val forkProp = Prop.forAllPar(pint2)(i => equal(Par.fork(i), i)) tag "fork"
-}
-
-case class Gen[+A](sample: State[RNG,A]) {
-  def map[B](f: A => B): Gen[B] =
-    Gen(sample.map(f))
-
-  def map2[B,C](g: Gen[B])(f: (A,B) => C): Gen[C] =
-    Gen(sample.map2(g.sample)(f))
-
-  def flatMap[B](f: A => Gen[B]): Gen[B] =
-    Gen(sample.flatMap(a => f(a).sample))
-
-  /* A method alias for the function we wrote earlier. */
-  def listOfN(size: Int): Gen[List[A]] =
-    Gen.listOfN(size, this)
-
-  /* A version of `listOfN` that generates the size to use dynamically. */
-  def listOfN(size: Gen[Int]): Gen[List[A]] =
-    size flatMap (n => this.listOfN(n))
-
-  def listOf: SGen[List[A]] = Gen.listOf(this)
-  def listOf1: SGen[List[A]] = Gen.listOf1(this)
-
-  def unsized = SGen(_ => this)
-
-  def **[B](g: Gen[B]): Gen[(A,B)] =
-    (this map2 g)((_,_))
-}
-
-object Gen {
-  def unit[A](a: => A): Gen[A] =
-    Gen(State.unit(a))
-
-  val boolean: Gen[Boolean] =
-    Gen(State(RNG.boolean))
-
-  def choose(start: Int, stopExclusive: Int): Gen[Int] =
-    Gen(State(RNG.nonNegativeInt).map(n => start + n % (stopExclusive-start)))
-
-  def listOfN[A](n: Int, g: Gen[A]): Gen[List[A]] =
-    Gen(State.sequence(List.fill(n)(g.sample)))
-
-  val uniform: Gen[Double] = Gen(State(RNG.double))
-
-  def choose(i: Double, j: Double): Gen[Double] =
-    Gen(State(RNG.double).map(d => i + d*(j-i)))
-
-  /* Basic idea is to add 1 to the result of `choose` if it is of the wrong
-   * parity, but we require some special handling to deal with the maximum
-   * integer in the range.
-   */
-  def even(start: Int, stopExclusive: Int): Gen[Int] =
-    choose(start, if (stopExclusive%2 == 0) stopExclusive - 1 else stopExclusive).
-    map (n => if (n%2 != 0) n+1 else n)
-
-  def odd(start: Int, stopExclusive: Int): Gen[Int] =
-    choose(start, if (stopExclusive%2 != 0) stopExclusive - 1 else stopExclusive).
-    map (n => if (n%2 == 0) n+1 else n)
-
-  def sameParity(from: Int, to: Int): Gen[(Int,Int)] = for {
-    i <- choose(from,to)
-    j <- if (i%2 == 0) even(from,to) else odd(from,to)
-  } yield (i,j)
-
-  def listOfN_1[A](n: Int, g: Gen[A]): Gen[List[A]] =
-    List.fill(n)(g).foldRight(unit(List[A]()))((a,b) => a.map2(b)(_ :: _))
-
-  def union[A](g1: Gen[A], g2: Gen[A]): Gen[A] =
-    boolean.flatMap(b => if (b) g1 else g2)
-
-  def weighted[A](g1: (Gen[A],Double), g2: (Gen[A],Double)): Gen[A] = {
-    /* The probability we should pull from `g1`. */
-    val g1Threshold = g1._2.abs / (g1._2.abs + g2._2.abs)
-
-    Gen(State(RNG.double).flatMap(d => if (d < g1Threshold) g1._1.sample else g2._1.sample))
-  }
-
-  def listOf[A](g: Gen[A]): SGen[List[A]] =
-    SGen(n => g.listOfN(n))
-
-  /* Not the most efficient implementation, but it's simple.
-   * This generates ASCII strings.
-   */
-  def stringN(n: Int): Gen[String] =
-    listOfN(n, choose(0,127)).map(_.map(_.toChar).mkString)
-
-  val string: SGen[String] = SGen(stringN)
-
-  implicit def unsized[A](g: Gen[A]): SGen[A] = SGen(_ => g)
-
-  val smallInt = Gen.choose(-10,10)
-  val maxProp = forAll(listOf(smallInt)) { l =>
-    val max = l.max
-    !l.exists(_ > max) // No value greater than `max` should exist in `l`
-  }
-
-  def listOf1[A](g: Gen[A]): SGen[List[A]] =
-    SGen(n => g.listOfN(n max 1))
-
-  val maxProp1 = forAll(listOf1(smallInt)) { l =>
-    val max = l.max
-    !l.exists(_ > max) // No value greater than `max` should exist in `l`
-  }
-
-  // We specify that every sorted list is either empty, has one element,
-  // or has no two consecutive elements `(a,b)` such that `a` is greater than `b`.
-  val sortedProp = forAll(listOf(smallInt)) { l =>
-    val ls = l.sorted
-    l.isEmpty || ls.tail.isEmpty || !ls.zip(ls.tail).exists { case (a,b) => a > b }
-  }
-
-  object ** {
-    def unapply[A,B](p: (A,B)) = Some(p)
-  }
-
-  /* A `Gen[Par[Int]]` generated from a list summation that spawns a new parallel
-   * computation for each element of the input list summed to produce the final
-   * result. This is not the most compelling example, but it provides at least some
-   * variation in structure to use for testing.
-   *
-   * Note that this has to be a `lazy val` because of the way Scala initializes objects.
-   * It depends on the `Prop` companion object being created, which references `pint2`.
-   */
-  lazy val pint2: Gen[Par[Int]] = choose(-100,100).listOfN(choose(0,20)).map(l =>
-    l.foldLeft(Par.unit(0))((p,i) =>
-      Par.fork { Par.map2(p, Par.unit(i))(_ + _) }))
-
-  def genStringIntFn(g: Gen[Int]): Gen[String => Int] =
-    g map (i => (s => i))
-}
-
-case class SGen[+A](g: Int => Gen[A]) {
-  def apply(n: Int): Gen[A] = g(n)
-
-  def map[B](f: A => B): SGen[B] =
-    SGen { g(_) map f }
-
-  def flatMap[B](f: A => SGen[B]): SGen[B] = {
-    val g2: Int => Gen[B] = n => {
-      g(n) flatMap { f(_).g(n) }
-    }
-    SGen(g2)
-  }
-
-  def **[B](s2: SGen[B]): SGen[(A,B)] =
-    SGen(n => apply(n) ** s2(n))
-}
-
diff --git a/build.sbt b/build.sbt
index c6c4087..fb81161 100644
--- a/build.sbt
+++ b/build.sbt
@@ -1,21 +1,25 @@
+organization := "fpinscala"
+name := "fpinscala"
+
 val commonSettings = Seq(
-  scalaVersion := "2.12.1"
+  scalaVersion := "2.12.8",
+  version := "dc04eb6"
 )
 
-lazy val root = (project in file("."))
-  .aggregate(exercises, answers)
+lazy val fpinscala = (project in file("."))
   .settings(commonSettings)
   .settings(
     name := "fpinscala"
   )
+  .aggregate(exercises, answers)
 
-lazy val exercises = (project in file("exercises"))
+lazy val exercises = (project in file("./src/exercises"))
   .settings(commonSettings)
   .settings(
     name := "exercises"
   )
 
-lazy val answers = (project in file("answers"))
+lazy val answers = (project in file("./src/answers"))
   .settings(commonSettings)
   .settings(
     name := "answers"
diff --git a/exercises/src/main/scala/fpinscala/applicative/Applicative.scala b/exercises/src/main/scala/fpinscala/applicative/Applicative.scala
deleted file mode 100644
index 7f3a225..0000000
--- a/exercises/src/main/scala/fpinscala/applicative/Applicative.scala
+++ /dev/null
@@ -1,154 +0,0 @@
-package fpinscala
-package applicative
-
-import monads.Functor
-import state._
-import State._
-import StateUtil._ // defined at bottom of this file
-import monoids._
-import language.higherKinds
-import language.implicitConversions
-
-trait Applicative[F[_]] extends Functor[F] {
-
-  def map2[A,B,C](fa: F[A], fb: F[B])(f: (A, B) => C): F[C] = ???
-
-  def apply[A,B](fab: F[A => B])(fa: F[A]): F[B] = ???
-
-  def unit[A](a: => A): F[A]
-
-  def map[A,B](fa: F[A])(f: A => B): F[B] =
-    apply(unit(f))(fa)
-
-  def sequence[A](fas: List[F[A]]): F[List[A]] = ???
-
-  def traverse[A,B](as: List[A])(f: A => F[B]): F[List[B]] = ???
-
-  def replicateM[A](n: Int, fa: F[A]): F[List[A]] = ???
-
-  def factor[A,B](fa: F[A], fb: F[B]): F[(A,B)] = ???
-
-  def product[G[_]](G: Applicative[G]): Applicative[({type f[x] = (F[x], G[x])})#f] = ???
-
-  def compose[G[_]](G: Applicative[G]): Applicative[({type f[x] = F[G[x]]})#f] = ???
-
-  def sequenceMap[K,V](ofa: Map[K,F[V]]): F[Map[K,V]] = ???
-}
-
-case class Tree[+A](head: A, tail: List[Tree[A]])
-
-trait Monad[F[_]] extends Applicative[F] {
-  def flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] = join(map(ma)(f))
-
-  def join[A](mma: F[F[A]]): F[A] = flatMap(mma)(ma => ma)
-
-  def compose[A,B,C](f: A => F[B], g: B => F[C]): A => F[C] =
-    a => flatMap(f(a))(g)
-
-  override def apply[A,B](mf: F[A => B])(ma: F[A]): F[B] =
-    flatMap(mf)(f => map(ma)(a => f(a)))
-}
-
-object Monad {
-  def eitherMonad[E]: Monad[({type f[x] = Either[E, x]})#f] = ???
-
-  def stateMonad[S] = new Monad[({type f[x] = State[S, x]})#f] {
-    def unit[A](a: => A): State[S, A] = State(s => (a, s))
-    override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
-      st flatMap f
-  }
-
-  def composeM[F[_],N[_]](implicit F: Monad[F], N: Monad[N], T: Traverse[N]):
-    Monad[({type f[x] = F[N[x]]})#f] = ???
-}
-
-sealed trait Validation[+E, +A]
-
-case class Failure[E](head: E, tail: Vector[E])
-  extends Validation[E, Nothing]
-
-case class Success[A](a: A) extends Validation[Nothing, A]
-
-
-object Applicative {
-
-  val streamApplicative = new Applicative[Stream] {
-
-    def unit[A](a: => A): Stream[A] =
-      Stream.continually(a) // The infinite, constant stream
-
-    override def map2[A,B,C](a: Stream[A], b: Stream[B])( // Combine elements pointwise
-                    f: (A,B) => C): Stream[C] =
-      a zip b map f.tupled
-  }
-
-  def validationApplicative[E]: Applicative[({type f[x] = Validation[E,x]})#f] = ???
-
-  type Const[A, B] = A
-
-  implicit def monoidApplicative[M](M: Monoid[M]) =
-    new Applicative[({ type f[x] = Const[M, x] })#f] {
-      def unit[A](a: => A): M = M.zero
-      override def apply[A,B](m1: M)(m2: M): M = M.op(m1, m2)
-    }
-}
-
-trait Traverse[F[_]] extends Functor[F] with Foldable[F] {
-  def traverse[G[_]:Applicative,A,B](fa: F[A])(f: A => G[B]): G[F[B]] =
-    sequence(map(fa)(f))
-  def sequence[G[_]:Applicative,A](fma: F[G[A]]): G[F[A]] =
-    traverse(fma)(ma => ma)
-
-  def map[A,B](fa: F[A])(f: A => B): F[B] = ???
-
-  import Applicative._
-
-  override def foldMap[A,B](as: F[A])(f: A => B)(mb: Monoid[B]): B =
-    traverse[({type f[x] = Const[B,x]})#f,A,Nothing](
-      as)(f)(monoidApplicative(mb))
-
-  def traverseS[S,A,B](fa: F[A])(f: A => State[S, B]): State[S, F[B]] =
-    traverse[({type f[x] = State[S,x]})#f,A,B](fa)(f)(Monad.stateMonad)
-
-  def mapAccum[S,A,B](fa: F[A], s: S)(f: (A, S) => (B, S)): (F[B], S) =
-    traverseS(fa)((a: A) => (for {
-      s1 <- get[S]
-      (b, s2) = f(a, s1)
-      _  <- set(s2)
-    } yield b)).run(s)
-
-  override def toList[A](fa: F[A]): List[A] =
-    mapAccum(fa, List[A]())((a, s) => ((), a :: s))._2.reverse
-
-  def zipWithIndex[A](fa: F[A]): F[(A, Int)] =
-    mapAccum(fa, 0)((a, s) => ((a, s), s + 1))._1
-
-  def reverse[A](fa: F[A]): F[A] = ???
-
-  override def foldLeft[A,B](fa: F[A])(z: B)(f: (B, A) => B): B = ???
-
-  def fuse[G[_],H[_],A,B](fa: F[A])(f: A => G[B], g: A => H[B])
-                         (implicit G: Applicative[G], H: Applicative[H]): (G[F[B]], H[F[B]]) = ???
-
-  def compose[G[_]](implicit G: Traverse[G]): Traverse[({type f[x] = F[G[x]]})#f] = ???
-}
-
-object Traverse {
-  val listTraverse = ???
-
-  val optionTraverse = ???
-
-  val treeTraverse = ???
-}
-
-// The `get` and `set` functions on `State` are used above,
-// but aren't in the `exercises` subproject, so we include
-// them here
-object StateUtil {
-
-  def get[S]: State[S, S] =
-    State(s => (s, s))
-
-  def set[S](s: S): State[S, Unit] =
-    State(_ => ((), s))
-}
diff --git a/exercises/src/main/scala/fpinscala/datastructures/List.scala b/exercises/src/main/scala/fpinscala/datastructures/List.scala
deleted file mode 100644
index fd1cf5b..0000000
--- a/exercises/src/main/scala/fpinscala/datastructures/List.scala
+++ /dev/null
@@ -1,68 +0,0 @@
-package fpinscala.datastructures
-
-sealed trait List[+A] // `List` data type, parameterized on a type, `A`
-case object Nil extends List[Nothing] // A `List` data constructor representing the empty list
-/* Another data constructor, representing nonempty lists. Note that `tail` is another `List[A]`,
-which may be `Nil` or another `Cons`.
- */
-case class Cons[+A](head: A, tail: List[A]) extends List[A]
-
-object List { // `List` companion object. Contains functions for creating and working with lists.
-  def sum(ints: List[Int]): Int = ints match { // A function that uses pattern matching to add up a list of integers
-    case Nil => 0 // The sum of the empty list is 0.
-    case Cons(x,xs) => x + sum(xs) // The sum of a list starting with `x` is `x` plus the sum of the rest of the list.
-  }
-
-  def product(ds: List[Double]): Double = ds match {
-    case Nil => 1.0
-    case Cons(0.0, _) => 0.0
-    case Cons(x,xs) => x * product(xs)
-  }
-
-  def apply[A](as: A*): List[A] = // Variadic function syntax
-    if (as.isEmpty) Nil
-    else Cons(as.head, apply(as.tail: _*))
-
-  val x = List(1,2,3,4,5) match {
-    case Cons(x, Cons(2, Cons(4, _))) => x
-    case Nil => 42
-    case Cons(x, Cons(y, Cons(3, Cons(4, _)))) => x + y
-    case Cons(h, t) => h + sum(t)
-    case _ => 101
-  }
-
-  def append[A](a1: List[A], a2: List[A]): List[A] =
-    a1 match {
-      case Nil => a2
-      case Cons(h,t) => Cons(h, append(t, a2))
-    }
-
-  def foldRight[A,B](as: List[A], z: B)(f: (A, B) => B): B = // Utility functions
-    as match {
-      case Nil => z
-      case Cons(x, xs) => f(x, foldRight(xs, z)(f))
-    }
-
-  def sum2(ns: List[Int]) =
-    foldRight(ns, 0)((x,y) => x + y)
-
-  def product2(ns: List[Double]) =
-    foldRight(ns, 1.0)(_ * _) // `_ * _` is more concise notation for `(x,y) => x * y`; see sidebar
-
-
-  def tail[A](l: List[A]): List[A] = ???
-
-  def setHead[A](l: List[A], h: A): List[A] = ???
-
-  def drop[A](l: List[A], n: Int): List[A] = ???
-
-  def dropWhile[A](l: List[A], f: A => Boolean): List[A] = ???
-
-  def init[A](l: List[A]): List[A] = ???
-
-  def length[A](l: List[A]): Int = ???
-
-  def foldLeft[A,B](l: List[A], z: B)(f: (B, A) => B): B = ???
-
-  def map[A,B](l: List[A])(f: A => B): List[B] = ???
-}
diff --git a/exercises/src/main/scala/fpinscala/datastructures/Tree.scala b/exercises/src/main/scala/fpinscala/datastructures/Tree.scala
deleted file mode 100644
index b94250a..0000000
--- a/exercises/src/main/scala/fpinscala/datastructures/Tree.scala
+++ /dev/null
@@ -1,13 +0,0 @@
-package fpinscala.datastructures
-
-sealed trait Tree[+A]
-case class Leaf[A](value: A) extends Tree[A]
-case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]
-
-
-object Tree {
-
-
-
-
-}
\ No newline at end of file
diff --git a/exercises/src/main/scala/fpinscala/errorhandling/Either.scala b/exercises/src/main/scala/fpinscala/errorhandling/Either.scala
deleted file mode 100644
index 1b9617c..0000000
--- a/exercises/src/main/scala/fpinscala/errorhandling/Either.scala
+++ /dev/null
@@ -1,37 +0,0 @@
-package fpinscala.errorhandling
-
-
-import scala.{Option => _, Either => _, Left => _, Right => _, _} // hide std library `Option` and `Either`, since we are writing our own in this chapter
-
-sealed trait Either[+E,+A] {
- def map[B](f: A => B): Either[E, B] = ???
-
- def flatMap[EE >: E, B](f: A => Either[EE, B]): Either[EE, B] = ???
-
- def orElse[EE >: E, B >: A](b: => Either[EE, B]): Either[EE, B] = ???
-
- def map2[EE >: E, B, C](b: Either[EE, B])(f: (A, B) => C): Either[EE, C] = ???
-}
-case class Left[+E](get: E) extends Either[E,Nothing]
-case class Right[+A](get: A) extends Either[Nothing,A]
-
-object Either {
-  def traverse[E,A,B](es: List[A])(f: A => Either[E, B]): Either[E, List[B]] = ???
-
-  def sequence[E,A](es: List[Either[E,A]]): Either[E,List[A]] = ???
-
-  def mean(xs: IndexedSeq[Double]): Either[String, Double] = 
-    if (xs.isEmpty) 
-      Left("mean of empty list!")
-    else 
-      Right(xs.sum / xs.length)
-
-  def safeDiv(x: Int, y: Int): Either[Exception, Int] = 
-    try Right(x / y)
-    catch { case e: Exception => Left(e) }
-
-  def Try[A](a: => A): Either[Exception, A] =
-    try Right(a)
-    catch { case e: Exception => Left(e) }
-
-}
\ No newline at end of file
diff --git a/exercises/src/main/scala/fpinscala/errorhandling/Option.scala b/exercises/src/main/scala/fpinscala/errorhandling/Option.scala
deleted file mode 100644
index b13f292..0000000
--- a/exercises/src/main/scala/fpinscala/errorhandling/Option.scala
+++ /dev/null
@@ -1,48 +0,0 @@
-package fpinscala.errorhandling
-
-
-import scala.{Option => _, Some => _, Either => _, _} // hide std library `Option`, `Some` and `Either`, since we are writing our own in this chapter
-
-sealed trait Option[+A] {
-  def map[B](f: A => B): Option[B] = ???
-
-  def getOrElse[B>:A](default: => B): B = ???
-
-  def flatMap[B](f: A => Option[B]): Option[B] = ???
-
-  def orElse[B>:A](ob: => Option[B]): Option[B] = ???
-
-  def filter(f: A => Boolean): Option[A] = ???
-}
-case class Some[+A](get: A) extends Option[A]
-case object None extends Option[Nothing]
-
-object Option {
-  def failingFn(i: Int): Int = {
-    val y: Int = throw new Exception("fail!") // `val y: Int = ...` declares `y` as having type `Int`, and sets it equal to the right hand side of the `=`.
-    try {
-      val x = 42 + 5
-      x + y
-    }
-    catch { case e: Exception => 43 } // A `catch` block is just a pattern matching block like the ones we've seen. `case e: Exception` is a pattern that matches any `Exception`, and it binds this value to the identifier `e`. The match returns the value 43.
-  }
-
-  def failingFn2(i: Int): Int = {
-    try {
-      val x = 42 + 5
-      x + ((throw new Exception("fail!")): Int) // A thrown Exception can be given any type; here we're annotating it with the type `Int`
-    }
-    catch { case e: Exception => 43 }
-  }
-
-  def mean(xs: Seq[Double]): Option[Double] =
-    if (xs.isEmpty) None
-    else Some(xs.sum / xs.length)
-  def variance(xs: Seq[Double]): Option[Double] = ???
-
-  def map2[A,B,C](a: Option[A], b: Option[B])(f: (A, B) => C): Option[C] = ???
-
-  def sequence[A](a: List[Option[A]]): Option[List[A]] = ???
-
-  def traverse[A, B](a: List[A])(f: A => Option[B]): Option[List[B]] = ???
-}
\ No newline at end of file
diff --git a/exercises/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala b/exercises/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
deleted file mode 100644
index aa4c9d3..0000000
--- a/exercises/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
+++ /dev/null
@@ -1,178 +0,0 @@
-package fpinscala.gettingstarted
-
-// A comment!
-/* Another comment */
-/** A documentation comment */
-object MyModule {
-  def abs(n: Int): Int =
-    if (n < 0) -n
-    else n
-
-  private def formatAbs(x: Int) = {
-    val msg = "The absolute value of %d is %d"
-    msg.format(x, abs(x))
-  }
-
-  def main(args: Array[String]): Unit =
-    println(formatAbs(-42))
-
-  // A definition of factorial, using a local, tail recursive function
-  def factorial(n: Int): Int = {
-    @annotation.tailrec
-    def go(n: Int, acc: Int): Int =
-      if (n <= 0) acc
-      else go(n-1, n*acc)
-
-    go(n, 1)
-  }
-
-  // Another implementation of `factorial`, this time with a `while` loop
-  def factorial2(n: Int): Int = {
-    var acc = 1
-    var i = n
-    while (i > 0) { acc *= i; i -= 1 }
-    acc
-  }
-
-  // Exercise 1: Write a function to compute the nth fibonacci number
-
-  def fib(n: Int): Int = ???
-
-  // This definition and `formatAbs` are very similar..
-  private def formatFactorial(n: Int) = {
-    val msg = "The factorial of %d is %d."
-    msg.format(n, factorial(n))
-  }
-
-  // We can generalize `formatAbs` and `formatFactorial` to
-  // accept a _function_ as a parameter
-  def formatResult(name: String, n: Int, f: Int => Int) = {
-    val msg = "The %s of %d is %d."
-    msg.format(name, n, f(n))
-  }
-}
-
-object FormatAbsAndFactorial {
-
-  import MyModule._
-
-  // Now we can use our general `formatResult` function
-  // with both `abs` and `factorial`
-  def main(args: Array[String]): Unit = {
-    println(formatResult("absolute value", -42, abs))
-    println(formatResult("factorial", 7, factorial))
-  }
-}
-
-object TestFib {
-
-  import MyModule._
-
-  // test implementation of `fib`
-  def main(args: Array[String]): Unit = {
-    println("Expected: 0, 1, 1, 2, 3, 5, 8")
-    println("Actual:   %d, %d, %d, %d, %d, %d, %d".format(fib(0), fib(1), fib(2), fib(3), fib(4), fib(5), fib(6)))
-  }
-}
-
-// Functions get passed around so often in FP that it's
-// convenient to have syntax for constructing a function
-// *without* having to give it a name
-object AnonymousFunctions {
-  import MyModule._
-
-  // Some examples of anonymous functions:
-  def main(args: Array[String]): Unit = {
-    println(formatResult("absolute value", -42, abs))
-    println(formatResult("factorial", 7, factorial))
-    println(formatResult("increment", 7, (x: Int) => x + 1))
-    println(formatResult("increment2", 7, (x) => x + 1))
-    println(formatResult("increment3", 7, x => x + 1))
-    println(formatResult("increment4", 7, _ + 1))
-    println(formatResult("increment5", 7, x => { val r = x + 1; r }))
-  }
-}
-
-object MonomorphicBinarySearch {
-
-  // First, a binary search implementation, specialized to `Double`,
-  // another primitive type in Scala, representing 64-bit floating
-  // point numbers
-  // Ideally, we could generalize this to work for any `Array` type,
-  // so long as we have some way of comparing elements of the `Array`
-  def binarySearch(ds: Array[Double], key: Double): Int = {
-    @annotation.tailrec
-    def go(low: Int, mid: Int, high: Int): Int = {
-      if (low > high) -mid - 1
-      else {
-        val mid2 = (low + high) / 2
-        val d = ds(mid2) // We index into an array using the same
-                         // syntax as function application
-        if (d == key) mid2
-        else if (d > key) go(low, mid2, mid2-1)
-        else go(mid2 + 1, mid2, high)
-      }
-    }
-    go(0, 0, ds.length - 1)
-  }
-
-}
-
-object PolymorphicFunctions {
-
-  // Here's a polymorphic version of `binarySearch`, parameterized on
-  // a function for testing whether an `A` is greater than another `A`.
-  def binarySearch[A](as: Array[A], key: A, gt: (A,A) => Boolean): Int = {
-    @annotation.tailrec
-    def go(low: Int, mid: Int, high: Int): Int = {
-      if (low > high) -mid - 1
-      else {
-        val mid2 = (low + high) / 2
-        val a = as(mid2)
-        val greater = gt(a, key)
-        if (!greater && !gt(key,a)) mid2
-        else if (greater) go(low, mid2, mid2-1)
-        else go(mid2 + 1, mid2, high)
-      }
-    }
-    go(0, 0, as.length - 1)
-  }
-
-  // Exercise 2: Implement a polymorphic function to check whether
-  // an `Array[A]` is sorted
-  def isSorted[A](as: Array[A], gt: (A,A) => Boolean): Boolean = ???
-
-  // Polymorphic functions are often so constrained by their type
-  // that they only have one implementation! Here's an example:
-
-  def partial1[A,B,C](a: A, f: (A,B) => C): B => C =
-    (b: B) => f(a, b)
-
-  // Exercise 3: Implement `curry`.
-
-  // Note that `=>` associates to the right, so we could
-  // write the return type as `A => B => C`
-  def curry[A,B,C](f: (A, B) => C): A => (B => C) =
-    ???
-
-  // NB: The `Function2` trait has a `curried` method already
-
-  // Exercise 4: Implement `uncurry`
-  def uncurry[A,B,C](f: A => B => C): (A, B) => C =
-    ???
-
-  /*
-  NB: There is a method on the `Function` object in the standard library,
-  `Function.uncurried` that you can use for uncurrying.
-
-  Note that we can go back and forth between the two forms. We can curry
-  and uncurry and the two forms are in some sense "the same". In FP jargon,
-  we say that they are _isomorphic_ ("iso" = same; "morphe" = shape, form),
-  a term we inherit from category theory.
-  */
-
-  // Exercise 5: Implement `compose`
-
-  def compose[A,B,C](f: B => C, g: A => B): A => C =
-    ???
-}
diff --git a/exercises/src/main/scala/fpinscala/iomonad/IO.scala b/exercises/src/main/scala/fpinscala/iomonad/IO.scala
deleted file mode 100644
index 284116f..0000000
--- a/exercises/src/main/scala/fpinscala/iomonad/IO.scala
+++ /dev/null
@@ -1,583 +0,0 @@
-package fpinscala.iomonad
-
-import language.postfixOps
-import language.higherKinds
-import scala.io.StdIn.readLine
-
-object IO0 {
-                            /*
-
-  Our first attempt at data type for representing computations that
-  may perform I/O. Has a simple 'interpreter' baked in--the `run`
-  function, which just returns `Unit`.
-
-                             */
-  trait IO { self =>
-    def run: Unit
-    def ++(io: IO): IO = new IO {
-      def run = { self.run; io.run }
-    }
-  }
-  object IO {
-    def empty: IO = new IO { def run = () }
-  }
-
-                            /*
-
-  The API of this `IO` type isn't very useful.  Not many operations
-  (it is only a monoid), and not many laws to help with reasoning. It
-  is completely _opaque_. Also cannot represent _input_ effects, like
-  reading from console, for instance:
-
-                             */
-
-  def fahrenheitToCelsius(f: Double): Double =
-    (f - 32) * 5.0/9.0
-
-  // Ordinary code with side effects
-  def converter: Unit = {
-    println("Enter a temperature in degrees Fahrenheit: ")
-    val d = readLine.toDouble
-    println(fahrenheitToCelsius(d))
-  }
-
-  // A pure version is not possible!
-  /*
-  def converter: IO = {
-    val prompt: IO = PrintLine("Enter a temperature in degrees fahrenheit: ")
-    // now what ???
-  }
-  */
-}
-
-object IO1 {
-                            /*
-
-  We need a way for our `IO` actions to yield a result of some
-  meaningful type. We do this by adding a type parameter to `IO`,
-  which now forms a `Monad`.
-                             */
-
-  sealed trait IO[A] { self =>
-    def run: A
-    def map[B](f: A => B): IO[B] =
-      new IO[B] { def run = f(self.run) }
-    def flatMap[B](f: A => IO[B]): IO[B] =
-      new IO[B] { def run = f(self.run).run }
-  }
-
-  object IO extends Monad[IO] {
-    def unit[A](a: => A): IO[A] = new IO[A] { def run = a }
-    def flatMap[A,B](fa: IO[A])(f: A => IO[B]) = fa flatMap f
-    def apply[A](a: => A): IO[A] = unit(a) // syntax for IO { .. }
-
-    def ref[A](a: A): IO[IORef[A]] = IO { new IORef(a) }
-    sealed class IORef[A](var value: A) {
-      def set(a: A): IO[A] = IO { value = a; a }
-      def get: IO[A] = IO { value }
-      def modify(f: A => A): IO[A] = get flatMap (a => set(f(a)))
-    }
-  }
-
-  // We can now express the example
-
-  def ReadLine: IO[String] = IO { readLine }
-  def PrintLine(msg: String): IO[Unit] = IO { println(msg) }
-  import IO0.fahrenheitToCelsius
-
-  def converter: IO[Unit] = for {
-    _ <- PrintLine("Enter a temperature in degrees Fahrenheit: ")
-    d <- ReadLine.map(_.toDouble)
-    _ <- PrintLine(fahrenheitToCelsius(d).toString)
-  } yield ()
-
-  /*                         Some other examples                      */
-
-  import IO._ // import all the `IO` combinators that come from `Monad`
-
-  // An `IO[Unit]` that reads a line from the console and echoes it back.
-  val echo = ReadLine.flatMap(PrintLine)
-
-  // Parses an `Int` by reading a line from the console.
-  val readInt: IO[Int] = ReadLine.map(_.toInt)
-
-  // Parses an `(Int,Int)` by reading two lines from the console.
-  val readInts: IO[(Int,Int)] = readInt ** readInt
-
-  // Repeat `converter` 5 times, discarding the results (which are
-  // just `Unit`). We can replace `converter` here with any `IO`
-  // action we wished to repeat 5 times (ex: `echo` or `readInts`).
-  val prompts: IO[Unit] = replicateM_(5)(converter)
-
-  // An `IO[List[String]]` that will read 10 lines from the console and
-  // return the list of results.
-  val lines: IO[List[String]] = replicateM(10)(ReadLine)
-
-                            /*
-
-  Larger example using various monadic combinators. Sample run:
-
-     The Amazing Factorial REPL, v2.0
-     q - quit
-     <number> - compute the factorial of the given number
-     <anything else> - bomb with horrible error
-     3
-     factorial: 6
-     7
-     factorial: 5040
-     q
-
-                             */
-  val helpstring = """
-  | The Amazing Factorial REPL, v2.0
-  | q - quit
-  | <number> - compute the factorial of the given number
-  | <anything else> - bomb with horrible error
-  """.trim.stripMargin
-
-  def factorial(n: Int): IO[Int] = for {
-    acc <- ref(1)
-    _ <- foreachM (1 to n toStream) (i => acc.modify(_ * i).skip)
-    result <- acc.get
-  } yield result
-
-  val factorialREPL: IO[Unit] = sequence_(
-    IO { println(helpstring) },
-    doWhile { IO { readLine } } { line =>
-      val ok = line != "q"
-      when (ok) { for {
-        n <- factorial(line.toInt)
-        _ <- IO { println("factorial: " + n) }
-      } yield () }
-    }
-  )
-}
-
-
-object IO2a {
-
-  /*
-  The previous IO representation overflows the stack for some programs.
-  The problem is that `run` call itself recursively, which means that
-  an infinite or long running IO computation will have a chain of regular
-  calls to `run`, eventually overflowing the stack.
-
-  The general solution is to make the `IO` type into a data type that we
-  interpret using a tail recursive loop, using pattern matching.
-  */
-
-  sealed trait IO[A] {
-    def flatMap[B](f: A => IO[B]): IO[B] =
-      FlatMap(this, f) // we do not interpret the `flatMap` here, just return it as a value
-    def map[B](f: A => B): IO[B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[A](a: A) extends IO[A]
-  case class Suspend[A](resume: () => A) extends IO[A]
-  case class FlatMap[A,B](sub: IO[A], k: A => IO[B]) extends IO[B]
-
-  object IO extends Monad[IO] { // Notice that none of these operations DO anything
-    def unit[A](a: => A): IO[A] = Return(a)
-    def flatMap[A,B](a: IO[A])(f: A => IO[B]): IO[B] = a flatMap f
-    def suspend[A](a: => IO[A]) =
-      Suspend(() => ()).flatMap { _ => a }
-  }
-
-  def printLine(s: String): IO[Unit] =
-    Suspend(() => Return(println(s)))
-
-  val p = IO.forever(printLine("Still going..."))
-
-  val actions: Stream[IO[Unit]] =
-    Stream.fill(100000)(printLine("Still going..."))
-  val composite: IO[Unit] =
-    actions.foldLeft(IO.unit(())) { (acc, a) => acc flatMap { _ => a } }
-
-  // There is only one sensible way to implement this as a
-  // tail-recursive function, the one tricky case is left-nested
-  // flatMaps, as in `((a flatMap f) flatMap g)`, which we
-  // reassociate to the right as `a flatMap (ar => f(a) flatMap g)`
-  @annotation.tailrec def run[A](io: IO[A]): A = io match {
-    case Return(a) => a
-    case Suspend(r) => r()
-    case FlatMap(x, f) => x match {
-      case Return(a) => run(f(a))
-      case Suspend(r) => run(f(r()))
-      case FlatMap(y, g) => run(y flatMap (a => g(a) flatMap f))
-    }
-  }
-}
-
-object IO2aTests {
-  import IO2a._
-
-  /*
-  Pg 240: REPL session has a typo, should be:
-
-  val g = List.fill(100000)(f).foldLeft(f) {
-    (a, b) => x => Suspend(() => ()).flatMap { _ => a(x).flatMap(b)}
-  }
-
-  Note: we could write a little helper function to make this nicer:
-
-  def suspend[A](a: => IO[A]) = Suspend(() => ()).flatMap { _ => a }
-
-  val g = List.fill(100000)(f).foldLeft(f) {
-    (a, b) => x => suspend { a(x).flatMap(b) }
-  }
-   */
-
-  val f: Int => IO[Int] = (i: Int) => Return(i)
-
-  val g: Int => IO[Int] =
-    List.fill(10000)(f).foldLeft(f){
-      (a: Function1[Int, IO[Int]],
-        b: Function1[Int, IO[Int]]) => {
-        (x: Int) => IO.suspend(a(x).flatMap(b))
-      }
-    }
-
-  def main(args: Array[String]): Unit = {
-    val gFortyTwo = g(42)
-    println("g(42) = " + gFortyTwo)
-    println("run(g(42)) = " + run(gFortyTwo))
-  }
-}
-
-
-object IO2b {
-
-  /*
-   * As it turns out, there's nothing about this data type that is specific
-   * to I/O, it's just a general purpose data type for optimizing tail calls.
-   * Here it is, renamed to `TailRec`. This type is also sometimes called
-   * `Trampoline`, because of the way interpreting it bounces back and forth
-   * between the main `run` loop and the functions contained in the `TailRec`.
-   */
-
-  sealed trait TailRec[A] {
-    def flatMap[B](f: A => TailRec[B]): TailRec[B] =
-      FlatMap(this, f)
-    def map[B](f: A => B): TailRec[B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[A](a: A) extends TailRec[A]
-  case class Suspend[A](resume: () => A) extends TailRec[A]
-  case class FlatMap[A,B](sub: TailRec[A], k: A => TailRec[B]) extends TailRec[B]
-
-  object TailRec extends Monad[TailRec] {
-    def unit[A](a: => A): TailRec[A] = Return(a)
-    def flatMap[A,B](a: TailRec[A])(f: A => TailRec[B]): TailRec[B] =
-      a flatMap f
-    def suspend[A](a: => TailRec[A]) =
-      Suspend(() => ()).flatMap { _ => a }
-  }
-
-  @annotation.tailrec def run[A](t: TailRec[A]): A = t match {
-    case Return(a) => a
-    case Suspend(r) => r()
-    case FlatMap(x, f) => x match {
-      case Return(a) => run(f(a))
-      case Suspend(r) => run(f(r()))
-      case FlatMap(y, g) => run(y flatMap (a => g(a) flatMap f))
-    }
-  }
-}
-
-object IO2bTests {
-  import IO2b._
-
-  val f: Int => TailRec[Int] = (i: Int) => Return(i)
-
-  val g: Int => TailRec[Int] =
-    List.fill(10000)(f).foldLeft(f){
-      (a: Function1[Int, TailRec[Int]],
-        b: Function1[Int, TailRec[Int]]) => {
-        (x: Int) => TailRec.suspend(a(x).flatMap(b))
-      }
-    }
-
-  def main(args: Array[String]): Unit = {
-    val gFortyTwo = g(42)
-    println("g(42) = " + gFortyTwo)
-    println("run(g(42)) = " + run(gFortyTwo))
-  }
-}
-
-object IO2c {
-
-  import fpinscala.parallelism.Nonblocking._
-
-  /*
-   * We've solved our first problem of ensuring stack safety, but we're still
-   * being very inexplicit about what sort of effects can occur, and we also
-   * haven't found a way of describing asynchronous computations. Our `Suspend`
-   * thunks will just block the current thread when run by the interpreter.
-   * We could fix that by changing the signature of `Suspend` to take a `Par`.
-   * We'll call this new type `Async`.
-   */
-
-  sealed trait Async[A] { // will rename this type to `Async`
-    def flatMap[B](f: A => Async[B]): Async[B] =
-      FlatMap(this, f)
-    def map[B](f: A => B): Async[B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[A](a: A) extends Async[A]
-  case class Suspend[A](resume: Par[A]) extends Async[A] // notice this is a `Par`
-  case class FlatMap[A,B](sub: Async[A], k: A => Async[B]) extends Async[B]
-
-  object Async extends Monad[Async] {
-    def unit[A](a: => A): Async[A] = Return(a)
-    def flatMap[A,B](a: Async[A])(f: A => Async[B]): Async[B] = a flatMap f
-  }
-
-  // return either a `Suspend`, a `Return`, or a right-associated `FlatMap`
-  @annotation.tailrec def step[A](async: Async[A]): Async[A] = async match {
-    case FlatMap(FlatMap(x, f), g) => step(x flatMap (a => f(a) flatMap g))
-    case FlatMap(Return(x), f) => step(f(x))
-    case _ => async
-  }
-
-  def run[A](async: Async[A]): Par[A] = step(async) match {
-    case Return(a) => Par.unit(a)
-    case Suspend(r) => r
-    case FlatMap(x, f) => x match {
-      case Suspend(r) => Par.flatMap(r)(a => run(f(a)))
-      case _ => sys.error("Impossible, since `step` eliminates these cases")
-    }
-  }
-  // The fact that `run` only uses the `unit` and `flatMap` functions of
-  // `Par` is a clue that choosing `Par` was too specific of a choice,
-  // this interpreter could be generalized to work with any monad.
-}
-
-
-object IO3 {
-
-  /*
-  We can generalize `TailRec` and `Async` to the type `Free`, which is
-  a `Monad` for any choice of `F`.
-  */
-
-  sealed trait Free[F[_],A] {
-    def flatMap[B](f: A => Free[F,B]): Free[F,B] =
-      FlatMap(this, f)
-    def map[B](f: A => B): Free[F,B] =
-      flatMap(f andThen (Return(_)))
-  }
-  case class Return[F[_],A](a: A) extends Free[F, A]
-  case class Suspend[F[_],A](s: F[A]) extends Free[F, A]
-  case class FlatMap[F[_],A,B](s: Free[F, A],
-                               f: A => Free[F, B]) extends Free[F, B]
-
-  // Exercise 1: Implement the free monad
-  def freeMonad[F[_]]: Monad[({type f[a] = Free[F,a]})#f] = ???
-
-  // Exercise 2: Implement a specialized `Function0` interpreter.
-  // @annotation.tailrec
-  def runTrampoline[A](a: Free[Function0,A]): A = ???
-
-  // Exercise 3: Implement a `Free` interpreter which works for any `Monad`
-  def run[F[_],A](a: Free[F,A])(implicit F: Monad[F]): F[A] = ???
-
-  // return either a `Suspend`, a `Return`, or a right-associated `FlatMap`
-  // @annotation.tailrec
-  def step[F[_],A](a: Free[F,A]): Free[F,A] = ???
-
-  /*
-  The type constructor `F` lets us control the set of external requests our
-  program is allowed to make. For instance, here is a type that allows for
-  only console I/O effects.
-  */
-
-  import fpinscala.parallelism.Nonblocking.Par
-
-  sealed trait Console[A] {
-    def toPar: Par[A]
-    def toThunk: () => A
-
-    // other interpreters
-    def toState: ConsoleState[A]
-    def toReader: ConsoleReader[A]
-  }
-
-  case object ReadLine extends Console[Option[String]] {
-    def toPar = Par.lazyUnit(run)
-    def toThunk = () => run
-
-    def run: Option[String] =
-      try Some(readLine())
-      catch { case e: Exception => None }
-
-    def toState = ConsoleState { bufs =>
-      bufs.in match {
-        case List() => (None, bufs)
-        case h :: t => (Some(h), bufs.copy(in = t))
-      }
-    }
-    def toReader = ConsoleReader { in => Some(in) }
-  }
-
-  case class PrintLine(line: String) extends Console[Unit] {
-    def toPar = Par.lazyUnit(println(line))
-    def toThunk = () => println(line)
-    def toReader = ConsoleReader { s => () } // noop
-    def toState = ConsoleState { bufs => ((), bufs.copy(out = bufs.out :+ line)) } // append to the output
-  }
-
-  object Console {
-    type ConsoleIO[A] = Free[Console, A]
-
-    def readLn: ConsoleIO[Option[String]] =
-      Suspend(ReadLine)
-
-    def printLn(line: String): ConsoleIO[Unit] =
-      Suspend(PrintLine(line))
-  }
-
-  /*
-  How do we actually _run_ a `ConsoleIO` program? We don't have a `Monad[Console]`
-  for calling `run`, and we can't use `runTrampoline` either since we have `Console`,
-  not `Function0`. We need a way to translate from `Console` to `Function0`
-  (if we want to evaluate it sequentially) or a `Par`.
-
-  We introduce the following type to do this translation:
-  */
-
-  /* Translate between any `F[A]` to `G[A]`. */
-  trait Translate[F[_], G[_]] { def apply[A](f: F[A]): G[A] }
-
-  type ~>[F[_], G[_]] = Translate[F,G] // gives us infix syntax `F ~> G` for `Translate[F,G]`
-
-  implicit val function0Monad = new Monad[Function0] {
-    def unit[A](a: => A) = () => a
-    def flatMap[A,B](a: Function0[A])(f: A => Function0[B]) =
-      () => f(a())()
-  }
-
-  implicit val parMonad = new Monad[Par] {
-    def unit[A](a: => A) = Par.unit(a)
-    def flatMap[A,B](a: Par[A])(f: A => Par[B]) = Par.fork { Par.flatMap(a)(f) }
-  }
-
-  def runFree[F[_],G[_],A](free: Free[F,A])(t: F ~> G)(
-                           implicit G: Monad[G]): G[A] =
-    step(free) match {
-      case Return(a) => G.unit(a)
-      case Suspend(r) => t(r)
-      case FlatMap(Suspend(r), f) => G.flatMap(t(r))(a => runFree(f(a))(t))
-      case _ => sys.error("Impossible, since `step` eliminates these cases")
-    }
-
-  val consoleToFunction0 =
-    new (Console ~> Function0) { def apply[A](a: Console[A]) = a.toThunk }
-  val consoleToPar =
-    new (Console ~> Par) { def apply[A](a: Console[A]) = a.toPar }
-
-  def runConsoleFunction0[A](a: Free[Console,A]): () => A =
-    runFree[Console,Function0,A](a)(consoleToFunction0)
-  def runConsolePar[A](a: Free[Console,A]): Par[A] =
-    runFree[Console,Par,A](a)(consoleToPar)
-
-  /*
-  The `runConsoleFunction0` implementation is unfortunately not stack safe,
-  because it relies of the stack safety of the underlying monad, and the
-  `Function0` monad we gave is not stack safe. To see the problem, try
-  running: `freeMonad.forever(Console.printLn("Hello"))`.
-  */
-
-  // Exercise 4 (optional, hard): Implement `runConsole` using `runFree`,
-  // without going through `Par`. Hint: define `translate` using `runFree`.
-
-  def translate[F[_],G[_],A](f: Free[F,A])(fg: F ~> G): Free[G,A] = ???
-
-  def runConsole[A](a: Free[Console,A]): A = ???
-
-  /*
-  There is nothing about `Free[Console,A]` that requires we interpret
-  `Console` using side effects. Here are two pure ways of interpreting
-  a `Free[Console,A]`.
-  */
-  import Console._
-
-  case class Buffers(in: List[String], out: Vector[String])
-
-  // A specialized state monad
-  case class ConsoleState[A](run: Buffers => (A, Buffers)) {
-    def map[B](f: A => B): ConsoleState[B] =
-      ConsoleState { s =>
-        val (a, s1) = run(s)
-        (f(a), s1)
-      }
-    def flatMap[B](f: A => ConsoleState[B]): ConsoleState[B] =
-      ConsoleState { s =>
-        val (a, s1) = run(s)
-        f(a).run(s1)
-      }
-  }
-  object ConsoleState {
-    implicit val monad = new Monad[ConsoleState] {
-      def unit[A](a: => A) = ConsoleState(bufs => (a,bufs))
-      def flatMap[A,B](ra: ConsoleState[A])(f: A => ConsoleState[B]) = ra flatMap f
-    }
-  }
-
-  // A specialized reader monad
-  case class ConsoleReader[A](run: String => A) {
-    def map[B](f: A => B): ConsoleReader[B] =
-      ConsoleReader(r => f(run(r)))
-    def flatMap[B](f: A => ConsoleReader[B]): ConsoleReader[B] =
-      ConsoleReader(r => f(run(r)).run(r))
-  }
-  object ConsoleReader {
-    implicit val monad = new Monad[ConsoleReader] {
-      def unit[A](a: => A) = ConsoleReader(_ => a)
-      def flatMap[A,B](ra: ConsoleReader[A])(f: A => ConsoleReader[B]) = ra flatMap f
-    }
-  }
-
-  val consoleToState =
-    new (Console ~> ConsoleState) { def apply[A](a: Console[A]) = a.toState }
-  val consoleToReader =
-    new (Console ~> ConsoleReader) { def apply[A](a: Console[A]) = a.toReader }
-
-  /* Can interpet these as before to convert our `ConsoleIO` to a pure value that does no I/O! */
-  def runConsoleReader[A](io: ConsoleIO[A]): ConsoleReader[A] =
-    runFree[Console,ConsoleReader,A](io)(consoleToReader)
-
-  def runConsoleState[A](io: ConsoleIO[A]): ConsoleState[A] =
-    runFree[Console,ConsoleState,A](io)(consoleToState)
-
-  // So `Free[F,A]` is not really an I/O type. The interpreter `runFree` gets
-  // to choose how to interpret these `F` requests, and whether to do "real" I/O
-  // or simply convert to some pure value!
-
-  // NB: These interpretations are not stack safe for the same reason,
-  // can instead work with `case class ConsoleReader[A](run: String => Trampoline[A])`,
-  // which gives us a stack safe monad
-
-  // We conclude that a good representation of an `IO` monad is this:
-  type IO[A] = Free[Par, A]
-
-  /*
-   * Exercise 5: Implement a non-blocking read from an asynchronous file channel.
-   * We'll just give the basic idea - here, we construct a `Future`
-   * by reading from an `AsynchronousFileChannel`, a `java.nio` class
-   * which supports asynchronous reads.
-   */
-
-  import java.nio._
-  import java.nio.channels._
-
-  def read(file: AsynchronousFileChannel,
-           fromPosition: Long,
-           numBytes: Int): Par[Either[Throwable, Array[Byte]]] = ???
-
-  // Provides the syntax `Async { k => ... }` for asyncronous IO blocks.
-  def Async[A](cb: (A => Unit) => Unit): IO[A] =
-    Suspend(Par.async(cb))
-
-  // Provides the `IO { ... }` syntax for synchronous IO blocks.
-  def IO[A](a: => A): IO[A] = Suspend { Par.delay(a) }
-}
diff --git a/exercises/src/main/scala/fpinscala/iomonad/Monad.scala b/exercises/src/main/scala/fpinscala/iomonad/Monad.scala
deleted file mode 100644
index 3727d54..0000000
--- a/exercises/src/main/scala/fpinscala/iomonad/Monad.scala
+++ /dev/null
@@ -1,73 +0,0 @@
-package fpinscala.iomonad
-
-import language.higherKinds // Disable warnings for type constructor polymorphism
-import language.implicitConversions
-
-trait Functor[F[_]] {
-  def map[A,B](a: F[A])(f: A => B): F[B]
-}
-
-trait Monad[F[_]] extends Functor[F] {
-  def unit[A](a: => A): F[A]
-  def flatMap[A,B](a: F[A])(f: A => F[B]): F[B]
-
-  def map[A,B](a: F[A])(f: A => B): F[B] = flatMap(a)(a => unit(f(a)))
-  def map2[A,B,C](a: F[A], b: F[B])(f: (A,B) => C): F[C] =
-    flatMap(a)(a => map(b)(b => f(a,b)))
-  def sequence_[A](fs: Stream[F[A]]): F[Unit] = foreachM(fs)(skip)
-  def sequence_[A](fs: F[A]*): F[Unit] = sequence_(fs.toStream)
-  def replicateM[A](n: Int)(f: F[A]): F[List[A]] =
-    Stream.fill(n)(f).foldRight(unit(List[A]()))(map2(_,_)(_ :: _))
-  def replicateM_[A](n: Int)(f: F[A]): F[Unit] =
-    foreachM(Stream.fill(n)(f))(skip)
-  def as[A,B](a: F[A])(b: B): F[B] = map(a)(_ => b)
-  def skip[A](a: F[A]): F[Unit] = as(a)(())
-  def when[A](b: Boolean)(fa: => F[A]): F[Boolean] =
-    if (b) as(fa)(true) else unit(false)
-  def forever[A,B](a: F[A]): F[B] = {
-    lazy val t: F[B] = a flatMap (_ => t)
-    t
-  }
-  def while_(a: F[Boolean])(b: F[Unit]): F[Unit] = {
-    lazy val t: F[Unit] = while_(a)(b)
-    a flatMap (c => skip(when(c)(t)))
-  }
-  def doWhile[A](a: F[A])(cond: A => F[Boolean]): F[Unit] = for {
-    a1 <- a
-    ok <- cond(a1)
-    _ <- if (ok) doWhile(a)(cond) else unit(())
-  } yield ()
-
-  def foldM[A,B](l: Stream[A])(z: B)(f: (B,A) => F[B]): F[B] =
-    l match {
-      case h #:: t => f(z,h) flatMap (z2 => foldM(t)(z2)(f))
-      case _ => unit(z)
-    }
-  def foldM_[A,B](l: Stream[A])(z: B)(f: (B,A) => F[B]): F[Unit] =
-    skip { foldM(l)(z)(f) }
-  def foreachM[A](l: Stream[A])(f: A => F[Unit]): F[Unit] =
-    foldM_(l)(())((u,a) => skip(f(a)))
-  def seq[A,B,C](f: A => F[B])(g: B => F[C]): A => F[C] =
-    f andThen (fb => flatMap(fb)(g))
-
-  // syntax
-  implicit def toMonadic[A](a: F[A]): Monadic[F,A] =
-    new Monadic[F,A] { val F = Monad.this; def get = a }
-}
-
-trait Monadic[F[_],A] {
-  val F: Monad[F]
-  import F._
-  def get: F[A]
-  private val a = get
-  def map[B](f: A => B): F[B] = F.map(a)(f)
-  def flatMap[B](f: A => F[B]): F[B] = F.flatMap(a)(f)
-  def **[B](b: F[B]) = F.map2(a,b)((_,_))
-  def *>[B](b: F[B]) = F.map2(a,b)((_,b) => b)
-  def map2[B,C](b: F[B])(f: (A,B) => C): F[C] = F.map2(a,b)(f)
-  def as[B](b: B): F[B] = F.as(a)(b)
-  def skip: F[Unit] = F.skip(a)
-  def replicateM(n: Int) = F.replicateM(n)(a)
-  def replicateM_(n: Int) = F.replicateM_(n)(a)
-}
-
diff --git a/exercises/src/main/scala/fpinscala/iomonad/Task.scala b/exercises/src/main/scala/fpinscala/iomonad/Task.scala
deleted file mode 100644
index ab0363b..0000000
--- a/exercises/src/main/scala/fpinscala/iomonad/Task.scala
+++ /dev/null
@@ -1,66 +0,0 @@
-package fpinscala.iomonad
-
-import fpinscala.parallelism.Nonblocking._
-import java.util.concurrent.ExecutorService
-
-/*
- * `Task[A]` is a wrapper around `Free[Par, Either[Throwable, A]]`, with some
- * convenience functions for handling exceptions.
- */
-case class Task[A](get: IO[Either[Throwable, A]]) {
-
-  def flatMap[B](f: A => Task[B]): Task[B] =
-    Task(get.flatMap {
-      case Left(e) => IO(Left(e))
-      case Right(a) => f(a).get
-    })
-
-  def map[B](f: A => B): Task[B] = flatMap(f andThen (Task.now))
-
-  /* 'Catches' exceptions in the given task and returns them as values. */
-  def attempt: Task[Either[Throwable,A]] =
-    Task(get map {
-      case Left(e) => Right(Left(e))
-      case Right(a) => Right(Right(a))
-    })
-
-  def handle[B>:A](f: PartialFunction[Throwable,B]): Task[B] =
-    attempt flatMap {
-      case Left(e) => f.lift(e) map (Task.now) getOrElse Task.fail(e)
-      case Right(a) => Task.now(a)
-    }
-
-  def or[B>:A](t2: Task[B]): Task[B] =
-    Task(this.get flatMap {
-      case Left(e) => t2.get
-      case a => IO(a)
-    })
-
-  def run(implicit E: ExecutorService): A = unsafePerformIO(get) match {
-    case Left(e) => throw e
-    case Right(a) => a
-  }
-
-  def attemptRun(implicit E: ExecutorService): Either[Throwable,A] =
-    try unsafePerformIO(get) catch { case t: Throwable => Left(t) }
-}
-
-object Task extends Monad[Task] {
-  def unit[A](a: => A) = Task(IO(Try(a)))
-
-  def flatMap[A,B](a: Task[A])(f: A => Task[B]): Task[B] =
-    a flatMap f
-
-  def fail[A](e: Throwable): Task[A] = Task(IO(Left(e)))
-  def now[A](a: A): Task[A] = Task(Return(Right(a)))
-
-  def more[A](a: => Task[A]): Task[A] = Task.now(()) flatMap (_ => a)
-
-  def delay[A](a: => A): Task[A] = more(now(a))
-  def fork[A](a: => Task[A]): Task[A] =
-    Task { par { Par.lazyUnit(()) } flatMap (_ => a.get) }
-  def forkUnit[A](a: => A): Task[A] = fork(now(a))
-
-  def Try[A](a: => A): Either[Throwable,A] =
-    try Right(a) catch { case e: Throwable => Left(e) }
-}
diff --git a/exercises/src/main/scala/fpinscala/iomonad/package.scala b/exercises/src/main/scala/fpinscala/iomonad/package.scala
deleted file mode 100644
index 29c2b6e..0000000
--- a/exercises/src/main/scala/fpinscala/iomonad/package.scala
+++ /dev/null
@@ -1,37 +0,0 @@
-package fpinscala
-
-import language.higherKinds
-
-package object iomonad {
-  import fpinscala.parallelism.Nonblocking._
-
-  type IO[A] = IO3.IO[A]
-  def IO[A](a: => A): IO[A] = IO3.IO[A](a)
-
-  implicit val ioMonad = IO3.freeMonad[Par]
-
-  def now[A](a: A): IO[A] = IO3.Return(a)
-
-  def fork[A](a: => IO[A]): IO[A] = par(Par.lazyUnit(())) flatMap (_ => a)
-
-  def forkUnit[A](a: => A): IO[A] = fork(now(a))
-
-  def delay[A](a: => A): IO[A] = now(()) flatMap (_ => now(a))
-
-  def par[A](a: Par[A]): IO[A] = IO3.Suspend(a)
-
-  def async[A](cb: ((A => Unit) => Unit)): IO[A] =
-    fork(par(Par.async(cb)))
-
-  type Free[F[_], A] = IO3.Free[F, A]
-
-  def Return[A](a: A): IO[A] = IO3.Return[Par,A](a)
-
-  // To run an `IO`, we need an executor service.
-  // The name we have chosen for this method, `unsafePerformIO`,
-  // reflects that is is unsafe, i.e. that it has side effects,
-  // and that it _performs_ the actual I/O.
-  import java.util.concurrent.ExecutorService
-  def unsafePerformIO[A](io: IO[A])(implicit E: ExecutorService): A =
-    Par.run(E) { IO3.run(io)(IO3.parMonad) }
-}
diff --git a/exercises/src/main/scala/fpinscala/laziness/Stream.scala b/exercises/src/main/scala/fpinscala/laziness/Stream.scala
deleted file mode 100644
index e7405bc..0000000
--- a/exercises/src/main/scala/fpinscala/laziness/Stream.scala
+++ /dev/null
@@ -1,55 +0,0 @@
-package fpinscala.laziness
-
-import Stream._
-trait Stream[+A] {
-
-  def foldRight[B](z: => B)(f: (A, => B) => B): B = // The arrow `=>` in front of the argument type `B` means that the function `f` takes its second argument by name and may choose not to evaluate it.
-    this match {
-      case Cons(h,t) => f(h(), t().foldRight(z)(f)) // If `f` doesn't evaluate its second argument, the recursion never occurs.
-      case _ => z
-    }
-
-  def exists(p: A => Boolean): Boolean = 
-    foldRight(false)((a, b) => p(a) || b) // Here `b` is the unevaluated recursive step that folds the tail of the stream. If `p(a)` returns `true`, `b` will never be evaluated and the computation terminates early.
-
-  @annotation.tailrec
-  final def find(f: A => Boolean): Option[A] = this match {
-    case Empty => None
-    case Cons(h, t) => if (f(h())) Some(h()) else t().find(f)
-  }
-  def take(n: Int): Stream[A] = ???
-
-  def drop(n: Int): Stream[A] = ???
-
-  def takeWhile(p: A => Boolean): Stream[A] = ???
-
-  def forAll(p: A => Boolean): Boolean = ???
-
-  def headOption: Option[A] = ???
-
-  // 5.7 map, filter, append, flatmap using foldRight. Part of the exercise is
-  // writing your own function signatures.
-
-  def startsWith[B](s: Stream[B]): Boolean = ???
-}
-case object Empty extends Stream[Nothing]
-case class Cons[+A](h: () => A, t: () => Stream[A]) extends Stream[A]
-
-object Stream {
-  def cons[A](hd: => A, tl: => Stream[A]): Stream[A] = {
-    lazy val head = hd
-    lazy val tail = tl
-    Cons(() => head, () => tail)
-  }
-
-  def empty[A]: Stream[A] = Empty
-
-  def apply[A](as: A*): Stream[A] =
-    if (as.isEmpty) empty 
-    else cons(as.head, apply(as.tail: _*))
-
-  val ones: Stream[Int] = Stream.cons(1, ones)
-  def from(n: Int): Stream[Int] = ???
-
-  def unfold[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] = ???
-}
\ No newline at end of file
diff --git a/exercises/src/main/scala/fpinscala/localeffects/LocalEffects.scala b/exercises/src/main/scala/fpinscala/localeffects/LocalEffects.scala
deleted file mode 100644
index 433c79c..0000000
--- a/exercises/src/main/scala/fpinscala/localeffects/LocalEffects.scala
+++ /dev/null
@@ -1,143 +0,0 @@
-package fpinscala.localeffects
-
-import fpinscala.monads._
-
-object Mutable {
-  def quicksort(xs: List[Int]): List[Int] = if (xs.isEmpty) xs else {
-    val arr = xs.toArray
-    def swap(x: Int, y: Int) = {
-      val tmp = arr(x)
-      arr(x) = arr(y)
-      arr(y) = tmp
-    }
-    def partition(l: Int, r: Int, pivot: Int) = {
-      val pivotVal = arr(pivot)
-      swap(pivot, r)
-      var j = l
-      for (i <- l until r) if (arr(i) < pivotVal) {
-        swap(i, j)
-        j += 1
-      }
-      swap(j, r)
-      j
-    }
-    def qs(l: Int, r: Int): Unit = if (l < r) {
-      val pi = partition(l, r, l + (r - l) / 2)
-      qs(l, pi - 1)
-      qs(pi + 1, r)
-    }
-    qs(0, arr.length - 1)
-    arr.toList
-  }
-}
-
-sealed trait ST[S,A] { self =>
-  protected def run(s: S): (A,S)
-  def map[B](f: A => B): ST[S,B] = new ST[S,B] {
-    def run(s: S) = {
-      val (a, s1) = self.run(s)
-      (f(a), s1)
-    }
-  }
-  def flatMap[B](f: A => ST[S,B]): ST[S,B] = new ST[S,B] {
-    def run(s: S) = {
-      val (a, s1) = self.run(s)
-      f(a).run(s1)
-    }
-  }
-}
-
-object ST {
-  def apply[S,A](a: => A) = {
-    lazy val memo = a
-    new ST[S,A] {
-      def run(s: S) = (memo, s)
-    }
-  }
-  def runST[A](st: RunnableST[A]): A =
-    st[Null].run(null)._1
-}
-
-sealed trait STRef[S,A] {
-  protected var cell: A
-  def read: ST[S,A] = ST(cell)
-  def write(a: => A): ST[S,Unit] = new ST[S,Unit] {
-    def run(s: S) = {
-      cell = a
-      ((), s)
-    }
-  }
-}
-
-object STRef {
-  def apply[S,A](a: A): ST[S, STRef[S,A]] = ST(new STRef[S,A] {
-    var cell = a
-  })
-}
-
-trait RunnableST[A] {
-  def apply[S]: ST[S,A]
-}
-
-// Scala requires an implicit Manifest for constructing arrays.
-sealed abstract class STArray[S,A](implicit manifest: Manifest[A]) {
-  protected def value: Array[A]
-  def size: ST[S,Int] = ST(value.size)
-
-  // Write a value at the give index of the array
-  def write(i: Int, a: A): ST[S,Unit] = new ST[S,Unit] {
-    def run(s: S) = {
-      value(i) = a
-      ((), s)
-    }
-  }
-
-  // Read the value at the given index of the array
-  def read(i: Int): ST[S,A] = ST(value(i))
-
-  // Turn the array into an immutable list
-  def freeze: ST[S,List[A]] = ST(value.toList)
-
-  def fill(xs: Map[Int,A]): ST[S,Unit] = ???
-
-  def swap(i: Int, j: Int): ST[S,Unit] = for {
-    x <- read(i)
-    y <- read(j)
-    _ <- write(i, y)
-    _ <- write(j, x)
-  } yield ()
-}
-
-object STArray {
-  // Construct an array of the given size filled with the value v
-  def apply[S,A:Manifest](sz: Int, v: A): ST[S, STArray[S,A]] =
-    ST(new STArray[S,A] {
-      lazy val value = Array.fill(sz)(v)
-    })
-
-  def fromList[S,A:Manifest](xs: List[A]): ST[S, STArray[S,A]] =
-    ST(new STArray[S,A] {
-      lazy val value = xs.toArray
-    })
-}
-
-object Immutable {
-  def noop[S] = ST[S,Unit](())
-
-  def partition[S](a: STArray[S,Int], l: Int, r: Int, pivot: Int): ST[S,Int] = ???
-
-  def qs[S](a: STArray[S,Int], l: Int, r: Int): ST[S, Unit] = ???
-
-  def quicksort(xs: List[Int]): List[Int] =
-    if (xs.isEmpty) xs else ST.runST(new RunnableST[List[Int]] {
-      def apply[S] = for {
-        arr    <- STArray.fromList(xs)
-        size   <- arr.size
-        _      <- qs(arr, 0, size - 1)
-        sorted <- arr.freeze
-      } yield sorted
-  })
-}
-
-import scala.collection.mutable.HashMap
-
diff --git a/exercises/src/main/scala/fpinscala/monads/Monad.scala b/exercises/src/main/scala/fpinscala/monads/Monad.scala
deleted file mode 100644
index f13552f..0000000
--- a/exercises/src/main/scala/fpinscala/monads/Monad.scala
+++ /dev/null
@@ -1,93 +0,0 @@
-package fpinscala
-package monads
-
-import parsing._
-import testing._
-import parallelism._
-import state._
-import parallelism.Par._
-import language.higherKinds
-
-
-trait Functor[F[_]] {
-  def map[A,B](fa: F[A])(f: A => B): F[B]
-
-  def distribute[A,B](fab: F[(A, B)]): (F[A], F[B]) =
-    (map(fab)(_._1), map(fab)(_._2))
-
-  def codistribute[A,B](e: Either[F[A], F[B]]): F[Either[A, B]] = e match {
-    case Left(fa) => map(fa)(Left(_))
-    case Right(fb) => map(fb)(Right(_))
-  }
-}
-
-object Functor {
-  val listFunctor = new Functor[List] {
-    def map[A,B](as: List[A])(f: A => B): List[B] = as map f
-  }
-}
-
-trait Monad[M[_]] extends Functor[M] {
-  def unit[A](a: => A): M[A]
-  def flatMap[A,B](ma: M[A])(f: A => M[B]): M[B]
-
-  def map[A,B](ma: M[A])(f: A => B): M[B] =
-    flatMap(ma)(a => unit(f(a)))
-  def map2[A,B,C](ma: M[A], mb: M[B])(f: (A, B) => C): M[C] =
-    flatMap(ma)(a => map(mb)(b => f(a, b)))
-
-  def sequence[A](lma: List[M[A]]): M[List[A]] = ???
-
-  def traverse[A,B](la: List[A])(f: A => M[B]): M[List[B]] = ???
-
-  def replicateM[A](n: Int, ma: M[A]): M[List[A]] = ???
-
-  def compose[A,B,C](f: A => M[B], g: B => M[C]): A => M[C] = ???
-
-  // Implement in terms of `compose`:
-  def _flatMap[A,B](ma: M[A])(f: A => M[B]): M[B] = ???
-
-  def join[A](mma: M[M[A]]): M[A] = ???
-
-  // Implement in terms of `join`:
-  def __flatMap[A,B](ma: M[A])(f: A => M[B]): M[B] = ???
-}
-
-case class Reader[R, A](run: R => A)
-
-object Monad {
-  val genMonad = new Monad[Gen] {
-    def unit[A](a: => A): Gen[A] = Gen.unit(a)
-    override def flatMap[A,B](ma: Gen[A])(f: A => Gen[B]): Gen[B] =
-      ma flatMap f
-  }
-
-  val parMonad: Monad[Par] = ???
-
-  def parserMonad[P[+_]](p: Parsers[P]): Monad[P] = ???
-
-  val optionMonad: Monad[Option] = ???
-
-  val streamMonad: Monad[Stream] = ???
-
-  val listMonad: Monad[List] = ???
-
-  def stateMonad[S] = ???
-
-  val idMonad: Monad[Id] = ???
-
-  def readerMonad[R] = ???
-}
-
-case class Id[A](value: A) {
-  def map[B](f: A => B): Id[B] = ???
-  def flatMap[B](f: A => Id[B]): Id[B] = ???
-}
-
-object Reader {
-  def readerMonad[R] = new Monad[({type f[x] = Reader[R,x]})#f] {
-    def unit[A](a: => A): Reader[R,A] = ???
-    override def flatMap[A,B](st: Reader[R,A])(f: A => Reader[R,B]): Reader[R,B] = ???
-  }
-}
-
diff --git a/exercises/src/main/scala/fpinscala/monoids/Monoid.scala b/exercises/src/main/scala/fpinscala/monoids/Monoid.scala
deleted file mode 100644
index 7bf2afe..0000000
--- a/exercises/src/main/scala/fpinscala/monoids/Monoid.scala
+++ /dev/null
@@ -1,159 +0,0 @@
-package fpinscala.monoids
-
-import fpinscala.parallelism.Nonblocking._
-import fpinscala.parallelism.Nonblocking.Par.toParOps // infix syntax for `Par.map`, `Par.flatMap`, etc
-import language.higherKinds
-
-trait Monoid[A] {
-  def op(a1: A, a2: A): A
-  def zero: A
-}
-
-object Monoid {
-
-  val stringMonoid = new Monoid[String] {
-    def op(a1: String, a2: String) = a1 + a2
-    val zero = ""
-  }
-
-  def listMonoid[A] = new Monoid[List[A]] {
-    def op(a1: List[A], a2: List[A]) = a1 ++ a2
-    val zero = Nil
-  }
-
-  val intAddition: Monoid[Int] = ???
-
-  val intMultiplication: Monoid[Int] = ???
-
-  val booleanOr: Monoid[Boolean] = ???
-
-  val booleanAnd: Monoid[Boolean] = ???
-
-  def optionMonoid[A]: Monoid[Option[A]] = ???
-
-  def endoMonoid[A]: Monoid[A => A] = ???
-
-  // TODO: Placeholder for `Prop`. Remove once you have implemented the `Prop`
-  // data type from Part 2.
-  trait Prop {}
-
-  // TODO: Placeholder for `Gen`. Remove once you have implemented the `Gen`
-  // data type from Part 2.
-
-  import fpinscala.testing._
-  import Prop._
-  def monoidLaws[A](m: Monoid[A], gen: Gen[A]): Prop = ???
-
-  def trimMonoid(s: String): Monoid[String] = ???
-
-  def concatenate[A](as: List[A], m: Monoid[A]): A =
-    ???
-
-  def foldMap[A, B](as: List[A], m: Monoid[B])(f: A => B): B =
-    ???
-
-  def foldRight[A, B](as: List[A])(z: B)(f: (A, B) => B): B =
-    ???
-
-  def foldLeft[A, B](as: List[A])(z: B)(f: (B, A) => B): B =
-    ???
-
-  def foldMapV[A, B](as: IndexedSeq[A], m: Monoid[B])(f: A => B): B =
-    ???
-
-  def ordered(ints: IndexedSeq[Int]): Boolean =
-    ???
-
-  sealed trait WC
-  case class Stub(chars: String) extends WC
-  case class Part(lStub: String, words: Int, rStub: String) extends WC
-
-  def par[A](m: Monoid[A]): Monoid[Par[A]] = 
-    ???
-
-  def parFoldMap[A,B](v: IndexedSeq[A], m: Monoid[B])(f: A => B): Par[B] = 
-    ???
-
-  val wcMonoid: Monoid[WC] = ???
-
-  def count(s: String): Int = ???
-
-  def productMonoid[A,B](A: Monoid[A], B: Monoid[B]): Monoid[(A, B)] =
-    ???
-
-  def functionMonoid[A,B](B: Monoid[B]): Monoid[A => B] =
-    ???
-
-  def mapMergeMonoid[K,V](V: Monoid[V]): Monoid[Map[K, V]] =
-    ???
-
-  def bag[A](as: IndexedSeq[A]): Map[A, Int] =
-    ???
-}
-
-trait Foldable[F[_]] {
-  import Monoid._
-
-  def foldRight[A, B](as: F[A])(z: B)(f: (A, B) => B): B =
-    ???
-
-  def foldLeft[A, B](as: F[A])(z: B)(f: (B, A) => B): B =
-    ???
-
-  def foldMap[A, B](as: F[A])(f: A => B)(mb: Monoid[B]): B =
-    ???
-
-  def concatenate[A](as: F[A])(m: Monoid[A]): A =
-    ???
-
-  def toList[A](as: F[A]): List[A] =
-    ???
-}
-
-object ListFoldable extends Foldable[List] {
-  override def foldRight[A, B](as: List[A])(z: B)(f: (A, B) => B) =
-    ???
-  override def foldLeft[A, B](as: List[A])(z: B)(f: (B, A) => B) =
-    ???
-  override def foldMap[A, B](as: List[A])(f: A => B)(mb: Monoid[B]): B =
-    ???
-}
-
-object IndexedSeqFoldable extends Foldable[IndexedSeq] {
-  override def foldRight[A, B](as: IndexedSeq[A])(z: B)(f: (A, B) => B) =
-    ???
-  override def foldLeft[A, B](as: IndexedSeq[A])(z: B)(f: (B, A) => B) =
-    ???
-  override def foldMap[A, B](as: IndexedSeq[A])(f: A => B)(mb: Monoid[B]): B =
-    ???
-}
-
-object StreamFoldable extends Foldable[Stream] {
-  override def foldRight[A, B](as: Stream[A])(z: B)(f: (A, B) => B) =
-    ???
-  override def foldLeft[A, B](as: Stream[A])(z: B)(f: (B, A) => B) =
-    ???
-}
-
-sealed trait Tree[+A]
-case class Leaf[A](value: A) extends Tree[A]
-case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]
-
-object TreeFoldable extends Foldable[Tree] {
-  override def foldMap[A, B](as: Tree[A])(f: A => B)(mb: Monoid[B]): B =
-    ???
-  override def foldLeft[A, B](as: Tree[A])(z: B)(f: (B, A) => B) =
-    ???
-  override def foldRight[A, B](as: Tree[A])(z: B)(f: (A, B) => B) =
-    ???
-}
-
-object OptionFoldable extends Foldable[Option] {
-  override def foldMap[A, B](as: Option[A])(f: A => B)(mb: Monoid[B]): B =
-    ???
-  override def foldLeft[A, B](as: Option[A])(z: B)(f: (B, A) => B) =
-    ???
-  override def foldRight[A, B](as: Option[A])(z: B)(f: (A, B) => B) =
-    ???
-}
-
diff --git a/exercises/src/main/scala/fpinscala/parallelism/Actor.scala b/exercises/src/main/scala/fpinscala/parallelism/Actor.scala
deleted file mode 100644
index dc74f8e..0000000
--- a/exercises/src/main/scala/fpinscala/parallelism/Actor.scala
+++ /dev/null
@@ -1,138 +0,0 @@
-package fpinscala.parallelism
-
-import java.util.concurrent.atomic.{AtomicInteger, AtomicReference}
-import java.util.concurrent.{Callable,ExecutorService}
-import annotation.tailrec
-
-/*
- * Implementation is taken from `scalaz` library, with only minor changes. See:
- *
- * https://github.com/scalaz/scalaz/blob/scalaz-seven/concurrent/src/main/scala/scalaz/concurrent/Actor.scala
- *
- * This code is copyright Andriy Plokhotnyuk, Runar Bjarnason, and other contributors,
- * and is licensed using 3-clause BSD, see LICENSE file at:
- *
- * https://github.com/scalaz/scalaz/blob/scalaz-seven/etc/LICENCE
- */
-
-/**
- * Processes messages of type `A`, one at a time. Messages are submitted to
- * the actor with the method `!`. Processing is typically performed asynchronously,
- * this is controlled by the provided `strategy`.
- *
- * Memory consistency guarantee: when each message is processed by the `handler`, any memory that it
- * mutates is guaranteed to be visible by the `handler` when it processes the next message, even if
- * the `strategy` runs the invocations of `handler` on separate threads. This is achieved because
- * the `Actor` reads a volatile memory location before entering its event loop, and writes to the same
- * location before suspending.
- *
- * Implementation based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:
- * [[http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue]]
- *
- * @see scalaz.concurrent.Promise for a use case.
- *
- * @param handler  The message handler
- * @param onError  Exception handler, called if the message handler throws any `Throwable`.
- * @param strategy Execution strategy, for example, a strategy that is backed by an `ExecutorService`
- * @tparam A       The type of messages accepted by this actor.
- */
-final class Actor[A](strategy: Strategy)(handler: A => Unit, onError: Throwable => Unit = throw(_)) {
-  self =>
-
-  private val tail = new AtomicReference(new Node[A]())
-  private val suspended = new AtomicInteger(1)
-  private val head = new AtomicReference(tail.get)
-
-  /** Alias for `apply` */
-  def !(a: A) {
-    val n = new Node(a)
-    head.getAndSet(n).lazySet(n)
-    trySchedule()
-  }
-
-  /** Pass the message `a` to the mailbox of this actor */
-  def apply(a: A) {
-    this ! a
-  }
-
-  def contramap[B](f: B => A): Actor[B] =
-    new Actor[B](strategy)((b: B) => (this ! f(b)), onError)
-
-  private def trySchedule() {
-    if (suspended.compareAndSet(1, 0)) schedule()
-  }
-
-  private def schedule() {
-    strategy(act())
-  }
-
-  private def act() {
-    val t = tail.get
-    val n = batchHandle(t, 1024)
-    if (n ne t) {
-      n.a = null.asInstanceOf[A]
-      tail.lazySet(n)
-      schedule()
-    } else {
-      suspended.set(1)
-      if (n.get ne null) trySchedule()
-    }
-  }
-
-  @tailrec
-  private def batchHandle(t: Node[A], i: Int): Node[A] = {
-    val n = t.get
-    if (n ne null) {
-      try {
-        handler(n.a)
-      } catch {
-        case ex: Throwable => onError(ex)
-      }
-      if (i > 0) batchHandle(n, i - 1) else n
-    } else t
-  }
-}
-
-private class Node[A](var a: A = null.asInstanceOf[A]) extends AtomicReference[Node[A]]
-
-object Actor {
-
-  /** Create an `Actor` backed by the given `ExecutorService`. */
-  def apply[A](es: ExecutorService)(handler: A => Unit, onError: Throwable => Unit = throw(_)): Actor[A] =
-    new Actor(Strategy.fromExecutorService(es))(handler, onError)
-}
-
-/**
- * Provides a function for evaluating expressions, possibly asynchronously.
- * The `apply` function should typically begin evaluating its argument
- * immediately. The returned thunk can be used to block until the resulting `A`
- * is available.
- */
-trait Strategy {
-  def apply[A](a: => A): () => A
-}
-
-object Strategy {
-
-  /**
-   * We can create a `Strategy` from any `ExecutorService`. It's a little more
-   * convenient than submitting `Callable` objects directly.
-   */
-  def fromExecutorService(es: ExecutorService): Strategy = new Strategy {
-    def apply[A](a: => A): () => A = {
-      val f = es.submit { new Callable[A] { def call = a} }
-      () => f.get
-    }
-  }
-
-  /**
-   * A `Strategy` which begins executing its argument immediately in the calling thread.
-   */
-  def sequential: Strategy = new Strategy {
-    def apply[A](a: => A): () => A = {
-      val r = a
-      () => r
-    }
-  }
-}
-
diff --git a/exercises/src/main/scala/fpinscala/parallelism/Nonblocking.scala b/exercises/src/main/scala/fpinscala/parallelism/Nonblocking.scala
deleted file mode 100644
index 4cddf51..0000000
--- a/exercises/src/main/scala/fpinscala/parallelism/Nonblocking.scala
+++ /dev/null
@@ -1,174 +0,0 @@
-package fpinscala.parallelism
-
-import java.util.concurrent.{Callable, CountDownLatch, ExecutorService}
-import java.util.concurrent.atomic.AtomicReference
-import language.implicitConversions
-
-object Nonblocking {
-
-  trait Future[+A] {
-    private[parallelism] def apply(k: A => Unit): Unit
-  }
-
-  type Par[+A] = ExecutorService => Future[A]
-
-  object Par {
-
-    def run[A](es: ExecutorService)(p: Par[A]): A = {
-      val ref = new java.util.concurrent.atomic.AtomicReference[A] // A mutable, threadsafe reference, to use for storing the result
-      val latch = new CountDownLatch(1) // A latch which, when decremented, implies that `ref` has the result
-      p(es) { a => ref.set(a); latch.countDown } // Asynchronously set the result, and decrement the latch
-      latch.await // Block until the `latch.countDown` is invoked asynchronously
-      ref.get // Once we've passed the latch, we know `ref` has been set, and return its value
-    }
-
-    def unit[A](a: A): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          cb(a)
-      }
-
-    /** A non-strict version of `unit` */
-    def delay[A](a: => A): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          cb(a)
-      }
-
-    def fork[A](a: => Par[A]): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          eval(es)(a(es)(cb))
-      }
-
-    /**
-     * Helper function for constructing `Par` values out of calls to non-blocking continuation-passing-style APIs.
-     * This will come in handy in Chapter 13.
-     */
-    def async[A](f: (A => Unit) => Unit): Par[A] = es => new Future[A] {
-      def apply(k: A => Unit) = f(k)
-    }
-
-    /**
-     * Helper function, for evaluating an action
-     * asynchronously, using the given `ExecutorService`.
-     */
-    def eval(es: ExecutorService)(r: => Unit): Unit =
-      es.submit(new Callable[Unit] { def call = r })
-
-
-    def map2[A,B,C](p: Par[A], p2: Par[B])(f: (A,B) => C): Par[C] =
-      es => new Future[C] {
-        def apply(cb: C => Unit): Unit = {
-          var ar: Option[A] = None
-          var br: Option[B] = None
-          val combiner = Actor[Either[A,B]](es) {
-            case Left(a) =>
-              if (br.isDefined) eval(es)(cb(f(a,br.get)))
-              else ar = Some(a)
-            case Right(b) =>
-              if (ar.isDefined) eval(es)(cb(f(ar.get,b)))
-              else br = Some(b)
-          }
-          p(es)(a => combiner ! Left(a))
-          p2(es)(b => combiner ! Right(b))
-        }
-      }
-
-    // specialized version of `map`
-    def map[A,B](p: Par[A])(f: A => B): Par[B] =
-      es => new Future[B] {
-        def apply(cb: B => Unit): Unit =
-          p(es)(a => eval(es) { cb(f(a)) })
-      }
-
-    def lazyUnit[A](a: => A): Par[A] =
-      fork(unit(a))
-
-    def asyncF[A,B](f: A => B): A => Par[B] =
-      a => lazyUnit(f(a))
-
-    def sequenceRight[A](as: List[Par[A]]): Par[List[A]] =
-      as match {
-        case Nil => unit(Nil)
-        case h :: t => map2(h, fork(sequence(t)))(_ :: _)
-      }
-
-    def sequenceBalanced[A](as: IndexedSeq[Par[A]]): Par[IndexedSeq[A]] = fork {
-      if (as.isEmpty) unit(Vector())
-      else if (as.length == 1) map(as.head)(a => Vector(a))
-      else {
-        val (l,r) = as.splitAt(as.length/2)
-        map2(sequenceBalanced(l), sequenceBalanced(r))(_ ++ _)
-      }
-    }
-
-    def sequence[A](as: List[Par[A]]): Par[List[A]] =
-      map(sequenceBalanced(as.toIndexedSeq))(_.toList)
-
-    // exercise answers
-
-    /*
-     * We can implement `choice` as a new primitive.
-     *
-     * `p(es)(result => ...)` for some `ExecutorService`, `es`, and
-     * some `Par`, `p`, is the idiom for running `p`, and registering
-     * a callback to be invoked when its result is available. The
-     * result will be bound to `result` in the function passed to
-     * `p(es)`.
-     *
-     * If you find this code difficult to follow, you may want to
-     * write down the type of each subexpression and follow the types
-     * through the implementation. What is the type of `p(es)`? What
-     * about `t(es)`? What about `t(es)(cb)`?
-     */
-    def choice[A](p: Par[Boolean])(t: Par[A], f: Par[A]): Par[A] =
-      es => new Future[A] {
-        def apply(cb: A => Unit): Unit =
-          p(es) { b =>
-            if (b) eval(es) { t(es)(cb) }
-            else eval(es) { f(es)(cb) }
-          }
-      }
-
-    def choiceN[A](p: Par[Int])(ps: List[Par[A]]): Par[A] = ???
-
-    def choiceViaChoiceN[A](a: Par[Boolean])(ifTrue: Par[A], ifFalse: Par[A]): Par[A] =
-      ???
-
-    def choiceMap[K,V](p: Par[K])(ps: Map[K,Par[V]]): Par[V] =
-      ???
-
-    // see `Nonblocking.scala` answers file. This function is usually called something else!
-    def chooser[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-      ???
-
-    def flatMap[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-      ???
-
-    def choiceViaChooser[A](p: Par[Boolean])(f: Par[A], t: Par[A]): Par[A] =
-      ???
-
-    def choiceNChooser[A](p: Par[Int])(choices: List[Par[A]]): Par[A] =
-      ???
-
-    def join[A](p: Par[Par[A]]): Par[A] =
-      ???
-
-    def joinViaFlatMap[A](a: Par[Par[A]]): Par[A] =
-      ???
-
-    def flatMapViaJoin[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
-      ???
-
-    /* Gives us infix syntax for `Par`. */
-    implicit def toParOps[A](p: Par[A]): ParOps[A] = new ParOps(p)
-
-    // infix versions of `map`, `map2`
-    class ParOps[A](p: Par[A]) {
-      def map[B](f: A => B): Par[B] = Par.map(p)(f)
-      def map2[B,C](b: Par[B])(f: (A,B) => C): Par[C] = Par.map2(p,b)(f)
-      def zip[B](b: Par[B]): Par[(A,B)] = p.map2(b)((_,_))
-    }
-  }
-}
diff --git a/exercises/src/main/scala/fpinscala/parallelism/Par.scala b/exercises/src/main/scala/fpinscala/parallelism/Par.scala
deleted file mode 100644
index f790e48..0000000
--- a/exercises/src/main/scala/fpinscala/parallelism/Par.scala
+++ /dev/null
@@ -1,67 +0,0 @@
-package fpinscala.parallelism
-
-import java.util.concurrent._
-import language.implicitConversions
-
-object Par {
-  type Par[A] = ExecutorService => Future[A]
-  
-  def run[A](s: ExecutorService)(a: Par[A]): Future[A] = a(s)
-
-  def unit[A](a: A): Par[A] = (es: ExecutorService) => UnitFuture(a) // `unit` is represented as a function that returns a `UnitFuture`, which is a simple implementation of `Future` that just wraps a constant value. It doesn't use the `ExecutorService` at all. It's always done and can't be cancelled. Its `get` method simply returns the value that we gave it.
-  
-  private case class UnitFuture[A](get: A) extends Future[A] {
-    def isDone = true 
-    def get(timeout: Long, units: TimeUnit) = get 
-    def isCancelled = false 
-    def cancel(evenIfRunning: Boolean): Boolean = false 
-  }
-  
-  def map2[A,B,C](a: Par[A], b: Par[B])(f: (A,B) => C): Par[C] = // `map2` doesn't evaluate the call to `f` in a separate logical thread, in accord with our design choice of having `fork` be the sole function in the API for controlling parallelism. We can always do `fork(map2(a,b)(f))` if we want the evaluation of `f` to occur in a separate thread.
-    (es: ExecutorService) => {
-      val af = a(es) 
-      val bf = b(es)
-      UnitFuture(f(af.get, bf.get)) // This implementation of `map2` does _not_ respect timeouts, and eagerly waits for the returned futures. This means that even if you have passed in "forked" arguments, using this map2 on them will make them wait. It simply passes the `ExecutorService` on to both `Par` values, waits for the results of the Futures `af` and `bf`, applies `f` to them, and wraps them in a `UnitFuture`. In order to respect timeouts, we'd need a new `Future` implementation that records the amount of time spent evaluating `af`, then subtracts that time from the available time allocated for evaluating `bf`.
-    }
-  
-  def fork[A](a: => Par[A]): Par[A] = // This is the simplest and most natural implementation of `fork`, but there are some problems with it--for one, the outer `Callable` will block waiting for the "inner" task to complete. Since this blocking occupies a thread in our thread pool, or whatever resource backs the `ExecutorService`, this implies that we're losing out on some potential parallelism. Essentially, we're using two threads when one should suffice. This is a symptom of a more serious problem with the implementation, and we will discuss this later in the chapter.
-    es => es.submit(new Callable[A] { 
-      def call = a(es).get
-    })
-
-  def map[A,B](pa: Par[A])(f: A => B): Par[B] = 
-    map2(pa, unit(()))((a,_) => f(a))
-
-  def sortPar(parList: Par[List[Int]]) = map(parList)(_.sorted)
-
-  def equal[A](e: ExecutorService)(p: Par[A], p2: Par[A]): Boolean = 
-    p(e).get == p2(e).get
-
-  def delay[A](fa: => Par[A]): Par[A] = 
-    es => fa(es)
-
-  def choice[A](cond: Par[Boolean])(t: Par[A], f: Par[A]): Par[A] =
-    es => 
-      if (run(es)(cond).get) t(es) // Notice we are blocking on the result of `cond`.
-      else f(es)
-
-  /* Gives us infix syntax for `Par`. */
-  implicit def toParOps[A](p: Par[A]): ParOps[A] = new ParOps(p)
-
-  class ParOps[A](p: Par[A]) {
-
-
-  }
-}
-
-object Examples {
-  import Par._
-  def sum(ints: IndexedSeq[Int]): Int = // `IndexedSeq` is a superclass of random-access sequences like `Vector` in the standard library. Unlike lists, these sequences provide an efficient `splitAt` method for dividing them into two parts at a particular index.
-    if (ints.size <= 1)
-      ints.headOption getOrElse 0 // `headOption` is a method defined on all collections in Scala. We saw this function in chapter 3.
-    else { 
-      val (l,r) = ints.splitAt(ints.length/2) // Divide the sequence in half using the `splitAt` function.
-      sum(l) + sum(r) // Recursively sum both halves and add the results together.
-    }
-
-}
diff --git a/exercises/src/main/scala/fpinscala/parsing/Parsers.scala b/exercises/src/main/scala/fpinscala/parsing/Parsers.scala
deleted file mode 100644
index ec4b25e..0000000
--- a/exercises/src/main/scala/fpinscala/parsing/Parsers.scala
+++ /dev/null
@@ -1,34 +0,0 @@
-package fpinscala.parsing
-
-import language.higherKinds
-
-trait Parsers[Parser[+_]] { self => // so inner classes may call methods of trait
-
-  case class ParserOps[A](p: Parser[A]) {
-
-
-  }
-
-  object Laws {
-  }
-}
-
-case class Location(input: String, offset: Int = 0) {
-
-  lazy val line = input.slice(0,offset+1).count(_ == '\n') + 1
-  lazy val col = input.slice(0,offset+1).reverse.indexOf('\n')
-
-  def toError(msg: String): ParseError =
-    ParseError(List((this, msg)))
-
-  def advanceBy(n: Int) = copy(offset = offset+n)
-
-  /* Returns the line corresponding to this location */
-  def currentLine: String = 
-    if (input.length > 1) input.lines.drop(line-1).next
-    else ""
-}
-
-case class ParseError(stack: List[(Location,String)] = List(),
-                      otherFailures: List[ParseError] = List()) {
-}
\ No newline at end of file
diff --git a/exercises/src/main/scala/fpinscala/state/State.scala b/exercises/src/main/scala/fpinscala/state/State.scala
deleted file mode 100644
index d92558f..0000000
--- a/exercises/src/main/scala/fpinscala/state/State.scala
+++ /dev/null
@@ -1,70 +0,0 @@
-package fpinscala.state
-
-
-trait RNG {
-  def nextInt: (Int, RNG) // Should generate a random `Int`. We'll later define other functions in terms of `nextInt`.
-}
-
-object RNG {
-  // NB - this was called SimpleRNG in the book text
-
-  case class Simple(seed: Long) extends RNG {
-    def nextInt: (Int, RNG) = {
-      val newSeed = (seed * 0x5DEECE66DL + 0xBL) & 0xFFFFFFFFFFFFL // `&` is bitwise AND. We use the current seed to generate a new seed.
-      val nextRNG = Simple(newSeed) // The next state, which is an `RNG` instance created from the new seed.
-      val n = (newSeed >>> 16).toInt // `>>>` is right binary shift with zero fill. The value `n` is our new pseudo-random integer.
-      (n, nextRNG) // The return value is a tuple containing both a pseudo-random integer and the next `RNG` state.
-    }
-  }
-
-  type Rand[+A] = RNG => (A, RNG)
-
-  val int: Rand[Int] = _.nextInt
-
-  def unit[A](a: A): Rand[A] =
-    rng => (a, rng)
-
-  def map[A,B](s: Rand[A])(f: A => B): Rand[B] =
-    rng => {
-      val (a, rng2) = s(rng)
-      (f(a), rng2)
-    }
-
-  def nonNegativeInt(rng: RNG): (Int, RNG) = ???
-
-  def double(rng: RNG): (Double, RNG) = ???
-
-  def intDouble(rng: RNG): ((Int,Double), RNG) = ???
-
-  def doubleInt(rng: RNG): ((Double,Int), RNG) = ???
-
-  def double3(rng: RNG): ((Double,Double,Double), RNG) = ???
-
-  def ints(count: Int)(rng: RNG): (List[Int], RNG) = ???
-
-  def map2[A,B,C](ra: Rand[A], rb: Rand[B])(f: (A, B) => C): Rand[C] = ???
-
-  def sequence[A](fs: List[Rand[A]]): Rand[List[A]] = ???
-
-  def flatMap[A,B](f: Rand[A])(g: A => Rand[B]): Rand[B] = ???
-}
-
-case class State[S,+A](run: S => (A, S)) {
-  def map[B](f: A => B): State[S, B] =
-    ???
-  def map2[B,C](sb: State[S, B])(f: (A, B) => C): State[S, C] =
-    ???
-  def flatMap[B](f: A => State[S, B]): State[S, B] =
-    ???
-}
-
-sealed trait Input
-case object Coin extends Input
-case object Turn extends Input
-
-case class Machine(locked: Boolean, candies: Int, coins: Int)
-
-object State {
-  type Rand[A] = State[RNG, A]
-  def simulateMachine(inputs: List[Input]): State[Machine, (Int, Int)] = ???
-}
diff --git a/exercises/src/main/scala/fpinscala/streamingio/MonadCatch.scala b/exercises/src/main/scala/fpinscala/streamingio/MonadCatch.scala
deleted file mode 100644
index 1d0f752..0000000
--- a/exercises/src/main/scala/fpinscala/streamingio/MonadCatch.scala
+++ /dev/null
@@ -1,22 +0,0 @@
-package fpinscala.streamingio
-
-import fpinscala.iomonad._
-import language.higherKinds
-
-/*
- * A context in which exceptions can be caught and
- * thrown.
- */
-trait MonadCatch[F[_]] extends Monad[F] {
-  def attempt[A](a: F[A]): F[Either[Throwable,A]]
-  def fail[A](t: Throwable): F[A]
-}
-
-object MonadCatch {
-  implicit def task = new MonadCatch[Task] {
-    def unit[A](a: => A): Task[A] = Task.unit(a)
-    def flatMap[A,B](a: Task[A])(f: A => Task[B]): Task[B] = a flatMap f
-    def attempt[A](a: Task[A]): Task[Either[Throwable,A]] = a.attempt
-    def fail[A](err: Throwable): Task[A] = Task.fail(err)
-  }
-}
diff --git a/exercises/src/main/scala/fpinscala/streamingio/StreamingIO.scala b/exercises/src/main/scala/fpinscala/streamingio/StreamingIO.scala
deleted file mode 100644
index bd47215..0000000
--- a/exercises/src/main/scala/fpinscala/streamingio/StreamingIO.scala
+++ /dev/null
@@ -1,1030 +0,0 @@
-package fpinscala.streamingio
-
-import fpinscala.iomonad.{IO,Monad,Free,unsafePerformIO}
-import language.implicitConversions
-import language.higherKinds
-import language.postfixOps
-
-object ImperativeAndLazyIO {
-
-                            /*
-
-  We are going to consider various approaches to the simple task of
-  checking whether a file contains more than 40,000 lines.
-
-  Our first implementation is an imperative implementation, embedded
-  into `IO`.
-                             */
-
-  import java.io._
-
-  def linesGt40k(filename: String): IO[Boolean] = IO {
-    // There are a number of convenience functions in scala.io.Source
-    // for reading from external sources such as files.
-    val src = io.Source.fromFile(filename)
-    try {
-      var count = 0
-      // Obtain a stateful iterator from the Source
-      val lines: Iterator[String] = src.getLines
-      while (count <= 40000 && lines.hasNext) {
-        lines.next // has side effect of advancing to next element
-        count += 1
-      }
-      count > 40000
-    }
-    finally src.close
-  }
-
-                            /*
-
-  The above code is rather low-level, and it's not compositional,
-  either. Consider the following scenarios:
-
-  * Check whether the number of _nonempty_ lines in the file exceeds
-    40,000
-  * Find a line index before 40,000 where the first letter of
-    consecutive lines spells out `"abracadabra"`.
-
-  We cannot just compose our existing implementation with some
-  other combinator(s) to implement these tasks. Our implementation is
-  a monolithic loop, and we must modify this loop directly if we want
-  to change its behavior.
-
-  Now imagine if we had a `Stream[String]` for the lines of the file
-  and we could assemble functionality using all the `Stream` functions
-  we know and love.
-                             */
-
-  object Examples {
-    val lines: Stream[String] = sys.error("defined elsewhere")
-    val ex1 = lines.zipWithIndex.exists(_._2 + 1 >= 40000)
-    val ex2 = lines.filter(!_.trim.isEmpty).zipWithIndex.exists(_._2 + 1 >= 40000)
-    val ex3 = lines.take(40000).map(_.head).indexOfSlice("abracadabra".toList)
-  }
-
-                            /*
-
-  Could we actually write the above? Not quite. We could 'cheat' and
-  return an `IO[Stream[String]]` representing the lines of a file:
-
-                             */
-
-  def lines(filename: String): IO[Stream[String]] = IO {
-    val src = io.Source.fromFile(filename)
-    src.getLines.toStream append { src.close; Stream.empty }
-  }
-                            /*
-
-  This is called _lazy I/O_, and it's problematic for a number of
-  reasons, discussed in the book text. However, it would be nice to
-  recover the same high-level, compositional style we are used to
-  from our use of `List` and `Stream`.
-
-                             */
-}
-
-object SimpleStreamTransducers {
-
-                            /*
-
-  We now introduce a type, `Process`, representing pure, single-input
-  stream transducers. It can be in of three states - it can be
-  emitting a value to the output (`Emit`), reading a value from its
-  input (`Await`) or signaling termination via `Halt`.
-
-                             */
-
-  sealed trait Process[I,O] {
-    import Process._
-
-    /*
-     * A `Process[I,O]` can be used to transform a `Stream[I]` to a
-     * `Stream[O]`.
-     */
-    def apply(s: Stream[I]): Stream[O] = this match {
-      case Halt() => Stream()
-      case Await(recv) => s match {
-        case h #:: t => recv(Some(h))(t)
-        case xs => recv(None)(xs) // Stream is empty
-      }
-      case Emit(h,t) => h #:: t(s)
-    }
-
-    /*
-     * `Process` can be thought of as a sequence of values of type `O`
-     * and many of the operations that would be defined for `List[O]`
-     * can be defined for `Process[I,O]`, for instance `map`, `++` and
-     * `flatMap`. The definitions are analogous.
-     */
-
-    def map[O2](f: O => O2): Process[I,O2] = this match {
-      case Halt() => Halt()
-      case Emit(h, t) => Emit(f(h), t map f)
-      case Await(recv) => Await(recv andThen (_ map f))
-    }
-    def ++(p: => Process[I,O]): Process[I,O] = this match {
-      case Halt() => p
-      case Emit(h, t) => Emit(h, t ++ p)
-      case Await(recv) => Await(recv andThen (_ ++ p))
-    }
-    def flatMap[O2](f: O => Process[I,O2]): Process[I,O2] = this match {
-      case Halt() => Halt()
-      case Emit(h, t) => f(h) ++ t.flatMap(f)
-      case Await(recv) => Await(recv andThen (_ flatMap f))
-    }
-
-    /*
-     * Exercise 5: Implement `|>`. Let the types guide your implementation.
-     */
-    def |>[O2](p2: Process[O,O2]): Process[I,O2] = ???
-
-    /*
-     * Feed `in` to this `Process`. Uses a tail recursive loop as long
-     * as `this` is in the `Await` state.
-     */
-    def feed(in: Seq[I]): Process[I,O] = {
-      @annotation.tailrec
-      def go(in: Seq[I], cur: Process[I,O]): Process[I,O] =
-        cur match {
-          case Halt() => Halt()
-          case Await(recv) =>
-            if (in.nonEmpty) go(in.tail, recv(Some(in.head)))
-            else cur
-          case Emit(h, t) => Emit(h, t.feed(in))
-        }
-      go(in, this)
-    }
-
-
-    /*
-     * See `Process.lift` for a typical repeating `Process`
-     * definition expressed with explicit recursion.
-     */
-
-    /*
-     * `Process` definitions can often be expressed without explicit
-     * recursion, by repeating some simpler `Process` forever.
-     */
-    def repeat: Process[I,O] = {
-      def go(p: Process[I,O]): Process[I,O] = p match {
-        case Halt() => go(this)
-        case Await(recv) => Await {
-          case None => recv(None)
-          case i => go(recv(i))
-        }
-        case Emit(h, t) => Emit(h, go(t))
-      }
-      go(this)
-    }
-
-    def repeatN(n: Int): Process[I,O] = {
-      def go(n: Int, p: Process[I,O]): Process[I,O] = p match {
-        case Halt() => if (n > 0) go(n-1, this) else Halt()
-        case Await(recv) => Await {
-          case None => recv(None)
-          case i => go(n,recv(i))
-        }
-        case Emit(h, t) => Emit(h, go(n,t))
-      }
-      go(n, this)
-    }
-
-    /*
-     * As an example of `repeat`, see `Process.filter`. We define
-     * a convenience function here for composing this `Process`
-     * with a `Process` that filters the output type `O`.
-     */
-    def filter(f: O => Boolean): Process[I,O] =
-      this |> Process.filter(f)
-
-    /*
-     * Exercise 6: Implement `zipWithIndex`.
-     */
-    def zipWithIndex: Process[I,(O,Int)] = ???
-
-    /* Add `p` to the fallback branch of this process */
-    def orElse(p: Process[I,O]): Process[I,O] = this match {
-      case Halt() => p
-      case Await(recv) => Await {
-        case None => p
-        case x => recv(x)
-      }
-      case _ => this
-    }
-  }
-
-  object Process {
-
-    case class Emit[I,O](
-        head: O,
-        tail: Process[I,O] = Halt[I,O]())
-      extends Process[I,O]
-
-    case class Await[I,O](
-        recv: Option[I] => Process[I,O])
-      extends Process[I,O]
-
-    case class Halt[I,O]() extends Process[I,O]
-
-    def emit[I,O](head: O,
-                  tail: Process[I,O] = Halt[I,O]()): Process[I,O] =
-      Emit(head, tail)
-
-    // Process forms a monad, and we provide monad syntax for it
-
-    import fpinscala.iomonad.Monad
-
-    def monad[I]: Monad[({ type f[x] = Process[I,x]})#f] =
-      new Monad[({ type f[x] = Process[I,x]})#f] {
-        def unit[O](o: => O): Process[I,O] = emit(o)
-        def flatMap[O,O2](p: Process[I,O])(f: O => Process[I,O2]): Process[I,O2] =
-          p flatMap f
-      }
-
-    // enable monadic syntax for `Process` type
-    implicit def toMonadic[I,O](a: Process[I,O]) = monad[I].toMonadic(a)
-
-    /**
-     * A helper function to await an element or fall back to another process
-     * if there is no input.
-     */
-    def await[I,O](f: I => Process[I,O],
-                   fallback: Process[I,O] = Halt[I,O]()): Process[I,O] =
-      Await[I,O] {
-        case Some(i) => f(i)
-        case None => fallback
-      }
-
-    /*
-     * We can convert any function `f: I => O` to a `Process[I,O]`. We
-     * simply `Await`, then `Emit` the value received, transformed by
-     * `f`.
-     */
-    def liftOne[I,O](f: I => O): Process[I,O] =
-      Await {
-        case Some(i) => emit(f(i))
-        case None => Halt()
-      }
-
-    def lift[I,O](f: I => O): Process[I,O] =
-      liftOne(f).repeat
-
-    /*
-     * As an example of `repeat`, here's a definition of `filter` that
-     * uses `repeat`.
-     */
-    def filter[I](f: I => Boolean): Process[I,I] =
-      Await[I,I] {
-        case Some(i) if f(i) => emit(i)
-        case _ => Halt()
-      }.repeat
-
-    /*
-     * Here's a typical `Process` definition that requires tracking some
-     * piece of state (in this case, the running total):
-     */
-    def sum: Process[Double,Double] = {
-      def go(acc: Double): Process[Double,Double] =
-        await(d => emit(d+acc, go(d+acc)))
-      go(0.0)
-    }
-
-    /*
-     * Exercise 1: Implement `take`, `drop`, `takeWhile`, and `dropWhile`.
-     */
-    def take[I](n: Int): Process[I,I] = ???
-
-    def drop[I](n: Int): Process[I,I] = ???
-
-    def takeWhile[I](f: I => Boolean): Process[I,I] = ???
-
-    def dropWhile[I](f: I => Boolean): Process[I,I] = ???
-
-    /* The identity `Process`, just repeatedly echos its input. */
-    def id[I]: Process[I,I] = lift(identity)
-
-    /*
-     * Exercise 2: Implement `count`.
-     */
-    def count[I]: Process[I,Int] = ???
-
-    /* For comparison, here is an explicit recursive implementation. */
-    def count2[I]: Process[I,Int] = {
-      def go(n: Int): Process[I,Int] =
-        await((i: I) => emit(n+1, go(n+1)))
-      go(0)
-    }
-
-    /*
-     * Exercise 3: Implement `mean`.
-     */
-    def mean: Process[Double,Double] = ???
-
-    def loop[S,I,O](z: S)(f: (I,S) => (O,S)): Process[I,O] =
-      await((i: I) => f(i,z) match {
-        case (o,s2) => emit(o, loop(s2)(f))
-      })
-
-    /* Exercise 4: Implement `sum` and `count` in terms of `loop` */
-
-    def sum2: Process[Double,Double] = ???
-
-    def count3[I]: Process[I,Int] = ???
-
-    /*
-     * Exercise 7: Can you think of a generic combinator that would
-     * allow for the definition of `mean` in terms of `sum` and
-     * `count`?
-     */
-
-    def feed[A,B](oa: Option[A])(p: Process[A,B]): Process[A,B] =
-      p match {
-        case Halt() => p
-        case Emit(h,t) => Emit(h, feed(oa)(t))
-        case Await(recv) => recv(oa)
-      }
-
-    /*
-     * Exercise 6: Implement `zipWithIndex`.
-     *
-     * See definition on `Process` above.
-     */
-
-    /*
-     * Exercise 8: Implement `exists`
-     *
-     * We choose to emit all intermediate values, and not halt.
-     * See `existsResult` below for a trimmed version.
-     */
-    def exists[I](f: I => Boolean): Process[I,Boolean] = ???
-
-    /* Awaits then emits a single value, then halts. */
-    def echo[I]: Process[I,I] = await(i => emit(i))
-
-    def skip[I,O]: Process[I,O] = await(i => Halt())
-    def ignore[I,O]: Process[I,O] = skip.repeat
-
-    def terminated[I]: Process[I,Option[I]] =
-      await((i: I) => emit(Some(i), terminated[I]), emit(None))
-
-    def processFile[A,B](f: java.io.File,
-                         p: Process[String, A],
-                         z: B)(g: (B, A) => B): IO[B] = IO {
-      @annotation.tailrec
-      def go(ss: Iterator[String], cur: Process[String, A], acc: B): B =
-        cur match {
-          case Halt() => acc
-          case Await(recv) =>
-            val next = if (ss.hasNext) recv(Some(ss.next))
-                       else recv(None)
-            go(ss, next, acc)
-          case Emit(h, t) => go(ss, t, g(acc, h))
-        }
-      val s = io.Source.fromFile(f)
-      try go(s.getLines, p, z)
-      finally s.close
-    }
-
-    /*
-     * Exercise 9: Write a program that reads degrees fahrenheit as `Double` values from a file,
-     * converts each temperature to celsius, and writes results to another file.
-     */
-
-    def toCelsius(fahrenheit: Double): Double =
-      (5.0 / 9.0) * (fahrenheit - 32.0)
-  }
-}
-
-object GeneralizedStreamTransducers {
-
-                            /*
-
-  Our generalized process type is parameterized on the protocol used for
-  communicating with the driver. This works similarly to the `IO` type
-  we defined in chapter 13. The `Await` constructor emits a request of
-  type `F[A]`, and receives a response of type `Either[Throwable,A]`:
-
-    trait Process[F,A]
-    case class Await[F[_],A,O](
-      req: F[A],
-      recv: Either[Throwable,A] => Process[F,O]) extends Process[F,O]
-    case class Halt[F[_],O](err: Throwable) extends Process[F,O]
-    case class Emit[F[_],O](head: O, tail: Process[F,O]) extends Process[F,O]
-
-  The `Await` constructor may now receive a successful result or an error.
-
-  The `Halt` constructor now has a _reason_ for termination, which may be
-  either normal termination indicated by the special exception `End`,
-  forceful terimation, indicated by the special exception `Kill`,
-  or some other error.
-
-  We'll use the improved `Await` and `Halt` cases together to ensure
-  that all resources get released, even in the event of exceptions.
-
-                             */
-
-  trait Process[F[_],O] {
-    import Process._
-
-    /*
-     * Many of the same operations can be defined for this generalized
-     * `Process` type, regardless of the choice of `F`.
-     */
-
-    def map[O2](f: O => O2): Process[F,O2] = this match {
-      case Await(req,recv) =>
-        Await(req, recv andThen (_ map f))
-      case Emit(h, t) => Try { Emit(f(h), t map f) }
-      case Halt(err) => Halt(err)
-    }
-
-    def ++(p: => Process[F,O]): Process[F,O] =
-      this.onHalt {
-        case End => Try(p) // we consult `p` only on normal termination
-        case err => Halt(err)
-      }
-
-    /*
-     * Like `++`, but _always_ runs `p`, even if `this` halts with an error.
-     */
-    def onComplete(p: => Process[F,O]): Process[F,O] =
-      this.onHalt {
-        case End => p.asFinalizer
-        case err => p.asFinalizer ++ Halt(err) // we always run `p`, but preserve any errors
-      }
-
-    def asFinalizer: Process[F,O] = this match {
-      case Emit(h, t) => Emit(h, t.asFinalizer)
-      case Halt(e) => Halt(e)
-      case Await(req,recv) => await(req) {
-        case Left(Kill) => this.asFinalizer
-        case x => recv(x)
-      }
-    }
-
-    def onHalt(f: Throwable => Process[F,O]): Process[F,O] = this match {
-      case Halt(e) => Try(f(e))
-      case Emit(h, t) => Emit(h, t.onHalt(f))
-      case Await(req,recv) => Await(req, recv andThen (_.onHalt(f)))
-    }
-
-    /*
-     * Anywhere we _call_ `f`, we catch exceptions and convert them to `Halt`.
-     * See the helper function `Try` defined below.
-     */
-    def flatMap[O2](f: O => Process[F,O2]): Process[F,O2] =
-      this match {
-        case Halt(err) => Halt(err)
-        case Emit(o, t) => Try(f(o)) ++ t.flatMap(f)
-        case Await(req,recv) =>
-          Await(req, recv andThen (_ flatMap f))
-      }
-
-    def repeat: Process[F,O] =
-      this ++ this.repeat
-
-    def repeatNonempty: Process[F,O] = {
-      val cycle = (this.map(o => Some(o): Option[O]) ++ emit(None)).repeat
-      // cut off the cycle when we see two `None` values in a row, as this
-      // implies `this` has produced no values during an iteration
-      val trimmed = cycle |> window2 |> (takeWhile {
-        case (Some(None), None) => false
-        case _ => true
-      })
-      trimmed.map(_._2).flatMap {
-        case None => Halt(End)
-        case Some(o) => emit(o)
-      }
-    }
-
-    /*
-     * Exercise 10: This function is defined only if given a `MonadCatch[F]`.
-     * Unlike the simple `runLog` interpreter defined in the companion object
-     * below, this is not tail recursive and responsibility for stack safety
-     * is placed on the `Monad` instance.
-     */
-    def runLog(implicit F: MonadCatch[F]): F[IndexedSeq[O]] = ???
-
-    /*
-     * We define `Process1` as a type alias - see the companion object
-     * for `Process` below. Using that, we can then define `|>` once
-     * more. The definition is extremely similar to our previous
-     * definition. We again use the helper function, `feed`, to take
-     * care of the case where `this` is emitting values while `p2`
-     * is awaiting these values.
-     *
-     * The one subtlety is we make sure that if `p2` halts, we
-     * `kill` this process, giving it a chance to run any cleanup
-     * actions (like closing file handles, etc).
-     */
-    def |>[O2](p2: Process1[O,O2]): Process[F,O2] = {
-      p2 match {
-        case Halt(e) => this.kill onHalt { e2 => Halt(e) ++ Halt(e2) }
-        case Emit(h, t) => Emit(h, this |> t)
-        case Await(req,recv) => this match {
-          case Halt(err) => Halt(err) |> recv(Left(err))
-          case Emit(h,t) => t |> Try(recv(Right(h)))
-          case Await(req0,recv0) => await(req0)(recv0 andThen (_ |> p2))
-        }
-      }
-    }
-
-    @annotation.tailrec
-    final def kill[O2]: Process[F,O2] = this match {
-      case Await(req,recv) => recv(Left(Kill)).drain.onHalt {
-        case Kill => Halt(End) // we convert the `Kill` exception back to normal termination
-        case e => Halt(e)
-      }
-      case Halt(e) => Halt(e)
-      case Emit(h, t) => t.kill
-    }
-
-    /** Alias for `this |> p2`. */
-    def pipe[O2](p2: Process1[O,O2]): Process[F,O2] =
-      this |> p2
-
-    final def drain[O2]: Process[F,O2] = this match {
-      case Halt(e) => Halt(e)
-      case Emit(h, t) => t.drain
-      case Await(req,recv) => Await(req, recv andThen (_.drain))
-    }
-
-    def filter(f: O => Boolean): Process[F,O] =
-      this |> Process.filter(f)
-
-    def take(n: Int): Process[F,O] =
-      this |> Process.take(n)
-
-    def once: Process[F,O] = take(1)
-
-    /*
-     * Use a `Tee` to interleave or combine the outputs of `this` and
-     * `p2`. This can be used for zipping, interleaving, and so forth.
-     * Nothing requires that the `Tee` read elements from each
-     * `Process` in lockstep. It could read fifty elements from one
-     * side, then two elements from the other, then combine or
-     * interleave these values in some way, etc.
-     *
-     * This definition uses two helper functions, `feedL` and `feedR`,
-     * which feed the `Tee` in a tail-recursive loop as long as
-     * it is awaiting input.
-     */
-    def tee[O2,O3](p2: Process[F,O2])(t: Tee[O,O2,O3]): Process[F,O3] = {
-      t match {
-        case Halt(e) => this.kill onComplete p2.kill onComplete Halt(e)
-        case Emit(h,t) => Emit(h, (this tee p2)(t))
-        case Await(side, recv) => side.get match {
-          case Left(isO) => this match {
-            case Halt(e) => p2.kill onComplete Halt(e)
-            case Emit(o,ot) => (ot tee p2)(Try(recv(Right(o))))
-            case Await(reqL, recvL) =>
-              await(reqL)(recvL andThen (this2 => this2.tee(p2)(t)))
-          }
-          case Right(isO2) => p2 match {
-            case Halt(e) => this.kill onComplete Halt(e)
-            case Emit(o2,ot) => (this tee ot)(Try(recv(Right(o2))))
-            case Await(reqR, recvR) =>
-              await(reqR)(recvR andThen (p3 => this.tee(p3)(t)))
-          }
-        }
-      }
-    }
-
-    def zipWith[O2,O3](p2: Process[F,O2])(f: (O,O2) => O3): Process[F,O3] =
-      (this tee p2)(Process.zipWith(f))
-
-    def zip[O2](p2: Process[F,O2]): Process[F,(O,O2)] =
-      zipWith(p2)((_,_))
-
-    def to[O2](sink: Sink[F,O]): Process[F,Unit] =
-      join { (this zipWith sink)((o,f) => f(o)) }
-
-    def through[O2](p2: Channel[F, O, O2]): Process[F,O2] =
-      join { (this zipWith p2)((o,f) => f(o)) }
-  }
-
-  object Process {
-    case class Await[F[_],A,O](
-      req: F[A],
-      recv: Either[Throwable,A] => Process[F,O]) extends Process[F,O]
-
-    case class Emit[F[_],O](
-      head: O,
-      tail: Process[F,O]) extends Process[F,O]
-
-    case class Halt[F[_],O](err: Throwable) extends Process[F,O]
-
-    def emit[F[_],O](
-        head: O,
-        tail: Process[F,O] = Halt[F,O](End)): Process[F,O] =
-      Emit(head, tail)
-
-    def await[F[_],A,O](req: F[A])(recv: Either[Throwable,A] => Process[F,O]): Process[F,O] =
-      Await(req, recv)
-
-    /**
-     * Helper function to safely produce `p`, or gracefully halt
-     * with an error if an exception is thrown.
-     */
-    def Try[F[_],O](p: => Process[F,O]): Process[F,O] =
-      try p
-      catch { case e: Throwable => Halt(e) }
-
-    /*
-     * Safely produce `p`, or run `cleanup` and halt gracefully with the
-     * exception thrown while evaluating `p`.
-     */
-    def TryOr[F[_],O](p: => Process[F,O])(cleanup: Process[F,O]): Process[F,O] =
-      try p
-      catch { case e: Throwable => cleanup ++ Halt(e) }
-
-    /*
-     * Safely produce `p`, or run `cleanup` or `fallback` if an exception
-     * occurs while evaluating `p`.
-     */
-    def TryAwait[F[_],O](p: => Process[F,O])(fallback: Process[F,O], cleanup: Process[F,O]): Process[F,O] =
-      try p
-      catch {
-        case End => fallback
-        case e: Throwable => cleanup ++ Halt(e)
-      }
-
-    /* Our generalized `Process` type can represent sources! */
-
-    import fpinscala.iomonad.IO
-
-    /* Special exception indicating normal termination */
-    case object End extends Exception
-
-    /* Special exception indicating forceful termination */
-    case object Kill extends Exception
-
-    /*
-     * A `Process[F,O]` where `F` is a monad like `IO` can be thought of
-     * as a source.
-     */
-
-    /*
-     * Here is a simple tail recursive function to collect all the
-     * output of a `Process[IO,O]`. Notice we are using the fact
-     * that `IO` can be `run` to produce either a result or an
-     * exception.
-     */
-    def runLog[O](src: Process[IO,O]): IO[IndexedSeq[O]] = IO {
-      val E = java.util.concurrent.Executors.newFixedThreadPool(4)
-      @annotation.tailrec
-      def go(cur: Process[IO,O], acc: IndexedSeq[O]): IndexedSeq[O] =
-        cur match {
-          case Emit(h,t) => go(t, acc :+ h)
-          case Halt(End) => acc
-          case Halt(err) => throw err
-          case Await(req,recv) =>
-            val next =
-              try recv(Right(fpinscala.iomonad.unsafePerformIO(req)(E)))
-              catch { case err: Throwable => recv(Left(err)) }
-            go(next, acc)
-        }
-      try go(src, IndexedSeq())
-      finally E.shutdown
-    }
-
-    /*
-     * We can write a version of collect that works for any `Monad`.
-     * See the definition in the body of `Process`.
-     */
-
-    import java.io.{BufferedReader,FileReader}
-    val p: Process[IO, String] =
-      await(IO(new BufferedReader(new FileReader("lines.txt")))) {
-        case Right(b) =>
-          lazy val next: Process[IO,String] = await(IO(b.readLine)) {
-            case Left(e) => await(IO(b.close))(_ => Halt(e))
-            case Right(line) => Emit(line, next)
-          }
-          next
-        case Left(e) => Halt(e)
-      }
-
-    /*
-     * Generic combinator for producing a `Process[IO,O]` from some
-     * effectful `O` source. The source is tied to some resource,
-     * `R` (like a file handle) that we want to ensure is released.
-     * See `lines` below for an example use.
-     */
-    def resource[R,O](acquire: IO[R])(
-                      use: R => Process[IO,O])(
-                      release: R => Process[IO,O]): Process[IO,O] =
-      eval(acquire) flatMap { r => use(r).onComplete(release(r)) }
-
-    /*
-     * Like `resource`, but `release` is a single `IO` action.
-     */
-    def resource_[R,O](acquire: IO[R])(
-                       use: R => Process[IO,O])(
-                       release: R => IO[Unit]): Process[IO,O] =
-      resource(acquire)(use)(release andThen (eval_[IO,Unit,O]))
-
-    /*
-     * Create a `Process[IO,O]` from the lines of a file, using
-     * the `resource` combinator above to ensure the file is closed
-     * when processing the stream of lines is finished.
-     */
-    def lines(filename: String): Process[IO,String] =
-      resource
-        { IO(io.Source.fromFile(filename)) }
-        { src =>
-            lazy val iter = src.getLines // a stateful iterator
-            def step = if (iter.hasNext) Some(iter.next) else None
-            lazy val lines: Process[IO,String] = eval(IO(step)).flatMap {
-              case None => Halt(End)
-              case Some(line) => Emit(line, lines)
-            }
-            lines
-        }
-        { src => eval_ { IO(src.close) } }
-
-    /* Exercise 11: Implement `eval`, `eval_`, and use these to implement `lines`. */
-    def eval[F[_],A](a: F[A]): Process[F,A] = ???
-
-    /* Evaluate the action purely for its effects. */
-    def eval_[F[_],A,B](a: F[A]): Process[F,B] = ???
-
-    /* Helper function with better type inference. */
-    def evalIO[A](a: IO[A]): Process[IO,A] =
-      eval[IO,A](a)
-
-    /*
-     * We now have nice, resource safe effectful sources, but we don't
-     * have any way to transform them or filter them. Luckily we can
-     * still represent the single-input `Process` type we introduced
-     * earlier, which we'll now call `Process1`.
-     */
-
-    case class Is[I]() {
-      sealed trait f[X]
-      val Get = new f[I] {}
-    }
-    def Get[I] = Is[I]().Get
-
-    type Process1[I,O] = Process[Is[I]#f, O]
-
-    /* Some helper functions to improve type inference. */
-
-    def await1[I,O](
-        recv: I => Process1[I,O],
-        fallback: => Process1[I,O] = halt1[I,O]): Process1[I, O] =
-      Await(Get[I], (e: Either[Throwable,I]) => e match {
-        case Left(End) => fallback
-        case Left(err) => Halt(err)
-        case Right(i) => Try(recv(i))
-      })
-
-    def emit1[I,O](h: O, tl: Process1[I,O] = halt1[I,O]): Process1[I,O] =
-      emit(h, tl)
-
-    def halt1[I,O]: Process1[I,O] = Halt[Is[I]#f, O](End)
-
-    def lift[I,O](f: I => O): Process1[I,O] =
-      await1[I,O]((i:I) => emit(f(i))) repeat
-
-    def filter[I](f: I => Boolean): Process1[I,I] =
-      await1[I,I](i => if (f(i)) emit(i) else halt1) repeat
-
-    // we can define take, takeWhile, and so on as before
-
-    def take[I](n: Int): Process1[I,I] =
-      if (n <= 0) halt1
-      else await1[I,I](i => emit(i, take(n-1)))
-
-    def takeWhile[I](f: I => Boolean): Process1[I,I] =
-      await1(i =>
-        if (f(i)) emit(i, takeWhile(f))
-        else      halt1)
-
-    def dropWhile[I](f: I => Boolean): Process1[I,I] =
-      await1(i =>
-        if (f(i)) dropWhile(f)
-        else      emit(i,id))
-
-    def id[I]: Process1[I,I] =
-      await1((i: I) => emit(i, id))
-
-    def window2[I]: Process1[I,(Option[I],I)] = {
-      def go(prev: Option[I]): Process1[I,(Option[I],I)] =
-        await1[I,(Option[I],I)](i => emit(prev -> i) ++ go(Some(i)))
-      go(None)
-    }
-
-    /** Emits `sep` in between each input received. */
-    def intersperse[I](sep: I): Process1[I,I] =
-      await1[I,I](i => emit1(i) ++ id.flatMap(i => emit1(sep) ++ emit1(i)))
-
-                            /*
-
-    We sometimes need to construct a `Process` that will pull values
-    from multiple input sources. For instance, suppose we want to
-    'zip' together two files, `f1.txt` and `f2.txt`, combining
-    corresponding lines in some way. Using the same trick we used for
-    `Process1`, we can create a two-input `Process` which can request
-    values from either the 'left' stream or the 'right' stream. We'll
-    call this a `Tee`, after the letter 'T', which looks like a
-    little diagram of two inputs being combined into one output.
-
-                             */
-
-    case class T[I,I2]() {
-      sealed trait f[X] { def get: Either[I => X, I2 => X] }
-      val L = new f[I] { def get = Left(identity) }
-      val R = new f[I2] { def get = Right(identity) }
-    }
-    def L[I,I2] = T[I,I2]().L
-    def R[I,I2] = T[I,I2]().R
-
-    type Tee[I,I2,O] = Process[T[I,I2]#f, O]
-
-    /* Again some helper functions to improve type inference. */
-
-    def haltT[I,I2,O]: Tee[I,I2,O] =
-      Halt[T[I,I2]#f,O](End)
-
-    def awaitL[I,I2,O](recv: I => Tee[I,I2,O],
-                       fallback: => Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
-      await[T[I,I2]#f,I,O](L) {
-        case Left(End) => fallback
-        case Left(err) => Halt(err)
-        case Right(a) => Try(recv(a))
-      }
-
-    def awaitR[I,I2,O](recv: I2 => Tee[I,I2,O],
-                       fallback: => Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
-      await[T[I,I2]#f,I2,O](R) {
-        case Left(End) => fallback
-        case Left(err) => Halt(err)
-        case Right(a) => Try(recv(a))
-      }
-
-    def emitT[I,I2,O](h: O, tl: Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
-      emit(h, tl)
-
-    def zipWith[I,I2,O](f: (I,I2) => O): Tee[I,I2,O] =
-      awaitL[I,I2,O](i  =>
-      awaitR        (i2 => emitT(f(i,i2)))) repeat
-
-    def zip[I,I2]: Tee[I,I2,(I,I2)] = zipWith((_,_))
-
-    /* Ignores all input from left. */
-    def passR[I,I2]: Tee[I,I2,I2] = awaitR(emitT(_, passR))
-
-    /* Ignores input from the right. */
-    def passL[I,I2]: Tee[I,I2,I] = awaitL(emitT(_, passL))
-
-    /* Alternate pulling values from the left and the right inputs. */
-    def interleaveT[I]: Tee[I,I,I] =
-      awaitL[I,I,I](i =>
-      awaitR       (i2 => emitT(i) ++ emitT(i2))) repeat
-
-                            /*
-
-    Our `Process` type can also represent effectful sinks (like a file).
-    A `Sink` is simply a source of effectful functions! See the
-    definition of `to` in `Process` for an example of how to feed a
-    `Process` to a `Sink`.
-
-                             */
-
-    type Sink[F[_],O] = Process[F, O => Process[F,Unit]]
-
-    import java.io.FileWriter
-
-    /* A `Sink` which writes input strings to the given file. */
-    def fileW(file: String, append: Boolean = false): Sink[IO,String] =
-      resource[FileWriter, String => Process[IO,Unit]]
-        { IO { new FileWriter(file, append) }}
-        { w => constant { (s: String) => eval[IO,Unit](IO(w.write(s))) }}
-        { w => eval_(IO(w.close)) }
-
-    /* The infinite, constant stream. */
-    def constant[A](a: A): Process[IO,A] =
-      eval(IO(a)).flatMap { a => Emit(a, constant(a)) }
-
-    /* Exercise 12: Implement `join`. Notice this is the standard monadic combinator! */
-    def join[F[_],A](p: Process[F,Process[F,A]]): Process[F,A] = ???
-
-    /*
-     * An example use of the combinators we have so far: incrementally
-     * convert the lines of a file from fahrenheit to celsius.
-     */
-
-    import fpinscala.iomonad.IO0.fahrenheitToCelsius
-
-    val converter: Process[IO,Unit] =
-      lines("fahrenheit.txt").
-      filter(line => !line.startsWith("#") && !line.trim.isEmpty).
-      map(line => fahrenheitToCelsius(line.toDouble).toString).
-      pipe(intersperse("\n")).
-      to(fileW("celsius.txt")).
-      drain
-
-                            /*
-
-    More generally, we can feed a `Process` through an effectful
-    channel which returns a value other than `Unit`.
-
-                             */
-
-    type Channel[F[_],I,O] = Process[F, I => Process[F,O]]
-
-    /*
-     * Here is an example, a JDBC query runner which returns the
-     * stream of rows from the result set of the query. We have
-     * the channel take a `Connection => PreparedStatement` as
-     * input, so code that uses this channel does not need to be
-     * responsible for knowing how to obtain a `Connection`.
-     */
-    import java.sql.{Connection, PreparedStatement, ResultSet}
-
-    def query(conn: IO[Connection]):
-        Channel[IO, Connection => PreparedStatement, Map[String,Any]] =
-      resource_
-        { conn }
-        { conn => constant { (q: Connection => PreparedStatement) =>
-          resource_
-            { IO {
-                val rs = q(conn).executeQuery
-                val ncols = rs.getMetaData.getColumnCount
-                val cols = (1 to ncols).map(rs.getMetaData.getColumnName)
-                (rs, cols)
-            }}
-            { case (rs, cols) =>
-                def step =
-                  if (!rs.next) None
-                  else Some(cols.map(c => (c, rs.getObject(c): Any)).toMap)
-                lazy val rows: Process[IO,Map[String,Any]] =
-                  eval(IO(step)).flatMap {
-                    case None => Halt(End)
-                    case Some(row) => Emit(row, rows)
-                  }
-                rows
-            }
-            { p => IO { p._1.close } } // close the ResultSet
-        }}
-        { c => IO(c.close) }
-
-    /*
-     * We can allocate resources dynamically when defining a `Process`.
-     * As an example, this program reads a list of filenames to process
-     * _from another file_, opening each file, processing it and closing
-     * it promptly.
-     */
-
-    val convertAll: Process[IO,Unit] = (for {
-      out <- fileW("celsius.txt").once
-      file <- lines("fahrenheits.txt")
-      _ <- lines(file).
-           map(line => fahrenheitToCelsius(line.toDouble)).
-           flatMap(celsius => out(celsius.toString))
-    } yield ()) drain
-
-    /*
-     * Just by switching the order of the `flatMap` calls, we can output
-     * to multiple files.
-     */
-    val convertMultisink: Process[IO,Unit] = (for {
-      file <- lines("fahrenheits.txt")
-      _ <- lines(file).
-           map(line => fahrenheitToCelsius(line.toDouble)).
-           map(_ toString).
-           to(fileW(file + ".celsius"))
-    } yield ()) drain
-
-    /*
-     * We can attach filters or other transformations at any point in the
-     * program, for example:
-     */
-    val convertMultisink2: Process[IO,Unit] = (for {
-      file <- lines("fahrenheits.txt")
-      _ <- lines(file).
-           filter(!_.startsWith("#")).
-           map(line => fahrenheitToCelsius(line.toDouble)).
-           filter(_ > 0). // ignore below zero temperatures
-           map(_ toString).
-           to(fileW(file + ".celsius"))
-    } yield ()) drain
-  }
-}
-
-object ProcessTest extends App {
-  import GeneralizedStreamTransducers._
-  import fpinscala.iomonad.IO
-  import Process._
-
-  val p = eval(IO { println("woot"); 1 }).repeat
-  val p2 = eval(IO { println("cleanup"); 2 } ).onHalt {
-    case Kill => println { "cleanup was killed, instead of bring run" }; Halt(Kill)
-    case e => Halt(e)
-  }
-
-  println { Process.runLog { p2.onComplete(p2).onComplete(p2).take(1).take(1) } }
-  println { Process.runLog(converter) }
-  // println { Process.collect(Process.convertAll) }
-}
diff --git a/exercises/src/main/scala/fpinscala/testing/Gen.scala b/exercises/src/main/scala/fpinscala/testing/Gen.scala
deleted file mode 100644
index a91ed14..0000000
--- a/exercises/src/main/scala/fpinscala/testing/Gen.scala
+++ /dev/null
@@ -1,35 +0,0 @@
-package fpinscala.testing
-
-import fpinscala.laziness.Stream
-import fpinscala.state._
-import fpinscala.parallelism._
-import fpinscala.parallelism.Par.Par
-import Gen._
-import Prop._
-import java.util.concurrent.{Executors,ExecutorService}
-
-/*
-The library developed in this chapter goes through several iterations. This file is just the
-shell, which you can fill in and modify while working through the chapter.
-*/
-
-trait Prop {
-}
-
-object Prop {
-  def forAll[A](gen: Gen[A])(f: A => Boolean): Prop = ???
-}
-
-object Gen {
-  def unit[A](a: => A): Gen[A] = ???
-}
-
-trait Gen[A] {
-  def map[A,B](f: A => B): Gen[B] = ???
-  def flatMap[A,B](f: A => Gen[B]): Gen[B] = ???
-}
-
-trait SGen[+A] {
-
-}
-
diff --git a/project/build.properties b/project/build.properties
index 27e88aa..3100bc2 100644
--- a/project/build.properties
+++ b/project/build.properties
@@ -1 +1,2 @@
-sbt.version=0.13.13
+# sbt.version=0.13.13
+sbt.version=1.2.3
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/applicative/Applicative.scala b/src/main/scala/answers/src/main/scala/fpinscala/applicative/Applicative.scala
new file mode 100644
index 0000000..1714aeb
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/applicative/Applicative.scala
@@ -0,0 +1,282 @@
+package fpinscala
+package applicative
+
+import monads.Functor
+import state._
+import State._
+import monoids._
+import language.higherKinds
+import language.implicitConversions
+
+
+trait Applicative[F[_]] extends Functor[F] {
+  // `map2` is implemented by first currying `f` so we get a function
+  // of type `A => B => C`. This is a function that takes `A` and returns
+  // another function of type `B => C`. So if we map `f.curried` over an
+  // `F[A]`, we get `F[B => C]`. Passing that to `apply` along with the
+  // `F[B]` will give us the desired `F[C]`.
+  def map2[A,B,C](fa: F[A], fb: F[B])(f: (A, B) => C): F[C] =
+    apply(map(fa)(f.curried))(fb)
+
+  // We simply use `map2` to lift a function into `F` so we can apply it
+  // to both `fab` and `fa`. The function being lifted here is `_(_)`,
+  // which is the same as the lambda notation `(f, x) => f(x)`. That is,
+  // It's a function that takes two arguments:
+  //   1. A function `f`
+  //   2. An argument `x` to that function
+  // and it simply applies `f` to `x`.
+  def apply[A,B](fab: F[A => B])(fa: F[A]): F[B] =
+    map2(fab, fa)(_(_))
+
+  def unit[A](a: => A): F[A]
+
+  def map[A,B](fa: F[A])(f: A => B): F[B] =
+    apply(unit(f))(fa)
+
+  def sequence[A](fas: List[F[A]]): F[List[A]] =
+    traverse(fas)(fa => fa)
+
+  def traverse[A,B](as: List[A])(f: A => F[B]): F[List[B]] =
+    as.foldRight(unit(List[B]()))((a, fbs) => map2(f(a), fbs)(_ :: _))
+
+  def replicateM[A](n: Int, fa: F[A]): F[List[A]] =
+    sequence(List.fill(n)(fa))
+
+  def factor[A,B](fa: F[A], fb: F[B]): F[(A,B)] =
+    map2(fa, fb)((_,_))
+
+  def product[G[_]](G: Applicative[G]): Applicative[({type f[x] = (F[x], G[x])})#f] = {
+    val self = this
+    new Applicative[({type f[x] = (F[x], G[x])})#f] {
+      def unit[A](a: => A) = (self.unit(a), G.unit(a))
+      override def apply[A,B](fs: (F[A => B], G[A => B]))(p: (F[A], G[A])) =
+        (self.apply(fs._1)(p._1), G.apply(fs._2)(p._2))
+    }
+  }
+
+  // Here we simply use `map2` to lift `apply` and `unit` themselves from one
+  // Applicative into the other.
+  // If `self` and `G` both satisfy the laws, then so does the composite.
+  // The full proof can be found at
+  // https://github.com/runarorama/sannanir/blob/master/Applicative.v
+  def compose[G[_]](G: Applicative[G]): Applicative[({type f[x] = F[G[x]]})#f] = {
+    val self = this
+    new Applicative[({type f[x] = F[G[x]]})#f] {
+      def unit[A](a: => A) = self.unit(G.unit(a))
+      override def map2[A,B,C](fga: F[G[A]], fgb: F[G[B]])(f: (A,B) => C) =
+        self.map2(fga, fgb)(G.map2(_,_)(f))
+    }
+  }
+
+  def sequenceMap[K,V](ofa: Map[K,F[V]]): F[Map[K,V]] =
+    (ofa foldLeft unit(Map.empty[K,V])) { case (acc, (k, fv)) =>
+      map2(acc, fv)((m, v) => m + (k -> v))
+    }
+
+}
+
+sealed trait Validation[+E, +A]
+
+case class Failure[E](head: E, tail: Vector[E])
+  extends Validation[E, Nothing]
+
+case class Success[A](a: A) extends Validation[Nothing, A]
+
+object Applicative {
+  val streamApplicative = new Applicative[Stream] {
+
+    def unit[A](a: => A): Stream[A] =
+      Stream.continually(a) // The infinite, constant stream
+
+    override def map2[A,B,C](a: Stream[A], b: Stream[B])( // Combine elements pointwise
+                    f: (A,B) => C): Stream[C] =
+      a zip b map f.tupled
+  }
+
+  def validationApplicative[E]: Applicative[({type f[x] = Validation[E,x]})#f] =
+    new Applicative[({type f[x] = Validation[E,x]})#f] {
+      def unit[A](a: => A) = Success(a)
+      override def map2[A,B,C](fa: Validation[E,A], fb: Validation[E,B])(f: (A, B) => C) =
+        (fa, fb) match {
+          case (Success(a), Success(b)) => Success(f(a, b))
+          case (Failure(h1, t1), Failure(h2, t2)) =>
+            Failure(h1, t1 ++ Vector(h2) ++ t2)
+          case (e@Failure(_, _), _) => e
+          case (_, e@Failure(_, _)) => e
+        }
+    }
+
+  type Const[A, B] = A
+
+  implicit def monoidApplicative[M](M: Monoid[M]) =
+    new Applicative[({ type f[x] = Const[M, x] })#f] {
+      def unit[A](a: => A): M = M.zero
+      override def apply[A,B](m1: M)(m2: M): M = M.op(m1, m2)
+    }
+
+}
+
+trait Monad[F[_]] extends Applicative[F] {
+  def flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] =
+    join(map(ma)(f))
+
+  override def apply[A,B](mf: F[A => B])(ma: F[A]): F[B] =
+    flatMap(mf)(f => map(ma)(f))
+
+  override def map[A,B](m: F[A])(f: A => B): F[B] =
+    flatMap(m)(a => unit(f(a)))
+
+  override def map2[A,B,C](ma: F[A], mb: F[B])(f: (A, B) => C): F[C] =
+    flatMap(ma)(a => map(mb)(b => f(a, b)))
+
+  def compose[A,B,C](f: A => F[B], g: B => F[C]): A => F[C] =
+    a => flatMap(f(a))(g)
+
+  def join[A](mma: F[F[A]]): F[A] = flatMap(mma)(ma => ma)
+}
+
+object Monad {
+
+  // Notice that in the case of a `Left`, flatMap does nothing.
+  def eitherMonad[E]: Monad[({type f[x] = Either[E, x]})#f] =
+    new Monad[({type f[x] = Either[E, x]})#f] {
+      def unit[A](a: => A): Either[E, A] = Right(a)
+      override def flatMap[A,B](eea: Either[E, A])(f: A => Either[E, B]) = eea match {
+        case Right(a) => f(a)
+        case Left(b) => Left(b)
+      }
+    }
+
+  def stateMonad[S] = new Monad[({type f[x] = State[S, x]})#f] {
+    def unit[A](a: => A): State[S, A] = State(s => (a, s))
+    override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
+      st flatMap f
+  }
+
+  // Monad composition
+  def composeM[G[_],H[_]](implicit G: Monad[G], H: Monad[H], T: Traverse[H]):
+    Monad[({type f[x] = G[H[x]]})#f] = new Monad[({type f[x] = G[H[x]]})#f] {
+      def unit[A](a: => A): G[H[A]] = G.unit(H.unit(a))
+      override def flatMap[A,B](mna: G[H[A]])(f: A => G[H[B]]): G[H[B]] =
+        G.flatMap(mna)(na => G.map(T.traverse(na)(f))(H.join))
+    }
+
+}
+
+trait Traverse[F[_]] extends Functor[F] with Foldable[F] { self =>
+  def traverse[M[_]:Applicative,A,B](fa: F[A])(f: A => M[B]): M[F[B]] =
+    sequence(map(fa)(f))
+  def sequence[M[_]:Applicative,A](fma: F[M[A]]): M[F[A]] =
+    traverse(fma)(ma => ma)
+
+  type Id[A] = A
+
+  val idMonad = new Monad[Id] {
+    def unit[A](a: => A) = a
+    override def flatMap[A,B](a: A)(f: A => B): B = f(a)
+  }
+
+  def map[A,B](fa: F[A])(f: A => B): F[B] =
+    traverse[Id, A, B](fa)(f)(idMonad)
+
+  import Applicative._
+
+  override def foldMap[A,B](as: F[A])(f: A => B)(mb: Monoid[B]): B =
+    traverse[({type f[x] = Const[B,x]})#f,A,Nothing](
+      as)(f)(monoidApplicative(mb))
+
+  def traverseS[S,A,B](fa: F[A])(f: A => State[S, B]): State[S, F[B]] =
+    traverse[({type f[x] = State[S, x]})#f, A, B](fa)(f)(Monad.stateMonad)
+
+  def zipWithIndex_[A](ta: F[A]): F[(A,Int)] =
+    traverseS(ta)((a: A) => (for {
+      i <- get[Int]
+      _ <- set(i + 1)
+    } yield (a, i))).run(0)._1
+
+  def toList_[A](fa: F[A]): List[A] =
+    traverseS(fa)((a: A) => (for {
+      as <- get[List[A]] // Get the current state, the accumulated list.
+      _  <- set(a :: as) // Add the current element and set the new list as the new state.
+    } yield ())).run(Nil)._2.reverse
+
+  def mapAccum[S,A,B](fa: F[A], s: S)(f: (A, S) => (B, S)): (F[B], S) =
+    traverseS(fa)((a: A) => (for {
+      s1 <- get[S]
+      (b, s2) = f(a, s1)
+      _  <- set(s2)
+    } yield b)).run(s)
+
+  override def toList[A](fa: F[A]): List[A] =
+    mapAccum(fa, List[A]())((a, s) => ((), a :: s))._2.reverse
+
+  def zipWithIndex[A](fa: F[A]): F[(A, Int)] =
+    mapAccum(fa, 0)((a, s) => ((a, s), s + 1))._1
+
+  def reverse[A](fa: F[A]): F[A] =
+    mapAccum(fa, toList(fa).reverse)((_, as) => (as.head, as.tail))._1
+
+  override def foldLeft[A,B](fa: F[A])(z: B)(f: (B, A) => B): B =
+    mapAccum(fa, z)((a, b) => ((), f(b, a)))._2
+
+  def zip[A,B](fa: F[A], fb: F[B]): F[(A, B)] =
+    (mapAccum(fa, toList(fb)) {
+      case (a, Nil) => sys.error("zip: Incompatible shapes.")
+      case (a, b :: bs) => ((a, b), bs)
+    })._1
+
+  def zipL[A,B](fa: F[A], fb: F[B]): F[(A, Option[B])] =
+    (mapAccum(fa, toList(fb)) {
+      case (a, Nil) => ((a, None), Nil)
+      case (a, b :: bs) => ((a, Some(b)), bs)
+    })._1
+
+  def zipR[A,B](fa: F[A], fb: F[B]): F[(Option[A], B)] =
+    (mapAccum(fb, toList(fa)) {
+      case (b, Nil) => ((None, b), Nil)
+      case (b, a :: as) => ((Some(a), b), as)
+    })._1
+
+  def fuse[M[_],N[_],A,B](fa: F[A])(f: A => M[B], g: A => N[B])
+                         (implicit M: Applicative[M], N: Applicative[N]): (M[F[B]], N[F[B]]) =
+    traverse[({type f[x] = (M[x], N[x])})#f, A, B](fa)(a => (f(a), g(a)))(M product N)
+
+  def compose[G[_]](implicit G: Traverse[G]): Traverse[({type f[x] = F[G[x]]})#f] =
+    new Traverse[({type f[x] = F[G[x]]})#f] {
+      override def traverse[M[_]:Applicative,A,B](fa: F[G[A]])(f: A => M[B]) =
+        self.traverse(fa)((ga: G[A]) => G.traverse(ga)(f))
+    }
+}
+
+case class Tree[+A](head: A, tail: List[Tree[A]])
+
+object Traverse {
+  val listTraverse = new Traverse[List] {
+    override def traverse[M[_],A,B](as: List[A])(f: A => M[B])(implicit M: Applicative[M]): M[List[B]] =
+      as.foldRight(M.unit(List[B]()))((a, fbs) => M.map2(f(a), fbs)(_ :: _))
+  }
+
+  val optionTraverse = new Traverse[Option] {
+    override def traverse[M[_],A,B](oa: Option[A])(f: A => M[B])(implicit M: Applicative[M]): M[Option[B]] =
+      oa match {
+        case Some(a) => M.map(f(a))(Some(_))
+        case None    => M.unit(None)
+      }
+  }
+
+  val treeTraverse = new Traverse[Tree] {
+    override def traverse[M[_],A,B](ta: Tree[A])(f: A => M[B])(implicit M: Applicative[M]): M[Tree[B]] =
+      M.map2(f(ta.head), listTraverse.traverse(ta.tail)(a => traverse(a)(f)))(Tree(_, _))
+  }
+
+  // An example of a Foldable that is not a functor
+  case class Iteration[A](a: A, f: A => A, n: Int) {
+    def foldMap[B](g: A => B)(M: Monoid[B]): B = {
+      def iterate(n: Int, b: B, c: A): B =
+        if (n <= 0) b else iterate(n-1, g(c), f(a))
+      iterate(n, M.zero, a)
+    }
+  }
+}
+
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/datastructures/List.scala b/src/main/scala/answers/src/main/scala/fpinscala/datastructures/List.scala
new file mode 100644
index 0000000..c5354a2
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/datastructures/List.scala
@@ -0,0 +1,327 @@
+package fpinscala.datastructures
+
+sealed trait List[+A] // `List` data type, parameterized on a type, `A`
+case object Nil extends List[Nothing] // A `List` data constructor representing the empty list
+/* Another data constructor, representing nonempty lists. Note that `tail` is another `List[A]`,
+which may be `Nil` or another `Cons`.
+ */
+case class Cons[+A](head: A, tail: List[A]) extends List[A]
+
+object List { // `List` companion object. Contains functions for creating and working with lists.
+  def sum(ints: List[Int]): Int = ints match { // A function that uses pattern matching to add up a list of integers
+    case Nil => 0 // The sum of the empty list is 0.
+    case Cons(x,xs) => x + sum(xs) // The sum of a list starting with `x` is `x` plus the sum of the rest of the list.
+  }
+
+  def product(ds: List[Double]): Double = ds match {
+    case Nil => 1.0
+    case Cons(0.0, _) => 0.0
+    case Cons(x,xs) => x * product(xs)
+  }
+
+  def apply[A](as: A*): List[A] = // Variadic function syntax
+    if (as.isEmpty) Nil
+    else Cons(as.head, apply(as.tail: _*))
+
+  val x = List(1,2,3,4,5) match {
+    case Cons(x, Cons(2, Cons(4, _))) => x
+    case Nil => 42
+    case Cons(x, Cons(y, Cons(3, Cons(4, _)))) => x + y
+    case Cons(h, t) => h + sum(t)
+    case _ => 101
+  }
+
+  def append[A](a1: List[A], a2: List[A]): List[A] =
+    a1 match {
+      case Nil => a2
+      case Cons(h,t) => Cons(h, append(t, a2))
+    }
+
+  def foldRight[A,B](as: List[A], z: B)(f: (A, B) => B): B = // Utility functions
+    as match {
+      case Nil => z
+      case Cons(x, xs) => f(x, foldRight(xs, z)(f))
+    }
+
+  def sum2(ns: List[Int]) =
+    foldRight(ns, 0)((x,y) => x + y)
+
+  def product2(ns: List[Double]) =
+    foldRight(ns, 1.0)(_ * _) // `_ * _` is more concise notation for `(x,y) => x * y`; see sidebar
+
+
+  /*
+  3. The third case is the first that matches, with `x` bound to 1 and `y` bound to 2.
+  */
+
+  /*
+  Although we could return `Nil` when the input list is empty, we choose to throw an exception instead. This is
+  a somewhat subjective choice. In our experience, taking the tail of an empty list is often a bug, and silently
+  returning a value just means this bug will be discovered later, further from the place where it was introduced.
+
+  It's generally good practice when pattern matching to use `_` for any variables you don't intend to use on the
+  right hand side of a pattern. This makes it clear the value isn't relevant.
+  */
+  def tail[A](l: List[A]): List[A] =
+    l match {
+      case Nil => sys.error("tail of empty list")
+      case Cons(_,t) => t
+    }
+
+  /*
+  If a function body consists solely of a match expression, we'll often put the match on the same line as the
+  function signature, rather than introducing another level of nesting.
+  */
+  def setHead[A](l: List[A], h: A): List[A] = l match {
+    case Nil => sys.error("setHead on empty list")
+    case Cons(_,t) => Cons(h,t)
+  }
+
+  /*
+  Again, it's somewhat subjective whether to throw an exception when asked to drop more elements than the list
+  contains. The usual default for `drop` is not to throw an exception, since it's typically used in cases where this
+  is not indicative of a programming error. If you pay attention to how you use `drop`, it's often in cases where the
+  length of the input list is unknown, and the number of elements to be dropped is being computed from something else.
+  If `drop` threw an exception, we'd have to first compute or check the length and only drop up to that many elements.
+  */
+  def drop[A](l: List[A], n: Int): List[A] =
+    if (n <= 0) l
+    else l match {
+      case Nil => Nil
+      case Cons(_,t) => drop(t, n-1)
+    }
+
+  /*
+  Somewhat overkill, but to illustrate the feature we're using a _pattern guard_, to only match a `Cons` whose head
+  satisfies our predicate, `f`. The syntax is to add `if <cond>` after the pattern, before the `=>`, where `<cond>` can
+  use any of the variables introduced by the pattern.
+  */
+  def dropWhile[A](l: List[A], f: A => Boolean): List[A] =
+    l match {
+      case Cons(h,t) if f(h) => dropWhile(t, f)
+      case _ => l
+    }
+
+  /*
+  Note that we're copying the entire list up until the last element. Besides being inefficient, the natural recursive
+  solution will use a stack frame for each element of the list, which can lead to stack overflows for
+  large lists (can you see why?). With lists, it's common to use a temporary, mutable buffer internal to the
+  function (with lazy lists or streams, which we discuss in chapter 5, we don't normally do this). So long as the
+  buffer is allocated internal to the function, the mutation is not observable and RT is preserved.
+
+  Another common convention is to accumulate the output list in reverse order, then reverse it at the end, which
+  doesn't require even local mutation. We'll write a reverse function later in this chapter.
+  */
+  def init[A](l: List[A]): List[A] =
+    l match {
+      case Nil => sys.error("init of empty list")
+      case Cons(_,Nil) => Nil
+      case Cons(h,t) => Cons(h,init(t))
+    }
+  def init2[A](l: List[A]): List[A] = {
+    import collection.mutable.ListBuffer
+    val buf = new ListBuffer[A]
+    @annotation.tailrec
+    def go(cur: List[A]): List[A] = cur match {
+      case Nil => sys.error("init of empty list")
+      case Cons(_,Nil) => List(buf.toList: _*)
+      case Cons(h,t) => buf += h; go(t)
+    }
+    go(l)
+  }
+
+  /*
+  No, this is not possible! The reason is because _before_ we ever call our function, `f`, we evaluate its argument,
+  which in the case of `foldRight` means traversing the list all the way to the end. We need _non-strict_ evaluation
+  to support early termination---we discuss this in chapter 5.
+  */
+
+  /*
+  We get back the original list! Why is that? As we mentioned earlier, one way of thinking about what `foldRight` "does"
+  is it replaces the `Nil` constructor of the list with the `z` argument, and it replaces the `Cons` constructor with
+  the given function, `f`. If we just supply `Nil` for `z` and `Cons` for `f`, then we get back the input list.
+
+  foldRight(Cons(1, Cons(2, Cons(3, Nil))), Nil:List[Int])(Cons(_,_))
+  Cons(1, foldRight(Cons(2, Cons(3, Nil)), Nil:List[Int])(Cons(_,_)))
+  Cons(1, Cons(2, foldRight(Cons(3, Nil), Nil:List[Int])(Cons(_,_))))
+  Cons(1, Cons(2, Cons(3, foldRight(Nil, Nil:List[Int])(Cons(_,_)))))
+  Cons(1, Cons(2, Cons(3, Nil)))
+  */
+
+  def length[A](l: List[A]): Int =
+    foldRight(l, 0)((_,acc) => acc + 1)
+
+  /*
+  It's common practice to annotate functions you expect to be tail-recursive with the `tailrec` annotation. If the
+  function is not tail-recursive, it will yield a compile error, rather than silently compiling the code and resulting
+  in greater stack space usage at runtime.
+  */
+  @annotation.tailrec
+  def foldLeft[A,B](l: List[A], z: B)(f: (B, A) => B): B = l match {
+    case Nil => z
+    case Cons(h,t) => foldLeft(t, f(z,h))(f)
+  }
+
+  def sum3(l: List[Int]) = foldLeft(l, 0)(_ + _)
+  def product3(l: List[Double]) = foldLeft(l, 1.0)(_ * _)
+
+  def length2[A](l: List[A]): Int = foldLeft(l, 0)((acc,h) => acc + 1)
+
+  def reverse[A](l: List[A]): List[A] = foldLeft(l, List[A]())((acc,h) => Cons(h,acc))
+
+  /*
+  The implementation of `foldRight` in terms of `reverse` and `foldLeft` is a common trick for avoiding stack overflows
+  when implementing a strict `foldRight` function as we've done in this chapter. (We'll revisit this in a later chapter,
+  when we discuss laziness).
+
+  The other implementations build up a chain of functions which, when called, results in the operations being performed
+  with the correct associativity. We are calling `foldRight` with the `B` type being instantiated to `B => B`, then
+  calling the built up function with the `z` argument. Try expanding the definitions by substituting equals for equals
+  using a simple example, like `foldLeft(List(1,2,3), 0)(_ + _)` if this isn't clear. Note these implementations are
+  more of theoretical interest - they aren't stack-safe and won't work for large lists.
+  */
+  def foldRightViaFoldLeft[A,B](l: List[A], z: B)(f: (A,B) => B): B =
+    foldLeft(reverse(l), z)((b,a) => f(a,b))
+
+  def foldRightViaFoldLeft_1[A,B](l: List[A], z: B)(f: (A,B) => B): B =
+    foldLeft(l, (b:B) => b)((g,a) => b => g(f(a,b)))(z)
+
+  def foldLeftViaFoldRight[A,B](l: List[A], z: B)(f: (B,A) => B): B =
+    foldRight(l, (b:B) => b)((a,g) => b => g(f(b,a)))(z)
+
+  /*
+  `append` simply replaces the `Nil` constructor of the first list with the second list, which is exactly the operation
+  performed by `foldRight`.
+  */
+  def appendViaFoldRight[A](l: List[A], r: List[A]): List[A] =
+    foldRight(l, r)(Cons(_,_))
+
+  /*
+  Since `append` takes time proportional to its first argument, and this first argument never grows because of the
+  right-associativity of `foldRight`, this function is linear in the total length of all lists. You may want to try
+  tracing the execution of the implementation on paper to convince yourself that this works.
+
+  Note that we're simply referencing the `append` function, without writing something like `(x,y) => append(x,y)`
+  or `append(_,_)`. In Scala there is a rather arbitrary distinction between functions defined as _methods_, which are
+  introduced with the `def` keyword, and function values, which are the first-class objects we can pass to other
+  functions, put in collections, and so on. This is a case where Scala lets us pretend the distinction doesn't exist.
+  In other cases, you'll be forced to write `append _` (to convert a `def` to a function value)
+  or even `(x: List[A], y: List[A]) => append(x,y)` if the function is polymorphic and the type arguments aren't known.
+  */
+  def concat[A](l: List[List[A]]): List[A] =
+    foldRight(l, Nil:List[A])(append)
+
+  def add1(l: List[Int]): List[Int] =
+    foldRight(l, Nil:List[Int])((h,t) => Cons(h+1,t))
+
+  def doubleToString(l: List[Double]): List[String] =
+    foldRight(l, Nil:List[String])((h,t) => Cons(h.toString,t))
+
+  /*
+  A natural solution is using `foldRight`, but our implementation of `foldRight` is not stack-safe. We can
+  use `foldRightViaFoldLeft` to avoid the stack overflow (variation 1), but more commonly, with our current
+  implementation of `List`, `map` will just be implemented using local mutation (variation 2). Again, note that the
+  mutation isn't observable outside the function, since we're only mutating a buffer that we've allocated.
+  */
+  def map[A,B](l: List[A])(f: A => B): List[B] =
+    foldRight(l, Nil:List[B])((h,t) => Cons(f(h),t))
+
+  def map_1[A,B](l: List[A])(f: A => B): List[B] =
+    foldRightViaFoldLeft(l, Nil:List[B])((h,t) => Cons(f(h),t))
+
+  def map_2[A,B](l: List[A])(f: A => B): List[B] = {
+    val buf = new collection.mutable.ListBuffer[B]
+    def go(l: List[A]): Unit = l match {
+      case Nil => ()
+      case Cons(h,t) => buf += f(h); go(t)
+    }
+    go(l)
+    List(buf.toList: _*) // converting from the standard Scala list to the list we've defined here
+  }
+
+  /*
+  The discussion about `map` also applies here.
+  */
+  def filter[A](l: List[A])(f: A => Boolean): List[A] =
+    foldRight(l, Nil:List[A])((h,t) => if (f(h)) Cons(h,t) else t)
+
+  def filter_1[A](l: List[A])(f: A => Boolean): List[A] =
+    foldRightViaFoldLeft(l, Nil:List[A])((h,t) => if (f(h)) Cons(h,t) else t)
+
+  def filter_2[A](l: List[A])(f: A => Boolean): List[A] = {
+    val buf = new collection.mutable.ListBuffer[A]
+    def go(l: List[A]): Unit = l match {
+      case Nil => ()
+      case Cons(h,t) => if (f(h)) buf += h; go(t)
+    }
+    go(l)
+    List(buf.toList: _*) // converting from the standard Scala list to the list we've defined here
+  }
+
+  /*
+  This could also be implemented directly using `foldRight`.
+  */
+  def flatMap[A,B](l: List[A])(f: A => List[B]): List[B] =
+    concat(map(l)(f))
+
+  def filterViaFlatMap[A](l: List[A])(f: A => Boolean): List[A] =
+    flatMap(l)(a => if (f(a)) List(a) else Nil)
+
+  /*
+  To match on multiple values, we can put the values into a pair and match on the pair, as shown next, and the same
+  syntax extends to matching on N values (see sidebar "Pairs and tuples in Scala" for more about pair and tuple
+  objects). You can also (somewhat less conveniently, but a bit more efficiently) nest pattern matches: on the
+  right hand side of the `=>`, simply begin another `match` expression. The inner `match` will have access to all the
+  variables introduced in the outer `match`.
+
+  The discussion about stack usage from the explanation of `map` also applies here.
+  */
+  def addPairwise(a: List[Int], b: List[Int]): List[Int] = (a,b) match {
+    case (Nil, _) => Nil
+    case (_, Nil) => Nil
+    case (Cons(h1,t1), Cons(h2,t2)) => Cons(h1+h2, addPairwise(t1,t2))
+  }
+
+  /*
+  This function is usually called `zipWith`. The discussion about stack usage from the explanation of `map` also
+  applies here. By putting the `f` in the second argument list, Scala can infer its type from the previous argument list.
+  */
+  def zipWith[A,B,C](a: List[A], b: List[B])(f: (A,B) => C): List[C] = (a,b) match {
+    case (Nil, _) => Nil
+    case (_, Nil) => Nil
+    case (Cons(h1,t1), Cons(h2,t2)) => Cons(f(h1,h2), zipWith(t1,t2)(f))
+  }
+
+  /*
+  There's nothing particularly bad about this implementation,
+  except that it's somewhat monolithic and easy to get wrong.
+  Where possible, we prefer to assemble functions like this using
+  combinations of other functions. It makes the code more obviously
+  correct and easier to read and understand. Notice that in this
+  implementation we need special purpose logic to break out of our
+  loops early. In Chapter 5 we'll discuss ways of composing functions
+  like this from simpler components, without giving up the efficiency
+  of having the resulting functions work in one pass over the data.
+  
+  It's good to specify some properties about these functions.
+  For example, do you expect these expressions to be true?
+  
+  (xs append ys) startsWith xs
+  xs startsWith Nil
+  (xs append ys append zs) hasSubsequence ys
+  xs hasSubsequence Nil
+
+  */
+  @annotation.tailrec
+  def startsWith[A](l: List[A], prefix: List[A]): Boolean = (l,prefix) match {
+    case (_,Nil) => true
+    case (Cons(h,t),Cons(h2,t2)) if h == h2 => startsWith(t, t2)
+    case _ => false
+  }
+  @annotation.tailrec
+  def hasSubsequence[A](sup: List[A], sub: List[A]): Boolean = sup match {
+    case Nil => sub == Nil
+    case _ if startsWith(sup, sub) => true
+    case Cons(h,t) => hasSubsequence(t, sub)
+  }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/datastructures/Tree.scala b/src/main/scala/answers/src/main/scala/fpinscala/datastructures/Tree.scala
new file mode 100644
index 0000000..edb1018
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/datastructures/Tree.scala
@@ -0,0 +1,80 @@
+package fpinscala.datastructures
+
+sealed trait Tree[+A]
+case class Leaf[A](value: A) extends Tree[A]
+case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]
+
+
+object Tree {
+
+
+
+  def size[A](t: Tree[A]): Int = t match {
+    case Leaf(_) => 1
+    case Branch(l,r) => 1 + size(l) + size(r)
+  }
+
+  /*
+  We're using the method `max` that exists on all `Int` values rather than an explicit `if` expression.
+  
+  Note how similar the implementation is to `size`. We'll abstract out the common pattern in a later exercise. 
+  */
+  def maximum(t: Tree[Int]): Int = t match {
+    case Leaf(n) => n
+    case Branch(l,r) => maximum(l) max maximum(r)
+  }
+
+  /*
+  Again, note how similar the implementation is to `size` and `maximum`.
+  */
+  def depth[A](t: Tree[A]): Int = t match {
+    case Leaf(_) => 0
+    case Branch(l,r) => 1 + (depth(l) max depth(r))
+  }
+
+  def map[A,B](t: Tree[A])(f: A => B): Tree[B] = t match {
+    case Leaf(a) => Leaf(f(a))
+    case Branch(l,r) => Branch(map(l)(f), map(r)(f))
+  }
+
+  /* 
+  Like `foldRight` for lists, `fold` receives a "handler" for each of the data constructors of the type, and recursively
+  accumulates some value using these handlers. As with `foldRight`, `fold(t)(Leaf(_))(Branch(_,_)) == t`, and we can use
+  this function to implement just about any recursive function that would otherwise be defined by pattern matching.
+  */
+  def fold[A,B](t: Tree[A])(f: A => B)(g: (B,B) => B): B = t match {
+    case Leaf(a) => f(a)
+    case Branch(l,r) => g(fold(l)(f)(g), fold(r)(f)(g))
+  }
+  
+  def sizeViaFold[A](t: Tree[A]): Int = 
+    fold(t)(a => 1)(1 + _ + _)
+  
+  def maximumViaFold(t: Tree[Int]): Int = 
+    fold(t)(a => a)(_ max _)
+  
+  def depthViaFold[A](t: Tree[A]): Int = 
+    fold(t)(a => 0)((d1,d2) => 1 + (d1 max d2))
+  
+  /*
+  Note the type annotation required on the expression `Leaf(f(a))`. Without this annotation, we get an error like this: 
+  
+  type mismatch;
+    found   : fpinscala.datastructures.Branch[B]
+    required: fpinscala.datastructures.Leaf[B]
+       fold(t)(a => Leaf(f(a)))(Branch(_,_))
+                                      ^  
+  
+  This error is an unfortunate consequence of Scala using subtyping to encode algebraic data types. Without the
+  annotation, the result type of the fold gets inferred as `Leaf[B]` and it is then expected that the second argument
+  to `fold` will return `Leaf[B]`, which it doesn't (it returns `Branch[B]`). Really, we'd prefer Scala to
+  infer `Tree[B]` as the result type in both cases. When working with algebraic data types in Scala, it's somewhat
+  common to define helper functions that simply call the corresponding data constructors but give the less specific
+  result type:
+    
+    def leaf[A](a: A): Tree[A] = Leaf(a)
+    def branch[A](l: Tree[A], r: Tree[A]): Tree[A] = Branch(l, r)
+  */
+  def mapViaFold[A,B](t: Tree[A])(f: A => B): Tree[B] = 
+    fold(t)(a => Leaf(f(a)): Tree[B])(Branch(_,_))
+}
\ No newline at end of file
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Either.scala b/src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Either.scala
new file mode 100644
index 0000000..0e0fa3c
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Either.scala
@@ -0,0 +1,73 @@
+package fpinscala.errorhandling
+
+
+//hide std library `Option` and `Either`, since we are writing our own in this chapter
+import scala.{Option => _, Either => _, _}
+
+sealed trait Either[+E,+A] {
+ def map[B](f: A => B): Either[E, B] = 
+   this match {
+     case Right(a) => Right(f(a))
+     case Left(e) => Left(e)
+   }
+   
+ def flatMap[EE >: E, B](f: A => Either[EE, B]): Either[EE, B] =
+   this match {
+     case Left(e) => Left(e)
+     case Right(a) => f(a)
+   }
+ def orElse[EE >: E, AA >: A](b: => Either[EE, AA]): Either[EE, AA] =
+   this match {
+     case Left(_) => b
+     case Right(a) => Right(a)
+   }
+ def map2[EE >: E, B, C](b: Either[EE, B])(f: (A, B) => C): 
+   Either[EE, C] = for { a <- this; b1 <- b } yield f(a,b1)
+}
+case class Left[+E](get: E) extends Either[E,Nothing]
+case class Right[+A](get: A) extends Either[Nothing,A]
+
+object Either {
+  def mean(xs: IndexedSeq[Double]): Either[String, Double] = 
+    if (xs.isEmpty) 
+      Left("mean of empty list!")
+    else 
+      Right(xs.sum / xs.length)
+
+  def safeDiv(x: Int, y: Int): Either[Exception, Int] = 
+    try Right(x / y)
+    catch { case e: Exception => Left(e) }
+
+  def Try[A](a: => A): Either[Exception, A] =
+    try Right(a)
+    catch { case e: Exception => Left(e) }
+
+  def traverse[E,A,B](es: List[A])(f: A => Either[E, B]): Either[E, List[B]] = 
+    es match {
+      case Nil => Right(Nil)
+      case h::t => (f(h) map2 traverse(t)(f))(_ :: _)
+    }
+  
+  def traverse_1[E,A,B](es: List[A])(f: A => Either[E, B]): Either[E, List[B]] = 
+    es.foldRight[Either[E,List[B]]](Right(Nil))((a, b) => f(a).map2(b)(_ :: _))
+  
+  def sequence[E,A](es: List[Either[E,A]]): Either[E,List[A]] = 
+    traverse(es)(x => x)
+
+  /*
+  There are a number of variations on `Option` and `Either`. If we want to accumulate multiple errors, a simple
+  approach is a new data type that lets us keep a list of errors in the data constructor that represents failures:
+  
+  trait Partial[+A,+B]
+  case class Errors[+A](get: Seq[A]) extends Partial[A,Nothing]
+  case class Success[+B](get: B) extends Partial[Nothing,B]
+  
+  There is a type very similar to this called `Validation` in the Scalaz library. You can implement `map`, `map2`,
+  `sequence`, and so on for this type in such a way that errors are accumulated when possible (`flatMap` is unable to
+  accumulate errors--can you see why?). This idea can even be generalized further--we don't need to accumulate failing
+  values into a list; we can accumulate values using any user-supplied binary function.
+  
+  It's also possible to use `Either[List[E],_]` directly to accumulate errors, using different implementations of
+  helper functions like `map2` and `sequence`.
+  */
+}
\ No newline at end of file
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Option.scala b/src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Option.scala
new file mode 100644
index 0000000..f2ca3dc
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/errorhandling/Option.scala
@@ -0,0 +1,113 @@
+package fpinscala.errorhandling
+
+//hide std library `Option` and `Either`, since we are writing our own in this chapter
+import scala.{Option => _, Either => _, _}
+
+sealed trait Option[+A] {
+  def map[B](f: A => B): Option[B] = this match {
+    case None => None
+    case Some(a) => Some(f(a))
+  }
+
+  def getOrElse[B>:A](default: => B): B = this match {
+    case None => default
+    case Some(a) => a
+  }
+
+  def flatMap[B](f: A => Option[B]): Option[B] =
+    map(f) getOrElse None
+
+  /*
+  Of course, we can also implement `flatMap` with explicit pattern matching.
+  */
+  def flatMap_1[B](f: A => Option[B]): Option[B] = this match {
+    case None => None
+    case Some(a) => f(a)
+  }
+
+  def orElse[B>:A](ob: => Option[B]): Option[B] =
+    this map (Some(_)) getOrElse ob
+
+  /*
+  Again, we can implement this with explicit pattern matching.
+  */
+  def orElse_1[B>:A](ob: => Option[B]): Option[B] = this match {
+    case None => ob
+    case _ => this
+  }
+
+  def filter(f: A => Boolean): Option[A] = this match {
+    case Some(a) if f(a) => this
+    case _ => None
+  }
+  /*
+  This can also be defined in terms of `flatMap`.
+  */
+  def filter_1(f: A => Boolean): Option[A] =
+    flatMap(a => if (f(a)) Some(a) else None)
+}
+case class Some[+A](get: A) extends Option[A]
+case object None extends Option[Nothing]
+
+object Option {
+  def failingFn(i: Int): Int = {
+    // `val y: Int = ...` declares `y` as having type `Int`, and sets it equal to the right hand side of the `=`.
+    val y: Int = throw new Exception("fail!")
+    try {
+      val x = 42 + 5
+      x + y
+    }
+    // A `catch` block is just a pattern matching block like the ones we've seen. `case e: Exception` is a pattern
+    // that matches any `Exception`, and it binds this value to the identifier `e`. The match returns the value 43.
+    catch { case e: Exception => 43 }
+  }
+
+  def failingFn2(i: Int): Int = {
+    try {
+      val x = 42 + 5
+      // A thrown Exception can be given any type; here we're annotating it with the type `Int`
+      x + ((throw new Exception("fail!")): Int)
+    }
+    catch { case e: Exception => 43 }
+  }
+
+  def mean(xs: Seq[Double]): Option[Double] =
+    if (xs.isEmpty) None
+    else Some(xs.sum / xs.length)
+
+  def variance(xs: Seq[Double]): Option[Double] =
+    mean(xs) flatMap (m => mean(xs.map(x => math.pow(x - m, 2))))
+
+  // a bit later in the chapter we'll learn nicer syntax for
+  // writing functions like this
+  def map2[A,B,C](a: Option[A], b: Option[B])(f: (A, B) => C): Option[C] =
+    a flatMap (aa => b map (bb => f(aa, bb)))
+
+  /*
+  Here's an explicit recursive version:
+  */
+  def sequence[A](a: List[Option[A]]): Option[List[A]] =
+    a match {
+      case Nil => Some(Nil)
+      case h :: t => h flatMap (hh => sequence(t) map (hh :: _))
+    }
+  /*
+  It can also be implemented using `foldRight` and `map2`. The type annotation on `foldRight` is needed here; otherwise
+  Scala wrongly infers the result type of the fold as `Some[Nil.type]` and reports a type error (try it!). This is an
+  unfortunate consequence of Scala using subtyping to encode algebraic data types.
+  */
+  def sequence_1[A](a: List[Option[A]]): Option[List[A]] =
+    a.foldRight[Option[List[A]]](Some(Nil))((x,y) => map2(x,y)(_ :: _))
+
+  def traverse[A, B](a: List[A])(f: A => Option[B]): Option[List[B]] =
+    a match {
+      case Nil => Some(Nil)
+      case h::t => map2(f(h), traverse(t)(f))(_ :: _)
+    }
+
+  def traverse_1[A, B](a: List[A])(f: A => Option[B]): Option[List[B]] =
+    a.foldRight[Option[List[B]]](Some(Nil))((h,t) => map2(f(h),t)(_ :: _))
+
+  def sequenceViaTraverse[A](a: List[Option[A]]): Option[List[A]] =
+    traverse(a)(x => x)
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala b/src/main/scala/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
new file mode 100644
index 0000000..9dadf08
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/gettingstarted/GettingStarted.scala
@@ -0,0 +1,180 @@
+package fpinscala.gettingstarted
+
+// A comment!
+/* Another comment */
+/** A documentation comment */
+object MyModule {
+  def abs(n: Int): Int =
+    if (n < 0) -n
+    else n
+
+  private def formatAbs(x: Int) = {
+    val msg = "The absolute value of %d is %d"
+    msg.format(x, abs(x))
+  }
+
+  def main(args: Array[String]): Unit =
+    println(formatAbs(-42))
+
+  // A definition of factorial, using a local, tail recursive function
+  def factorial(n: Int): Int = {
+    @annotation.tailrec
+    def go(n: Int, acc: Int): Int =
+      if (n <= 0) acc
+      else go(n-1, n*acc)
+
+    go(n, 1)
+  }
+
+  // Another implementation of `factorial`, this time with a `while` loop
+  def factorial2(n: Int): Int = {
+    var acc = 1
+    var i = n
+    while (i > 0) { acc *= i; i -= 1 }
+    acc
+  }
+
+  // Exercise 1: Write a function to compute the nth fibonacci number
+
+  // 0 and 1 are the first two numbers in the sequence,
+  // so we start the accumulators with those.
+  // At every iteration, we add the two numbers to get the next one.
+  def fib(n: Int): Int = {
+    @annotation.tailrec
+    def loop(n: Int, prev: Int, cur: Int): Int =
+      if (n == 0) prev
+      else loop(n - 1, cur, prev + cur)
+    loop(n, 0, 1)
+  }
+
+  // This definition and `formatAbs` are very similar..
+  private def formatFactorial(n: Int) = {
+    val msg = "The factorial of %d is %d."
+    msg.format(n, factorial(n))
+  }
+
+  // We can generalize `formatAbs` and `formatFactorial` to
+  // accept a _function_ as a parameter
+  def formatResult(name: String, n: Int, f: Int => Int) = {
+    val msg = "The %s of %d is %d."
+    msg.format(name, n, f(n))
+  }
+}
+
+object FormatAbsAndFactorial {
+
+  import MyModule._
+
+  // Now we can use our general `formatResult` function
+  // with both `abs` and `factorial`
+  def main(args: Array[String]): Unit = {
+    println(formatResult("absolute value", -42, abs))
+    println(formatResult("factorial", 7, factorial))
+  }
+}
+
+// Functions get passed around so often in FP that it's
+// convenient to have syntax for constructing a function
+// *without* having to give it a name
+object AnonymousFunctions {
+  import MyModule._
+
+  // Some examples of anonymous functions:
+  def main(args: Array[String]): Unit = {
+    println(formatResult("absolute value", -42, abs))
+    println(formatResult("factorial", 7, factorial))
+    println(formatResult("increment", 7, (x: Int) => x + 1))
+    println(formatResult("increment2", 7, (x) => x + 1))
+    println(formatResult("increment3", 7, x => x + 1))
+    println(formatResult("increment4", 7, _ + 1))
+    println(formatResult("increment5", 7, x => { val r = x + 1; r }))
+  }
+}
+
+object MonomorphicBinarySearch {
+
+  // First, a findFirst, specialized to `String`.
+  // Ideally, we could generalize this to work for any `Array` type.
+  def findFirst(ss: Array[String], key: String): Int = {
+    @annotation.tailrec
+    def loop(n: Int): Int =
+      // If `n` is past the end of the array, return `-1`
+      // indicating the key doesn't exist in the array.
+      if (n >= ss.length) -1
+      // `ss(n)` extracts the n'th element of the array `ss`.
+      // If the element at `n` is equal to the key, return `n`
+      // indicating that the element appears in the array at that index.
+      else if (ss(n) == key) n
+      else loop(n + 1) // Otherwise increment `n` and keep looking.
+    // Start the loop at the first element of the array.
+    loop(0)
+  }
+
+}
+
+object PolymorphicFunctions {
+
+  // Here's a polymorphic version of `findFirst`, parameterized on
+  // a function for testing whether an `A` is the element we want to find.
+  // Instead of hard-coding `String`, we take a type `A` as a parameter.
+  // And instead of hard-coding an equality check for a given key,
+  // we take a function with which to test each element of the array.
+  def findFirst[A](as: Array[A], p: A => Boolean): Int = {
+    @annotation.tailrec
+    def loop(n: Int): Int =
+      if (n >= as.length) -1
+      // If the function `p` matches the current element,
+      // we've found a match and we return its index in the array.
+      else if (p(as(n))) n
+      else loop(n + 1)
+
+    loop(0)
+  }
+
+
+  // Exercise 2: Implement a polymorphic function to check whether
+  // an `Array[A]` is sorted
+  def isSorted[A](as: Array[A], gt: (A,A) => Boolean): Boolean = {
+    @annotation.tailrec
+    def go(n: Int): Boolean =
+      if (n >= as.length-1) true
+      else if (gt(as(n), as(n+1))) false
+      else go(n+1)
+
+    go(0)
+  }
+
+  // Polymorphic functions are often so constrained by their type
+  // that they only have one implementation! Here's an example:
+
+  def partial1[A,B,C](a: A, f: (A,B) => C): B => C =
+    (b: B) => f(a, b)
+
+  // Exercise 3: Implement `curry`.
+
+  // Note that `=>` associates to the right, so we could
+  // write the return type as `A => B => C`
+  def curry[A,B,C](f: (A, B) => C): A => (B => C) =
+    a => b => f(a, b)
+
+  // NB: The `Function2` trait has a `curried` method already
+
+  // Exercise 4: Implement `uncurry`
+  def uncurry[A,B,C](f: A => B => C): (A, B) => C =
+    (a, b) => f(a)(b)
+
+  /*
+  NB: There is a method on the `Function` object in the standard library,
+  `Function.uncurried` that you can use for uncurrying.
+
+  Note that we can go back and forth between the two forms. We can curry
+  and uncurry and the two forms are in some sense "the same". In FP jargon,
+  we say that they are _isomorphic_ ("iso" = same; "morphe" = shape, form),
+  a term we inherit from category theory.
+  */
+
+  // Exercise 5: Implement `compose`
+
+  def compose[A,B,C](f: B => C, g: A => B): A => C =
+    a => f(g(a))
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/iomonad/BindTest.scala b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/BindTest.scala
new file mode 100644
index 0000000..803d0cc
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/BindTest.scala
@@ -0,0 +1,47 @@
+package fpinscala.iomonad
+
+import language.higherKinds
+import language.postfixOps
+
+object BindTest extends App {
+
+  def timeit(n: Int)(task: => Unit): Unit = {
+    val start = System.currentTimeMillis
+    (0 to n).foreach { _ => task }
+    val stop = System.currentTimeMillis
+    println((stop - start) / 1000.0 + " seconds")
+  }
+
+  val N = 100000
+  def go[F[_]](F: Monad[F])(unit: F[Unit])(f: F[Int] => Int): Unit = {
+    import F.toMonadic
+    f { (0 to N).map(i => F.map(unit)(_ => i)).foldLeft(F.unit(0)) {
+      (f1,f2) => for {
+        acc <- f1
+        i <- f2
+      } yield { // if (i == N) println("result: " + (acc+i))
+                (acc + i)
+              }
+    }}
+  }
+
+  import fpinscala.parallelism.Nonblocking._
+
+  object ParMonad extends Monad[Par] {
+    def unit[A](a: => A) = Par.unit(a)
+    def flatMap[A,B](pa: Par[A])(f: A => Par[B]) = Par.fork { Par.flatMap(pa)(f) }
+  }
+
+  val pool = java.util.concurrent.Executors.newFixedThreadPool(4)
+
+  timeit(10) { go(Throw)(Throw.unit(())) ( _ run ) }
+  timeit(10) { go(IO2b.TailRec)(IO2b.TailRec.unit(())) ( IO2b.run ) }
+  timeit(10) { go(IO2c.Async)(IO2c.Async.unit(()))(r => Par.run(pool) { IO2c.run(r) }) }
+  timeit(10) { go[IO](ioMonad)(ioMonad.unit(()))(r => unsafePerformIO(r)(pool)) }
+  timeit(10) { go(Task)(Task.now(()))(r => r.run(pool)) }
+  timeit(10) { go(Task)(Task.forkUnit(()))(r => r.run(pool)) }
+  timeit(10) { go(ParMonad)(ParMonad.unit(())) { p => Par.run(pool)(p) }}
+
+  // Par.run(pool)(ParMonad.forever { ParMonad.unit { println("woot") }})
+  pool.shutdown()
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/iomonad/IO.scala b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/IO.scala
new file mode 100644
index 0000000..47a1d34
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/IO.scala
@@ -0,0 +1,629 @@
+package fpinscala.iomonad
+
+import scala.io.StdIn.readLine
+import language.higherKinds
+import language.postfixOps
+
+object IO0 {
+                            /*
+
+  Our first attempt at data type for representing computations that
+  may perform I/O. Has a simple 'interpreter' baked in--the `run`
+  function, which just returns `Unit`.
+
+                             */
+  trait IO { self =>
+    def run: Unit
+    def ++(io: IO): IO = new IO {
+      def run = { self.run; io.run }
+    }
+  }
+  object IO {
+    def empty: IO = new IO { def run = () }
+  }
+
+                            /*
+
+  The API of this `IO` type isn't very useful.  Not many operations
+  (it is only a monoid), and not many laws to help with reasoning. It
+  is completely _opaque_. Also cannot represent _input_ effects, like
+  reading from console, for instance:
+
+                             */
+
+  def fahrenheitToCelsius(f: Double): Double =
+    (f - 32) * 5.0/9.0
+
+  // Ordinary code with side effects
+  def converter: Unit = {
+    println("Enter a temperature in degrees Fahrenheit: ")
+    val d = readLine.toDouble
+    println(fahrenheitToCelsius(d))
+  }
+
+  // A pure version is not possible!
+  /*
+  def converter: IO = {
+    val prompt: IO = PrintLine("Enter a temperature in degrees fahrenheit: ")
+    // now what ???
+  }
+  */
+}
+
+object IO1 {
+                            /*
+
+  We need a way for our `IO` actions to yield a result of some
+  meaningful type. We do this by adding a type parameter to `IO`,
+  which now forms a `Monad`.
+                             */
+
+  sealed trait IO[A] { self =>
+    def run: A
+    def map[B](f: A => B): IO[B] =
+      new IO[B] { def run = f(self.run) }
+    def flatMap[B](f: A => IO[B]): IO[B] =
+      new IO[B] { def run = f(self.run).run }
+  }
+
+  object IO extends Monad[IO] {
+    def unit[A](a: => A): IO[A] = new IO[A] { def run = a }
+    def flatMap[A,B](fa: IO[A])(f: A => IO[B]) = fa flatMap f
+    def apply[A](a: => A): IO[A] = unit(a) // syntax for IO { .. }
+
+    def ref[A](a: A): IO[IORef[A]] = IO { new IORef(a) }
+    sealed class IORef[A](var value: A) {
+      def set(a: A): IO[A] = IO { value = a; a }
+      def get: IO[A] = IO { value }
+      def modify(f: A => A): IO[A] = get flatMap (a => set(f(a)))
+    }
+  }
+
+  // We can now express the example
+
+  def ReadLine: IO[String] = IO { readLine }
+  def PrintLine(msg: String): IO[Unit] = IO { println(msg) }
+  import IO0.fahrenheitToCelsius
+
+  def converter: IO[Unit] = for {
+    _ <- PrintLine("Enter a temperature in degrees Fahrenheit: ")
+    d <- ReadLine.map(_.toDouble)
+    _ <- PrintLine(fahrenheitToCelsius(d).toString)
+  } yield ()
+
+  /*                         Some other examples                      */
+
+  import IO._ // import all the `IO` combinators that come from `Monad`
+
+  // An `IO[Unit]` that reads a line from the console and echoes it back.
+  val echo = ReadLine.flatMap(PrintLine)
+
+  // Parses an `Int` by reading a line from the console.
+  val readInt: IO[Int] = ReadLine.map(_.toInt)
+
+  // Parses an `(Int,Int)` by reading two lines from the console.
+  val readInts: IO[(Int,Int)] = readInt ** readInt
+
+  // Repeat `converter` 5 times, discarding the results (which are
+  // just `Unit`). We can replace `converter` here with any `IO`
+  // action we wished to repeat 5 times (ex: `echo` or `readInts`).
+  val prompts: IO[Unit] = replicateM_(5)(converter)
+
+  // An `IO[List[String]]` that will read 10 lines from the console and
+  // return the list of results.
+  val lines: IO[List[String]] = replicateM(10)(ReadLine)
+
+                            /*
+
+  Larger example using various monadic combinators. Sample run:
+
+     The Amazing Factorial REPL, v2.0
+     q - quit
+     <number> - compute the factorial of the given number
+     <anything else> - bomb with horrible error
+     3
+     factorial: 6
+     7
+     factorial: 5040
+     q
+
+                             */
+  val helpstring = """
+  | The Amazing Factorial REPL, v2.0
+  | q - quit
+  | <number> - compute the factorial of the given number
+  | <anything else> - bomb with horrible error
+  """.trim.stripMargin
+
+  def factorial(n: Int): IO[Int] = for {
+    acc <- ref(1)
+    _ <- foreachM (1 to n toStream) (i => acc.modify(_ * i).skip)
+    result <- acc.get
+  } yield result
+
+  val factorialREPL: IO[Unit] = sequence_(
+    IO { println(helpstring) },
+    doWhile { IO { readLine } } { line =>
+      val ok = line != "q"
+      when (ok) { for {
+        n <- factorial(line.toInt)
+        _ <- IO { println("factorial: " + n) }
+      } yield () }
+    }
+  )
+}
+
+
+object IO2a {
+
+  /*
+  The previous IO representation overflows the stack for some programs.
+  The problem is that `run` call itself recursively, which means that
+  an infinite or long running IO computation will have a chain of regular
+  calls to `run`, eventually overflowing the stack.
+
+  The general solution is to make the `IO` type into a data type that we
+  interpret using a tail recursive loop, using pattern matching.
+  */
+
+  sealed trait IO[A] {
+    def flatMap[B](f: A => IO[B]): IO[B] =
+      FlatMap(this, f) // we do not interpret the `flatMap` here, just return it as a value
+    def map[B](f: A => B): IO[B] =
+      flatMap(f andThen (Return(_)))
+  }
+  case class Return[A](a: A) extends IO[A]
+  case class Suspend[A](resume: () => A) extends IO[A]
+  case class FlatMap[A,B](sub: IO[A], k: A => IO[B]) extends IO[B]
+
+  object IO extends Monad[IO] { // Notice that none of these operations DO anything
+    def unit[A](a: => A): IO[A] = Return(a)
+    def flatMap[A,B](a: IO[A])(f: A => IO[B]): IO[B] = a flatMap f
+    def suspend[A](a: => IO[A]) =
+      Suspend(() => ()).flatMap { _ => a }
+
+  }
+
+  def printLine(s: String): IO[Unit] =
+    Suspend(() => Return(println(s)))
+
+  val p = IO.forever(printLine("Still going..."))
+
+  val actions: Stream[IO[Unit]] =
+    Stream.fill(100000)(printLine("Still going..."))
+  val composite: IO[Unit] =
+    actions.foldLeft(IO.unit(())) { (acc, a) => acc flatMap { _ => a } }
+
+  // There is only one sensible way to implement this as a
+  // tail-recursive function, the one tricky case is left-nested
+  // flatMaps, as in `((a flatMap f) flatMap g)`, which we
+  // reassociate to the right as `a flatMap (ar => f(a) flatMap g)`
+  @annotation.tailrec def run[A](io: IO[A]): A = io match {
+    case Return(a) => a
+    case Suspend(r) => r()
+    case FlatMap(x, f) => x match {
+      case Return(a) => run(f(a))
+      case Suspend(r) => run(f(r()))
+      case FlatMap(y, g) => run(y flatMap (a => g(a) flatMap f))
+    }
+  }
+}
+
+object IO2aTests {
+  import IO2a._
+
+  /*
+  Pg 240: REPL session has a typo, should be:
+
+  val g = List.fill(100000)(f).foldLeft(f) {
+    (a, b) => x => Suspend(() => ()).flatMap { _ => a(x).flatMap(b)}
+  }
+
+  Note: we could write a little helper function to make this nicer:
+
+  def suspend[A](a: => IO[A]) = Suspend(() => ()).flatMap { _ => a }
+
+  val g = List.fill(100000)(f).foldLeft(f) {
+    (a, b) => x => suspend { a(x).flatMap(b) }
+  }
+   */
+
+  val f: Int => IO[Int] = (i: Int) => Return(i)
+
+  val g: Int => IO[Int] =
+    List.fill(10000)(f).foldLeft(f){
+      (a: Function1[Int, IO[Int]],
+        b: Function1[Int, IO[Int]]) => {
+        (x: Int) => IO.suspend(a(x).flatMap(b))
+      }
+    }
+
+  def main(args: Array[String]): Unit = {
+    val gFortyTwo = g(42)
+    println("g(42) = " + gFortyTwo)
+    println("run(g(42)) = " + run(gFortyTwo))
+  }
+}
+
+
+
+object IO2b {
+
+  /*
+   * As it turns out, there's nothing about this data type that is specific
+   * to I/O, it's just a general purpose data type for optimizing tail calls.
+   * Here it is, renamed to `TailRec`. This type is also sometimes called
+   * `Trampoline`, because of the way interpreting it bounces back and forth
+   * between the main `run` loop and the functions contained in the `TailRec`.
+   */
+
+  sealed trait TailRec[A] {
+    def flatMap[B](f: A => TailRec[B]): TailRec[B] =
+      FlatMap(this, f)
+    def map[B](f: A => B): TailRec[B] =
+      flatMap(f andThen (Return(_)))
+  }
+  case class Return[A](a: A) extends TailRec[A]
+  case class Suspend[A](resume: () => A) extends TailRec[A]
+  case class FlatMap[A,B](sub: TailRec[A], k: A => TailRec[B]) extends TailRec[B]
+
+  object TailRec extends Monad[TailRec] {
+    def unit[A](a: => A): TailRec[A] = Return(a)
+    def flatMap[A,B](a: TailRec[A])(f: A => TailRec[B]): TailRec[B] = a flatMap f
+    def suspend[A](a: => TailRec[A]) =
+      Suspend(() => ()).flatMap { _ => a }
+
+  }
+
+  @annotation.tailrec def run[A](t: TailRec[A]): A = t match {
+    case Return(a) => a
+    case Suspend(r) => r()
+    case FlatMap(x, f) => x match {
+      case Return(a) => run(f(a))
+      case Suspend(r) => run(f(r()))
+      case FlatMap(y, g) => run(y flatMap (a => g(a) flatMap f))
+    }
+  }
+}
+
+object IO2bTests {
+  import IO2b._
+
+  val f: Int => TailRec[Int] = (i: Int) => Return(i)
+
+  val g: Int => TailRec[Int] =
+    List.fill(10000)(f).foldLeft(f){
+      (a: Function1[Int, TailRec[Int]],
+        b: Function1[Int, TailRec[Int]]) => {
+        (x: Int) => TailRec.suspend(a(x).flatMap(b))
+      }
+    }
+
+  def main(args: Array[String]): Unit = {
+    val gFortyTwo = g(42)
+    println("g(42) = " + gFortyTwo)
+    println("run(g(42)) = " + run(gFortyTwo))
+  }
+}
+
+
+object IO2c {
+
+  import fpinscala.parallelism.Nonblocking._
+
+  /*
+   * We've solved our first problem of ensuring stack safety, but we're still
+   * being very inexplicit about what sort of effects can occur, and we also
+   * haven't found a way of describing asynchronous computations. Our `Suspend`
+   * thunks will just block the current thread when run by the interpreter.
+   * We could fix that by changing the signature of `Suspend` to take a `Par`.
+   * We'll call this new type `Async`.
+   */
+
+  sealed trait Async[A] { // will rename this type to `Async`
+    def flatMap[B](f: A => Async[B]): Async[B] =
+      FlatMap(this, f)
+    def map[B](f: A => B): Async[B] =
+      flatMap(f andThen (Return(_)))
+  }
+  case class Return[A](a: A) extends Async[A]
+  case class Suspend[A](resume: Par[A]) extends Async[A] // notice this is a `Par`
+  case class FlatMap[A,B](sub: Async[A], k: A => Async[B]) extends Async[B]
+
+  object Async extends Monad[Async] {
+    def unit[A](a: => A): Async[A] = Return(a)
+    def flatMap[A,B](a: Async[A])(f: A => Async[B]): Async[B] = a flatMap f
+  }
+
+  // return either a `Suspend`, a `Return`, or a right-associated `FlatMap`
+  @annotation.tailrec def step[A](async: Async[A]): Async[A] = async match {
+    case FlatMap(FlatMap(x, f), g) => step(x flatMap (a => f(a) flatMap g))
+    case FlatMap(Return(x), f) => step(f(x))
+    case _ => async
+  }
+
+  def run[A](async: Async[A]): Par[A] = step(async) match {
+    case Return(a) => Par.unit(a)
+    case Suspend(r) => r
+    case FlatMap(x, f) => x match {
+      case Suspend(r) => Par.flatMap(r)(a => run(f(a)))
+      case _ => sys.error("Impossible, since `step` eliminates these cases")
+    }
+  }
+  // The fact that `run` only uses the `unit` and `flatMap` functions of
+  // `Par` is a clue that choosing `Par` was too specific of a choice,
+  // this interpreter could be generalized to work with any monad.
+}
+
+
+object IO3 {
+
+  /*
+  We can generalize `TailRec` and `Async` to the type `Free`, which is
+  a `Monad` for any choice of `F`.
+  */
+
+  sealed trait Free[F[_],A] {
+    def flatMap[B](f: A => Free[F,B]): Free[F,B] =
+      FlatMap(this, f)
+    def map[B](f: A => B): Free[F,B] =
+      flatMap(f andThen (Return(_)))
+  }
+  case class Return[F[_],A](a: A) extends Free[F, A]
+  case class Suspend[F[_],A](s: F[A]) extends Free[F, A]
+  case class FlatMap[F[_],A,B](s: Free[F, A],
+                               f: A => Free[F, B]) extends Free[F, B]
+
+  // Exercise 1: Implement the free monad
+  def freeMonad[F[_]]: Monad[({type f[a] = Free[F,a]})#f] =
+    new Monad[({type f[a] = Free[F,a]})#f] {
+      def unit[A](a: => A) = Return(a)
+      def flatMap[A,B](fa: Free[F, A])(f: A => Free[F, B]) = fa flatMap f
+    }
+
+  // Exercise 2: Implement a specialized `Function0` interpreter.
+  @annotation.tailrec
+  def runTrampoline[A](a: Free[Function0,A]): A = (a) match {
+    case Return(a) => a
+    case Suspend(r) => r()
+    case FlatMap(x,f) => x match {
+      case Return(a) => runTrampoline { f(a) }
+      case Suspend(r) => runTrampoline { f(r()) }
+      case FlatMap(a0,g) => runTrampoline { a0 flatMap { a0 => g(a0) flatMap f } }
+    }
+  }
+
+  // Exercise 3: Implement a `Free` interpreter which works for any `Monad`
+  def run[F[_],A](a: Free[F,A])(implicit F: Monad[F]): F[A] = step(a) match {
+    case Return(a) => F.unit(a)
+    case Suspend(r) => r
+    case FlatMap(Suspend(r), f) => F.flatMap(r)(a => run(f(a)))
+    case _ => sys.error("Impossible, since `step` eliminates these cases")
+  }
+
+  // return either a `Suspend`, a `Return`, or a right-associated `FlatMap`
+  @annotation.tailrec
+  def step[F[_],A](a: Free[F,A]): Free[F,A] = a match {
+    case FlatMap(FlatMap(x, f), g) => step(x flatMap (a => f(a) flatMap g))
+    case FlatMap(Return(x), f) => step(f(x))
+    case _ => a
+  }
+
+  /*
+  The type constructor `F` lets us control the set of external requests our
+  program is allowed to make. For instance, here is a type that allows for
+  only console I/O effects.
+  */
+
+  import fpinscala.parallelism.Nonblocking.Par
+
+  sealed trait Console[A] {
+    def toPar: Par[A]
+    def toThunk: () => A
+
+    // other interpreters
+    def toState: ConsoleState[A]
+    def toReader: ConsoleReader[A]
+  }
+
+  case object ReadLine extends Console[Option[String]] {
+    def toPar = Par.lazyUnit(run)
+    def toThunk = () => run
+
+    def run: Option[String] =
+      try Some(readLine())
+      catch { case e: Exception => None }
+
+    def toState = ConsoleState { bufs =>
+      bufs.in match {
+        case List() => (None, bufs)
+        case h :: t => (Some(h), bufs.copy(in = t))
+      }
+    }
+    def toReader = ConsoleReader { in => Some(in) }
+  }
+
+  case class PrintLine(line: String) extends Console[Unit] {
+    def toPar = Par.lazyUnit(println(line))
+    def toThunk = () => println(line)
+    def toReader = ConsoleReader { s => () } // noop
+    def toState = ConsoleState { bufs => ((), bufs.copy(out = bufs.out :+ line)) } // append to the output
+  }
+
+  object Console {
+    type ConsoleIO[A] = Free[Console, A]
+
+    def readLn: ConsoleIO[Option[String]] =
+      Suspend(ReadLine)
+
+    def printLn(line: String): ConsoleIO[Unit] =
+      Suspend(PrintLine(line))
+  }
+
+  /*
+  How do we actually _run_ a `ConsoleIO` program? We don't have a `Monad[Console]`
+  for calling `run`, and we can't use `runTrampoline` either since we have `Console`,
+  not `Function0`. We need a way to translate from `Console` to `Function0`
+  (if we want to evaluate it sequentially) or a `Par`.
+
+  We introduce the following type to do this translation:
+  */
+
+  /* Translate between any `F[A]` to `G[A]`. */
+  trait Translate[F[_], G[_]] { def apply[A](f: F[A]): G[A] }
+
+  type ~>[F[_], G[_]] = Translate[F,G] // gives us infix syntax `F ~> G` for `Translate[F,G]`
+
+  implicit val function0Monad = new Monad[Function0] {
+    def unit[A](a: => A) = () => a
+    def flatMap[A,B](a: Function0[A])(f: A => Function0[B]) =
+      () => f(a())()
+  }
+
+  implicit val parMonad = new Monad[Par] {
+    def unit[A](a: => A) = Par.unit(a)
+    def flatMap[A,B](a: Par[A])(f: A => Par[B]) = Par.fork { Par.flatMap(a)(f) }
+  }
+
+  def runFree[F[_],G[_],A](free: Free[F,A])(t: F ~> G)(
+                           implicit G: Monad[G]): G[A] =
+    step(free) match {
+      case Return(a) => G.unit(a)
+      case Suspend(r) => t(r)
+      case FlatMap(Suspend(r), f) => G.flatMap(t(r))(a => runFree(f(a))(t))
+      case _ => sys.error("Impossible, since `step` eliminates these cases")
+    }
+
+  val consoleToFunction0 =
+    new (Console ~> Function0) { def apply[A](a: Console[A]) = a.toThunk }
+  val consoleToPar =
+    new (Console ~> Par) { def apply[A](a: Console[A]) = a.toPar }
+
+  def runConsoleFunction0[A](a: Free[Console,A]): () => A =
+    runFree[Console,Function0,A](a)(consoleToFunction0)
+  def runConsolePar[A](a: Free[Console,A]): Par[A] =
+    runFree[Console,Par,A](a)(consoleToPar)
+
+  /*
+  The `runConsoleFunction0` implementation is unfortunately not stack safe,
+  because it relies of the stack safety of the underlying monad, and the
+  `Function0` monad we gave is not stack safe. To see the problem, try
+  running: `freeMonad.forever(Console.printLn("Hello"))`.
+  */
+
+  // Exercise 4 (optional, hard): Implement `runConsole` using `runFree`,
+  // without going through `Par`. Hint: define `translate` using `runFree`.
+
+  def translate[F[_],G[_],A](f: Free[F,A])(fg: F ~> G): Free[G,A] = {
+    type FreeG[A] = Free[G,A]
+    val t = new (F ~> FreeG) {
+      def apply[A](a: F[A]): Free[G,A] = Suspend { fg(a) }
+    }
+    runFree(f)(t)(freeMonad[G])
+  }
+
+  def runConsole[A](a: Free[Console,A]): A =
+    runTrampoline { translate(a)(new (Console ~> Function0) {
+      def apply[A](c: Console[A]) = c.toThunk
+    })}
+
+
+  /*
+  There is nothing about `Free[Console,A]` that requires we interpret
+  `Console` using side effects. Here are two pure ways of interpreting
+  a `Free[Console,A]`.
+  */
+  import Console._
+
+  case class Buffers(in: List[String], out: Vector[String])
+
+  // A specialized state monad
+  case class ConsoleState[A](run: Buffers => (A, Buffers)) {
+    def map[B](f: A => B): ConsoleState[B] =
+      ConsoleState { s =>
+        val (a, s1) = run(s)
+        (f(a), s1)
+      }
+    def flatMap[B](f: A => ConsoleState[B]): ConsoleState[B] =
+      ConsoleState { s =>
+        val (a, s1) = run(s)
+        f(a).run(s1)
+      }
+  }
+  object ConsoleState {
+    implicit val monad = new Monad[ConsoleState] {
+      def unit[A](a: => A) = ConsoleState(bufs => (a,bufs))
+      def flatMap[A,B](ra: ConsoleState[A])(f: A => ConsoleState[B]) = ra flatMap f
+    }
+  }
+
+  // A specialized reader monad
+  case class ConsoleReader[A](run: String => A) {
+    def map[B](f: A => B): ConsoleReader[B] =
+      ConsoleReader(r => f(run(r)))
+    def flatMap[B](f: A => ConsoleReader[B]): ConsoleReader[B] =
+      ConsoleReader(r => f(run(r)).run(r))
+  }
+  object ConsoleReader {
+    implicit val monad = new Monad[ConsoleReader] {
+      def unit[A](a: => A) = ConsoleReader(_ => a)
+      def flatMap[A,B](ra: ConsoleReader[A])(f: A => ConsoleReader[B]) = ra flatMap f
+    }
+  }
+
+  val consoleToState =
+    new (Console ~> ConsoleState) { def apply[A](a: Console[A]) = a.toState }
+  val consoleToReader =
+    new (Console ~> ConsoleReader) { def apply[A](a: Console[A]) = a.toReader }
+
+  /* Can interpet these as before to convert our `ConsoleIO` to a pure value that does no I/O! */
+  def runConsoleReader[A](io: ConsoleIO[A]): ConsoleReader[A] =
+    runFree[Console,ConsoleReader,A](io)(consoleToReader)
+
+  def runConsoleState[A](io: ConsoleIO[A]): ConsoleState[A] =
+    runFree[Console,ConsoleState,A](io)(consoleToState)
+
+  // So `Free[F,A]` is not really an I/O type. The interpreter `runFree` gets
+  // to choose how to interpret these `F` requests, and whether to do "real" I/O
+  // or simply convert to some pure value!
+
+  // NB: These interpretations are not stack safe for the same reason,
+  // can instead work with `case class ConsoleReader[A](run: String => Trampoline[A])`,
+  // which gives us a stack safe monad
+
+  // We conclude that a good representation of an `IO` monad is this:
+  type IO[A] = Free[Par, A]
+
+  /*
+   * Exercise 5: Implement a non-blocking read from an asynchronous file channel.
+   * We'll just give the basic idea - here, we construct a `Future`
+   * by reading from an `AsynchronousFileChannel`, a `java.nio` class
+   * which supports asynchronous reads.
+   */
+
+  import java.nio._
+  import java.nio.channels._
+
+  // Provides the syntax `Async { k => ... }` for asyncronous IO blocks.
+  def Async[A](cb: (A => Unit) => Unit): IO[A] =
+    Suspend(Par.async(cb))
+
+  // Provides the `IO { ... }` syntax for synchronous IO blocks.
+  def IO[A](a: => A): IO[A] = Suspend { Par.delay(a) }
+
+  def read(file: AsynchronousFileChannel,
+           fromPosition: Long,
+           numBytes: Int): Par[Either[Throwable, Array[Byte]]] =
+    Par.async { (cb: Either[Throwable, Array[Byte]] => Unit) =>
+      val buf = ByteBuffer.allocate(numBytes)
+      file.read(buf, fromPosition, (), new CompletionHandler[Integer, Unit] {
+        def completed(bytesRead: Integer, ignore: Unit) = {
+          val arr = new Array[Byte](bytesRead)
+          buf.slice.get(arr, 0, bytesRead)
+          cb(Right(arr))
+        }
+        def failed(err: Throwable, ignore: Unit) =
+          cb(Left(err))
+      })
+    }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Monad.scala b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Monad.scala
new file mode 100644
index 0000000..52b35e2
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Monad.scala
@@ -0,0 +1,72 @@
+package fpinscala.iomonad
+
+import language.higherKinds // Disable warnings for type constructor polymorphism
+import language.implicitConversions
+
+trait Functor[F[_]] {
+  def map[A,B](a: F[A])(f: A => B): F[B]
+}
+
+trait Monad[F[_]] extends Functor[F] {
+  def unit[A](a: => A): F[A]
+  def flatMap[A,B](a: F[A])(f: A => F[B]): F[B]
+
+  def map[A,B](a: F[A])(f: A => B): F[B] = flatMap(a)(a => unit(f(a)))
+  def map2[A,B,C](a: F[A], b: F[B])(f: (A,B) => C): F[C] =
+    flatMap(a)(a => map(b)(b => f(a,b)))
+  def sequence_[A](fs: Stream[F[A]]): F[Unit] = foreachM(fs)(skip)
+  def sequence_[A](fs: F[A]*): F[Unit] = sequence_(fs.toStream)
+  def replicateM[A](n: Int)(f: F[A]): F[List[A]] =
+    Stream.fill(n)(f).foldRight(unit(List[A]()))(map2(_,_)(_ :: _))
+  def replicateM_[A](n: Int)(f: F[A]): F[Unit] =
+    foreachM(Stream.fill(n)(f))(skip)
+  def as[A,B](a: F[A])(b: B): F[B] = map(a)(_ => b)
+  def skip[A](a: F[A]): F[Unit] = as(a)(())
+  def when[A](b: Boolean)(fa: => F[A]): F[Boolean] =
+    if (b) as(fa)(true) else unit(false)
+  def forever[A,B](a: F[A]): F[B] = {
+    lazy val t: F[B] = a flatMap (_ => t)
+    t
+  }
+  def while_(a: F[Boolean])(b: F[Unit]): F[Unit] = {
+    lazy val t: F[Unit] = while_(a)(b)
+    a flatMap (c => skip(when(c)(t)))
+  }
+  def doWhile[A](a: F[A])(cond: A => F[Boolean]): F[Unit] = for {
+    a1 <- a
+    ok <- cond(a1)
+    _ <- if (ok) doWhile(a)(cond) else unit(())
+  } yield ()
+
+  def foldM[A,B](l: Stream[A])(z: B)(f: (B,A) => F[B]): F[B] =
+    l match {
+      case h #:: t => f(z,h) flatMap (z2 => foldM(t)(z2)(f))
+      case _ => unit(z)
+    }
+  def foldM_[A,B](l: Stream[A])(z: B)(f: (B,A) => F[B]): F[Unit] =
+    skip { foldM(l)(z)(f) }
+  def foreachM[A](l: Stream[A])(f: A => F[Unit]): F[Unit] =
+    foldM_(l)(())((u,a) => skip(f(a)))
+  def seq[A,B,C](f: A => F[B])(g: B => F[C]): A => F[C] =
+    f andThen (fb => flatMap(fb)(g))
+
+  // syntax
+  implicit def toMonadic[A](a: F[A]): Monadic[F,A] =
+    new Monadic[F,A] { val F = Monad.this; def get = a }
+}
+
+trait Monadic[F[_],A] {
+  val F: Monad[F]
+  import F._
+  def get: F[A]
+  private val a = get
+  def map[B](f: A => B): F[B] = F.map(a)(f)
+  def flatMap[B](f: A => F[B]): F[B] = F.flatMap(a)(f)
+  def **[B](b: F[B]) = F.map2(a,b)((_,_))
+  def *>[B](b: F[B]) = F.map2(a,b)((_,b) => b)
+  def map2[B,C](b: F[B])(f: (A,B) => C): F[C] = F.map2(a,b)(f)
+  def as[B](b: B): F[B] = F.as(a)(b)
+  def skip: F[Unit] = F.skip(a)
+  def replicateM(n: Int) = F.replicateM(n)(a)
+  def replicateM_(n: Int) = F.replicateM_(n)(a)
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Task.scala b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Task.scala
new file mode 100644
index 0000000..0e8349a
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Task.scala
@@ -0,0 +1,67 @@
+package fpinscala.iomonad
+
+import fpinscala.parallelism.Nonblocking._
+import java.util.concurrent.ExecutorService
+
+/*
+ * `Task[A]` is a wrapper around `Free[Par, Either[Throwable, A]]`, with some
+ * convenience functions for handling exceptions.
+ */
+case class Task[A](get: IO[Either[Throwable, A]]) {
+
+  def flatMap[B](f: A => Task[B]): Task[B] =
+    Task(get.flatMap {
+      case Left(e) => IO(Left(e))
+      case Right(a) => f(a).get
+    })
+
+  def map[B](f: A => B): Task[B] = flatMap(f andThen (Task.now))
+
+  /* 'Catches' exceptions in the given task and returns them as values. */
+  def attempt: Task[Either[Throwable,A]] =
+    Task(get map {
+      case Left(e) => Right(Left(e))
+      case Right(a) => Right(Right(a))
+    })
+
+  def handle[B>:A](f: PartialFunction[Throwable,B]): Task[B] =
+    attempt flatMap {
+      case Left(e) => f.lift(e) map (Task.now) getOrElse Task.fail(e)
+      case Right(a) => Task.now(a)
+    }
+
+  def or[B>:A](t2: Task[B]): Task[B] =
+    Task(this.get flatMap {
+      case Left(e) => t2.get
+      case a => IO(a)
+    })
+
+  def run(implicit E: ExecutorService): A = unsafePerformIO(get) match {
+    case Left(e) => throw e
+    case Right(a) => a
+  }
+
+  def attemptRun(implicit E: ExecutorService): Either[Throwable,A] =
+    try unsafePerformIO(get) catch { case t: Throwable => Left(t) }
+}
+
+object Task extends Monad[Task] {
+  def unit[A](a: => A) = Task(IO(Try(a)))
+
+  def flatMap[A,B](a: Task[A])(f: A => Task[B]): Task[B] =
+    a flatMap f
+
+  def fail[A](e: Throwable): Task[A] = Task(IO(Left(e)))
+  def now[A](a: A): Task[A] = Task(Return(Right(a)))
+
+  def more[A](a: => Task[A]): Task[A] = Task.now(()) flatMap (_ => a)
+
+  def delay[A](a: => A): Task[A] = more(now(a))
+  def fork[A](a: => Task[A]): Task[A] =
+    Task { par { Par.lazyUnit(()) } flatMap (_ => a.get) }
+  def forkUnit[A](a: => A): Task[A] = fork(now(a))
+
+  def Try[A](a: => A): Either[Throwable,A] =
+    try Right(a) catch { case e: Throwable => Left(e) }
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Throw.scala b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Throw.scala
new file mode 100644
index 0000000..5bf1d6b
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/Throw.scala
@@ -0,0 +1,65 @@
+package fpinscala.iomonad
+
+/**
+ * A version of `TailRec` implemented using exceptions.
+ * In the implementation of `flatMap`, rather than calling
+ * the function, we throw an exception indicating what
+ * function we want to call. A central loop repeatedly tries
+ * and catches these exceptions to force the computation.
+ */
+trait Throw[+A] {
+  import Throw._
+
+  @annotation.tailrec
+  final def run: A = this match {
+    case Done(a) => a
+    case More(thunk) => force(thunk).run
+  }
+}
+
+object Throw extends Monad[Throw] {
+
+  /* Exception indicating that the central loop should call `f(a)`. */
+  case class Call[A,+B] private[Throw] (a: A, f: A => B) extends Exception {
+    override def fillInStackTrace = this
+  }
+
+  case class Done[+A](a: A) extends Throw[A]
+  case class More[+A](thunk: () => Throw[A]) extends Throw[A]
+
+  /* Defer evaluation of `f(a)` to the central evaluation loop. */
+  def defer[A,B](a: A)(f: A => B): B =
+    throw new Call(a, f)
+
+  /* Central evaluation loop. */
+  def ap[A,B](a: A)(f: A => B): B = {
+    var ai: Any = a
+    var fi: Any => Any = f.asInstanceOf[Any => Any]
+    while (true) {
+      try return fi(ai).asInstanceOf[B]
+      catch { case Call(a2,f2) => ai = a2; fi = f2; }
+    }
+    return null.asInstanceOf[B] // unreachable
+  }
+
+  /* Convenience function for forcing a thunk. */
+  def force[A](f: () => A): A =
+    ap(f)(f => f())
+
+  def more[A](a: => Throw[A]): Throw[A] = More(() => a)
+
+  /* `Throw` forms a `Monad`. */
+
+  def unit[A](a: => A): Throw[A] = more(Done(a))
+
+  def flatMap[A,B](a: Throw[A])(f: A => Throw[B]): Throw[B] =
+    a match {
+      case Done(a) => f(a)
+      case More(thunk) =>
+        try thunk() flatMap f
+        catch { case Call(a0,g) => more {
+          defer(a0)(g.asInstanceOf[Any => Throw[A]].
+                    andThen(_ flatMap f))
+        }}
+    }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/iomonad/package.scala b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/package.scala
new file mode 100644
index 0000000..29c2b6e
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/iomonad/package.scala
@@ -0,0 +1,37 @@
+package fpinscala
+
+import language.higherKinds
+
+package object iomonad {
+  import fpinscala.parallelism.Nonblocking._
+
+  type IO[A] = IO3.IO[A]
+  def IO[A](a: => A): IO[A] = IO3.IO[A](a)
+
+  implicit val ioMonad = IO3.freeMonad[Par]
+
+  def now[A](a: A): IO[A] = IO3.Return(a)
+
+  def fork[A](a: => IO[A]): IO[A] = par(Par.lazyUnit(())) flatMap (_ => a)
+
+  def forkUnit[A](a: => A): IO[A] = fork(now(a))
+
+  def delay[A](a: => A): IO[A] = now(()) flatMap (_ => now(a))
+
+  def par[A](a: Par[A]): IO[A] = IO3.Suspend(a)
+
+  def async[A](cb: ((A => Unit) => Unit)): IO[A] =
+    fork(par(Par.async(cb)))
+
+  type Free[F[_], A] = IO3.Free[F, A]
+
+  def Return[A](a: A): IO[A] = IO3.Return[Par,A](a)
+
+  // To run an `IO`, we need an executor service.
+  // The name we have chosen for this method, `unsafePerformIO`,
+  // reflects that is is unsafe, i.e. that it has side effects,
+  // and that it _performs_ the actual I/O.
+  import java.util.concurrent.ExecutorService
+  def unsafePerformIO[A](io: IO[A])(implicit E: ExecutorService): A =
+    Par.run(E) { IO3.run(io)(IO3.parMonad) }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/laziness/Stream.scala b/src/main/scala/answers/src/main/scala/fpinscala/laziness/Stream.scala
new file mode 100644
index 0000000..d2a2f94
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/laziness/Stream.scala
@@ -0,0 +1,257 @@
+package fpinscala.laziness
+
+import Stream._
+trait Stream[+A] {
+
+  // The natural recursive solution
+  def toListRecursive: List[A] = this match {
+    case Cons(h,t) => h() :: t().toListRecursive
+    case _ => List()
+  }
+
+  /*
+  The above solution will stack overflow for large streams, since it's
+  not tail-recursive. Here is a tail-recursive implementation. At each
+  step we cons onto the front of the `acc` list, which will result in the
+  reverse of the stream. Then at the end we reverse the result to get the
+  correct order again.
+  */
+  def toList: List[A] = {
+    @annotation.tailrec
+    def go(s: Stream[A], acc: List[A]): List[A] = s match {
+      case Cons(h,t) => go(t(), h() :: acc)
+      case _ => acc
+    }
+    go(this, List()).reverse
+  }
+
+  /*
+  In order to avoid the `reverse` at the end, we could write it using a
+  mutable list buffer and an explicit loop instead. Note that the mutable
+  list buffer never escapes our `toList` method, so this function is
+  still _pure_.
+  */
+  def toListFast: List[A] = {
+    val buf = new collection.mutable.ListBuffer[A]
+    @annotation.tailrec
+    def go(s: Stream[A]): List[A] = s match {
+      case Cons(h,t) =>
+        buf += h()
+        go(t())
+      case _ => buf.toList
+    }
+    go(this)
+  }
+
+  /*
+    Create a new Stream[A] from taking the n first elements from this. We can achieve that by recursively
+    calling take on the invoked tail of a cons cell. We make sure that the tail is not invoked unless
+    we need to, by handling the special case where n == 1 separately. If n == 0, we can avoid looking
+    at the stream at all.
+  */
+  def take(n: Int): Stream[A] = this match {
+    case Cons(h, t) if n > 1 => cons(h(), t().take(n - 1))
+    case Cons(h, _) if n == 1 => cons(h(), empty)
+    case _ => empty
+  }
+
+  /*
+    Create a new Stream[A] from this, but ignore the n first elements. This can be achieved by recursively calling
+    drop on the invoked tail of a cons cell. Note that the implementation is also tail recursive.
+  */
+  @annotation.tailrec
+  final def drop(n: Int): Stream[A] = this match {
+    case Cons(_, t) if n > 0 => t().drop(n - 1)
+    case _ => this
+  }
+
+  /*
+  It's a common Scala style to write method calls without `.` notation, as in `t() takeWhile f`.
+  */
+  def takeWhile(f: A => Boolean): Stream[A] = this match {
+    case Cons(h,t) if f(h()) => cons(h(), t() takeWhile f)
+    case _ => empty
+  }
+
+  def foldRight[B](z: => B)(f: (A, => B) => B): B = // The arrow `=>` in front of the argument type `B` means that the function `f` takes its second argument by name and may choose not to evaluate it.
+    this match {
+      case Cons(h,t) => f(h(), t().foldRight(z)(f)) // If `f` doesn't evaluate its second argument, the recursion never occurs.
+      case _ => z
+    }
+
+  def exists(p: A => Boolean): Boolean =
+    foldRight(false)((a, b) => p(a) || b) // Here `b` is the unevaluated recursive step that folds the tail of the stream. If `p(a)` returns `true`, `b` will never be evaluated and the computation terminates early.
+
+  /*
+  Since `&&` is non-strict in its second argument, this terminates the traversal as soon as a nonmatching element is found.
+  */
+  def forAll(f: A => Boolean): Boolean =
+    foldRight(true)((a,b) => f(a) && b)
+
+  def takeWhile_1(f: A => Boolean): Stream[A] =
+    foldRight(empty[A])((h,t) =>
+      if (f(h)) cons(h,t)
+      else      empty)
+
+  def headOption: Option[A] =
+    foldRight(None: Option[A])((h,_) => Some(h))
+
+  def map[B](f: A => B): Stream[B] =
+    foldRight(empty[B])((h,t) => cons(f(h), t))
+
+  def filter(f: A => Boolean): Stream[A] =
+    foldRight(empty[A])((h,t) =>
+      if (f(h)) cons(h, t)
+      else t)
+
+  def append[B>:A](s: => Stream[B]): Stream[B] =
+    foldRight(s)((h,t) => cons(h,t))
+
+  def flatMap[B](f: A => Stream[B]): Stream[B] =
+    foldRight(empty[B])((h,t) => f(h) append t)
+
+  def mapViaUnfold[B](f: A => B): Stream[B] =
+    unfold(this) {
+      case Cons(h,t) => Some((f(h()), t()))
+      case _ => None
+    }
+
+  def takeViaUnfold(n: Int): Stream[A] =
+    unfold((this,n)) {
+      case (Cons(h,t), 1) => Some((h(), (empty, 0)))
+      case (Cons(h,t), n) if n > 1 => Some((h(), (t(), n-1)))
+      case _ => None
+    }
+
+  def takeWhileViaUnfold(f: A => Boolean): Stream[A] =
+    unfold(this) {
+      case Cons(h,t) if f(h()) => Some((h(), t()))
+      case _ => None
+    }
+
+  def zipWith[B,C](s2: Stream[B])(f: (A,B) => C): Stream[C] =
+    unfold((this, s2)) {
+      case (Cons(h1,t1), Cons(h2,t2)) =>
+        Some((f(h1(), h2()), (t1(), t2())))
+      case _ => None
+    }
+
+  // special case of `zipWith`
+  def zip[B](s2: Stream[B]): Stream[(A,B)] =
+    zipWith(s2)((_,_))
+
+
+  def zipAll[B](s2: Stream[B]): Stream[(Option[A],Option[B])] =
+    zipWithAll(s2)((_,_))
+
+  def zipWithAll[B, C](s2: Stream[B])(f: (Option[A], Option[B]) => C): Stream[C] =
+    Stream.unfold((this, s2)) {
+      case (Empty, Empty) => None
+      case (Cons(h, t), Empty) => Some(f(Some(h()), Option.empty[B]) -> (t(), empty[B]))
+      case (Empty, Cons(h, t)) => Some(f(Option.empty[A], Some(h())) -> (empty[A] -> t()))
+      case (Cons(h1, t1), Cons(h2, t2)) => Some(f(Some(h1()), Some(h2())) -> (t1() -> t2()))
+    }
+
+  /*
+  `s startsWith s2` when corresponding elements of `s` and `s2` are all equal, until the point that `s2` is exhausted. If `s` is exhausted first, or we find an element that doesn't match, we terminate early. Using non-strictness, we can compose these three separate logical steps--the zipping, the termination when the second stream is exhausted, and the termination if a nonmatching element is found or the first stream is exhausted.
+  */
+  def startsWith[A](s: Stream[A]): Boolean =
+    zipAll(s).takeWhile(!_._2.isEmpty) forAll {
+      case (h,h2) => h == h2
+    }
+
+  /*
+  The last element of `tails` is always the empty `Stream`, so we handle this as a special case, by appending it to the output.
+  */
+  def tails: Stream[Stream[A]] =
+    unfold(this) {
+      case Empty => None
+      case s => Some((s, s drop 1))
+    } append Stream(empty)
+
+  def hasSubsequence[A](s: Stream[A]): Boolean =
+    tails exists (_ startsWith s)
+
+  /*
+  The function can't be implemented using `unfold`, since `unfold` generates elements of the `Stream` from left to right. It can be implemented using `foldRight` though.
+
+  The implementation is just a `foldRight` that keeps the accumulated value and the stream of intermediate results, which we `cons` onto during each iteration. When writing folds, it's common to have more state in the fold than is needed to compute the result. Here, we simply extract the accumulated list once finished.
+  */
+  def scanRight[B](z: B)(f: (A, => B) => B): Stream[B] =
+    foldRight((z, Stream(z)))((a, p0) => {
+      // p0 is passed by-name and used in by-name args in f and cons. So use lazy val to ensure only one evaluation...
+      lazy val p1 = p0
+      val b2 = f(a, p1._1)
+      (b2, cons(b2, p1._2))
+    })._2
+
+  @annotation.tailrec
+  final def find(f: A => Boolean): Option[A] = this match {
+    case Empty => None
+    case Cons(h, t) => if (f(h())) Some(h()) else t().find(f)
+  }
+}
+case object Empty extends Stream[Nothing]
+case class Cons[+A](h: () => A, t: () => Stream[A]) extends Stream[A]
+
+object Stream {
+  def cons[A](hd: => A, tl: => Stream[A]): Stream[A] = {
+    lazy val head = hd
+    lazy val tail = tl
+    Cons(() => head, () => tail)
+  }
+
+  def empty[A]: Stream[A] = Empty
+
+  def apply[A](as: A*): Stream[A] =
+    if (as.isEmpty) empty
+    else cons(as.head, apply(as.tail: _*))
+
+  val ones: Stream[Int] = Stream.cons(1, ones)
+
+  // This is more efficient than `cons(a, constant(a))` since it's just
+  // one object referencing itself.
+  def constant[A](a: A): Stream[A] = {
+    lazy val tail: Stream[A] = Cons(() => a, () => tail)
+    tail
+  }
+
+  def from(n: Int): Stream[Int] =
+    cons(n, from(n+1))
+
+  val fibs = {
+    def go(f0: Int, f1: Int): Stream[Int] =
+      cons(f0, go(f1, f0+f1))
+    go(0, 1)
+  }
+
+  def unfold[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] =
+    f(z) match {
+      case Some((h,s)) => cons(h, unfold(s)(f))
+      case None => empty
+    }
+
+  /*
+  The below two implementations use `fold` and `map` functions in the Option class to implement unfold, thereby doing away with the need to manually pattern match as in the above solution.
+   */
+  def unfoldViaFold[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] =
+    f(z).fold(empty[A])((p: (A,S)) => cons(p._1,unfold(p._2)(f)))
+
+  def unfoldViaMap[A, S](z: S)(f: S => Option[(A, S)]): Stream[A] =
+    f(z).map((p: (A,S)) => cons(p._1,unfold(p._2)(f))).getOrElse(empty[A])
+
+  /*
+  Scala provides shorter syntax when the first action of a function literal is to match on an expression.  The function passed to `unfold` in `fibsViaUnfold` is equivalent to `p => p match { case (f0,f1) => ... }`, but we avoid having to choose a name for `p`, only to pattern match on it.
+  */
+  val fibsViaUnfold =
+    unfold((0,1)) { case (f0,f1) => Some((f0,(f1,f0+f1))) }
+
+  def fromViaUnfold(n: Int) =
+    unfold(n)(n => Some((n,n+1)))
+
+  def constantViaUnfold[A](a: A) =
+    unfold(a)(_ => Some((a,a)))
+
+  // could also of course be implemented as constant(1)
+  val onesViaUnfold = unfold(1)(_ => Some((1,1)))
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala b/src/main/scala/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala
new file mode 100644
index 0000000..f9e92fe
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/localeffects/LocalEffects.scala
@@ -0,0 +1,193 @@
+package fpinscala.localeffects
+
+import fpinscala.monads._
+
+object Mutable {
+  def quicksort(xs: List[Int]): List[Int] = if (xs.isEmpty) xs else {
+    val arr = xs.toArray
+    def swap(x: Int, y: Int) = {
+      val tmp = arr(x)
+      arr(x) = arr(y)
+      arr(y) = tmp
+    }
+    def partition(l: Int, r: Int, pivot: Int) = {
+      val pivotVal = arr(pivot)
+      swap(pivot, r)
+      var j = l
+      for (i <- l until r) if (arr(i) < pivotVal) {
+        swap(i, j)
+        j += 1
+      }
+      swap(j, r)
+      j
+    }
+    def qs(l: Int, r: Int): Unit = if (l < r) {
+      val pi = partition(l, r, l + (r - l) / 2)
+      qs(l, pi - 1)
+      qs(pi + 1, r)
+    }
+    qs(0, arr.length - 1)
+    arr.toList
+  }
+}
+
+sealed trait ST[S,A] { self =>
+  protected def run(s: S): (A,S)
+  def map[B](f: A => B): ST[S,B] = new ST[S,B] {
+    def run(s: S) = {
+      val (a, s1) = self.run(s)
+      (f(a), s1)
+    }
+  }
+  def flatMap[B](f: A => ST[S,B]): ST[S,B] = new ST[S,B] {
+    def run(s: S) = {
+      val (a, s1) = self.run(s)
+      f(a).run(s1)
+    }
+  }
+}
+
+object ST {
+  def apply[S,A](a: => A) = {
+    lazy val memo = a
+    new ST[S,A] {
+      def run(s: S) = (memo, s)
+    }
+  }
+  def runST[A](st: RunnableST[A]): A =
+    st[Unit].run(())._1
+}
+
+sealed trait STRef[S,A] {
+  protected var cell: A
+  def read: ST[S,A] = ST(cell)
+  def write(a: => A): ST[S,Unit] = new ST[S,Unit] {
+    def run(s: S) = {
+      cell = a
+      ((), s)
+    }
+  }
+}
+
+object STRef {
+  def apply[S,A](a: A): ST[S, STRef[S,A]] = ST(new STRef[S,A] {
+    var cell = a
+  })
+}
+
+trait RunnableST[A] {
+  def apply[S]: ST[S,A]
+}
+
+// Scala requires an implicit Manifest for constructing arrays.
+sealed abstract class STArray[S,A](implicit manifest: Manifest[A]) {
+  protected def value: Array[A]
+  def size: ST[S,Int] = ST(value.size)
+
+  // Write a value at the give index of the array
+  def write(i: Int, a: A): ST[S,Unit] = new ST[S,Unit] {
+    def run(s: S) = {
+      value(i) = a
+      ((), s)
+    }
+  }
+
+  // Read the value at the given index of the array
+  def read(i: Int): ST[S,A] = ST(value(i))
+
+  // Turn the array into an immutable list
+  def freeze: ST[S,List[A]] = ST(value.toList)
+
+  def fill(xs: Map[Int,A]): ST[S,Unit] =
+    xs.foldRight(ST[S,Unit](())) {
+      case ((k, v), st) => st flatMap (_ => write(k, v))
+    }
+
+  def swap(i: Int, j: Int): ST[S,Unit] = for {
+    x <- read(i)
+    y <- read(j)
+    _ <- write(i, y)
+    _ <- write(j, x)
+  } yield ()
+}
+
+object STArray {
+  // Construct an array of the given size filled with the value v
+  def apply[S,A:Manifest](sz: Int, v: A): ST[S, STArray[S,A]] =
+    ST(new STArray[S,A] {
+      lazy val value = Array.fill(sz)(v)
+    })
+
+  def fromList[S,A:Manifest](xs: List[A]): ST[S, STArray[S,A]] =
+    ST(new STArray[S,A] {
+      lazy val value = xs.toArray
+    })
+}
+
+object Immutable {
+  def noop[S] = ST[S,Unit](())
+
+  def partition[S](a: STArray[S,Int], l: Int, r: Int, pivot: Int): ST[S,Int] = for {
+    vp <- a.read(pivot)
+    _ <- a.swap(pivot, r)
+    j <- STRef(l)
+    _ <- (l until r).foldLeft(noop[S])((s, i) => for {
+      _ <- s
+      vi <- a.read(i)
+      _  <- if (vi < vp) (for {
+        vj <- j.read
+        _  <- a.swap(i, vj)
+        _  <- j.write(vj + 1)
+      } yield ()) else noop[S]
+    } yield ())
+    x <- j.read
+    _ <- a.swap(x, r)
+  } yield x
+
+  def qs[S](a: STArray[S,Int], l: Int, r: Int): ST[S, Unit] = if (l < r) for {
+    pi <- partition(a, l, r, l + (r - l) / 2)
+    _ <- qs(a, l, pi - 1)
+    _ <- qs(a, pi + 1, r)
+  } yield () else noop[S]
+
+  def quicksort(xs: List[Int]): List[Int] =
+    if (xs.isEmpty) xs else ST.runST(new RunnableST[List[Int]] {
+      def apply[S] = for {
+        arr    <- STArray.fromList(xs)
+        size   <- arr.size
+        _      <- qs(arr, 0, size - 1)
+        sorted <- arr.freeze
+      } yield sorted
+  })
+}
+
+import scala.collection.mutable.HashMap
+
+sealed trait STMap[S,K,V] {
+  protected def table: HashMap[K,V]
+
+  def size: ST[S,Int] = ST(table.size)
+
+  // Get the value under a key
+  def apply(k: K): ST[S,V] = ST(table(k))
+
+  // Get the value under a key, or None if the key does not exist
+  def get(k: K): ST[S, Option[V]] = ST(table.get(k))
+
+  // Add a value under a key
+  def +=(kv: (K, V)): ST[S,Unit] = ST(table += kv)
+
+  // Remove a key
+  def -=(k: K): ST[S,Unit] = ST(table -= k)
+}
+
+object STMap {
+  def empty[S,K,V]: ST[S, STMap[S,K,V]] = ST(new STMap[S,K,V] {
+    val table = HashMap.empty[K,V]
+  })
+
+  def fromMap[S,K,V](m: Map[K,V]): ST[S, STMap[S,K,V]] = ST(new STMap[S,K,V] {
+    val table = (HashMap.newBuilder[K,V] ++= m).result
+  })
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/monads/Monad.scala b/src/main/scala/answers/src/main/scala/fpinscala/monads/Monad.scala
new file mode 100644
index 0000000..f6e34cb
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/monads/Monad.scala
@@ -0,0 +1,189 @@
+package fpinscala
+package monads
+
+import parsing._
+import testing._
+import parallelism._
+import state._
+import parallelism.Par._
+import language.higherKinds
+
+
+trait Functor[F[_]] {
+  def map[A,B](fa: F[A])(f: A => B): F[B]
+
+  def distribute[A,B](fab: F[(A, B)]): (F[A], F[B]) =
+    (map(fab)(_._1), map(fab)(_._2))
+
+  def codistribute[A,B](e: Either[F[A], F[B]]): F[Either[A, B]] = e match {
+    case Left(fa) => map(fa)(Left(_))
+    case Right(fb) => map(fb)(Right(_))
+  }
+}
+
+object Functor {
+  val listFunctor = new Functor[List] {
+    def map[A,B](as: List[A])(f: A => B): List[B] = as map f
+  }
+}
+
+trait Monad[F[_]] extends Functor[F] {
+  def unit[A](a: => A): F[A]
+
+  def flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] =
+    join(map(ma)(f))
+
+  def map[A,B](ma: F[A])(f: A => B): F[B] =
+    flatMap(ma)(a => unit(f(a)))
+  def map2[A,B,C](ma: F[A], mb: F[B])(f: (A, B) => C): F[C] =
+    flatMap(ma)(a => map(mb)(b => f(a, b)))
+
+  def sequence[A](lma: List[F[A]]): F[List[A]] =
+    lma.foldRight(unit(List[A]()))((ma, mla) => map2(ma, mla)(_ :: _))
+
+  def traverse[A,B](la: List[A])(f: A => F[B]): F[List[B]] =
+    la.foldRight(unit(List[B]()))((a, mlb) => map2(f(a), mlb)(_ :: _))
+
+  // For `List`, the `replicateM` function will generate a list of lists.
+  // It will contain all the lists of length `n` with elements selected from the
+  // input list.
+  // For `Option`, it will generate either `Some` or `None` based on whether the
+  // input is `Some` or `None`. The `Some` case will contain a list of length `n`
+  // that repeats the element in the input `Option`.
+  // The general meaning of `replicateM` is described very well by the
+  // implementation `sequence(List.fill(n)(ma))`. It repeats the `ma` monadic value
+  // `n` times and gathers the results in a single value, where the monad `M`
+  // determines how values are actually combined.
+
+  // Recursive version:
+  def _replicateM[A](n: Int, ma: F[A]): F[List[A]] =
+    if (n <= 0) unit(List[A]()) else map2(ma, _replicateM(n - 1, ma))(_ :: _)
+
+  // Using `sequence` and the `List.fill` function of the standard library:
+  def replicateM[A](n: Int, ma: F[A]): F[List[A]] =
+    sequence(List.fill(n)(ma))
+
+
+  def compose[A,B,C](f: A => F[B], g: B => F[C]): A => F[C] =
+    a => flatMap(f(a))(g)
+
+  def _flatMap[A,B](ma: F[A])(f: A => F[B]): F[B] =
+    compose((_:Unit) => ma, f)(())
+
+  def join[A](mma: F[F[A]]): F[A] = flatMap(mma)(ma => ma)
+
+  def filterM[A](ms: List[A])(f: A => F[Boolean]): F[List[A]] =
+    ms.foldRight(unit(List[A]()))((x,y) =>
+      compose(f, (b: Boolean) => if (b) map2(unit(x),y)(_ :: _) else y)(x))
+}
+
+case class Reader[R, A](run: R => A)
+
+object Monad {
+  val genMonad = new Monad[Gen] {
+    def unit[A](a: => A): Gen[A] = Gen.unit(a)
+    override def flatMap[A,B](ma: Gen[A])(f: A => Gen[B]): Gen[B] =
+      ma flatMap f
+  }
+
+  val parMonad = new Monad[Par] {
+    def unit[A](a: => A) = Par.unit(a)
+    override def flatMap[A,B](ma: Par[A])(f: A => Par[B]) = Par.flatMap(ma)(f)
+  }
+
+  def parserMonad[P[+_]](p: Parsers[P]) = new Monad[P] {
+    def unit[A](a: => A) = p.succeed(a)
+    override def flatMap[A,B](ma: P[A])(f: A => P[B]) = p.flatMap(ma)(f)
+  }
+
+  val optionMonad = new Monad[Option] {
+    def unit[A](a: => A) = Some(a)
+    override def flatMap[A,B](ma: Option[A])(f: A => Option[B]) = ma flatMap f
+  }
+
+  val streamMonad = new Monad[Stream] {
+    def unit[A](a: => A) = Stream(a)
+    override def flatMap[A,B](ma: Stream[A])(f: A => Stream[B]) = ma flatMap f
+  }
+
+  val listMonad = new Monad[List] {
+    def unit[A](a: => A) = List(a)
+    override def flatMap[A,B](ma: List[A])(f: A => List[B]) = ma flatMap f
+  }
+
+  // Since `State` is a binary type constructor, we need to partially apply it
+  // with the `S` type argument. Thus, it is not just one monad, but an entire
+  // family of monads, one for each type `S`. One solution is to create a class
+  // `StateMonads` that accepts the `S` type argument and then has a _type member_
+  // for the fully applied `State[S, A]` type inside:
+  class StateMonads[S] {
+    type StateS[A] = State[S, A]
+
+    // We can then declare the monad for the `StateS` type constructor:
+    val monad = new Monad[StateS] {
+      def unit[A](a: => A): State[S, A] = State(s => (a, s))
+      override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
+        st flatMap f
+    }
+  }
+
+  // But we don't have to create a full class like `StateMonads`. We can create
+  // an anonymous class inline, inside parentheses, and project out its type member,
+  // `lambda`:
+  def stateMonad[S] = new Monad[({type lambda[x] = State[S, x]})#lambda] {
+    def unit[A](a: => A): State[S, A] = State(s => (a, s))
+    override def flatMap[A,B](st: State[S, A])(f: A => State[S, B]): State[S, B] =
+      st flatMap f
+  }
+
+  val idMonad = new Monad[Id] {
+    def unit[A](a: => A) = Id(a)
+    override def flatMap[A,B](ida: Id[A])(f: A => Id[B]): Id[B] = ida flatMap f
+  }
+
+  def getState[S]: State[S,S] = State(s => (s,s))
+  def setState[S](s: S): State[S,Unit] = State(_ => ((),s))
+
+  val F = stateMonad[Int]
+
+  def zipWithIndex[A](as: List[A]): List[(Int,A)] =
+    as.foldLeft(F.unit(List[(Int, A)]()))((acc,a) => for {
+      xs <- acc
+      n  <- getState
+      _  <- setState(n + 1)
+    } yield (n, a) :: xs).run(0)._1.reverse
+
+  // The action of Reader's `flatMap` is to pass the `r` argument along to both the
+  // outer Reader and also to the result of `f`, the inner Reader. Similar to how
+  // `State` passes along a state, except that in `Reader` the "state" is read-only.
+
+  // The meaning of `sequence` here is that if you have a list of functions, you can
+  // turn it into a function that takes one argument and passes it to all the functions
+  // in the list, returning a list of the results.
+
+  // The meaning of `join` is simply to pass the same value as both arguments to a
+  // binary function.
+
+  // The meaning of `replicateM` is to apply the same function a number of times to
+  // the same argument, returning a list of the results. Note that if this function
+  // is _pure_, (which it should be), this can be exploited by only applying the
+  // function once and replicating the result instead of calling the function many times.
+  // This means the Reader monad can override replicateM to provide a very efficient
+  // implementation.
+
+  def readerMonad[R] = new Monad[({type f[x] = Reader[R,x]})#f] {
+    def unit[A](a: => A): Reader[R, A] = Reader(_ => a)
+    override def flatMap[A,B](st: Reader[R, A])(f: A => Reader[R, B]): Reader[R, B] =
+      Reader(r => f(st.run(r)).run(r))
+  }
+}
+
+case class Id[A](value: A) {
+  def map[B](f: A => B): Id[B] = Id(f(value))
+  def flatMap[B](f: A => Id[B]): Id[B] = f(value)
+}
+
+object Reader {
+  def ask[R]: Reader[R, R] = Reader(r => r)
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/monoids/Monoid.scala b/src/main/scala/answers/src/main/scala/fpinscala/monoids/Monoid.scala
new file mode 100644
index 0000000..66721e2
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/monoids/Monoid.scala
@@ -0,0 +1,301 @@
+package fpinscala.monoids
+
+import fpinscala.parallelism.Nonblocking._
+import fpinscala.parallelism.Nonblocking.Par.toParOps // infix syntax for `Par.map`, `Par.flatMap`, etc
+import language.higherKinds
+
+trait Monoid[A] {
+  def op(a1: A, a2: A): A
+  def zero: A
+}
+
+object Monoid {
+
+  val stringMonoid = new Monoid[String] {
+    def op(a1: String, a2: String) = a1 + a2
+    val zero = ""
+  }
+
+  def listMonoid[A] = new Monoid[List[A]] {
+    def op(a1: List[A], a2: List[A]) = a1 ++ a2
+    val zero = Nil
+  }
+
+  val intAddition: Monoid[Int] = new Monoid[Int] {
+    def op(x: Int, y: Int) = x + y
+    val zero = 0
+  }
+
+  val intMultiplication: Monoid[Int] = new Monoid[Int] {
+    def op(x: Int, y: Int) = x * y
+    val zero = 1
+  }
+
+  val booleanOr: Monoid[Boolean] = new Monoid[Boolean] {
+    def op(x: Boolean, y: Boolean) = x || y
+    val zero = false
+  }
+
+  val booleanAnd: Monoid[Boolean] = new Monoid[Boolean] {
+    def op(x: Boolean, y: Boolean) = x && y
+    val zero = true
+  }
+
+  // Notice that we have a choice in how we implement `op`.
+  // We can compose the options in either order. Both of those implementations
+  // satisfy the monoid laws, but they are not equivalent.
+  // This is true in general--that is, every monoid has a _dual_ where the
+  // `op` combines things in the opposite order. Monoids like `booleanOr` and
+  // `intAddition` are equivalent to their duals because their `op` is commutative
+  // as well as associative.
+  def optionMonoid[A]: Monoid[Option[A]] = new Monoid[Option[A]] {
+    def op(x: Option[A], y: Option[A]) = x orElse y
+    val zero = None
+  }
+
+  // We can get the dual of any monoid just by flipping the `op`.
+  def dual[A](m: Monoid[A]): Monoid[A] = new Monoid[A] {
+    def op(x: A, y: A): A = m.op(y, x)
+    val zero = m.zero
+  }
+
+  // Now we can have both monoids on hand
+  def firstOptionMonoid[A]: Monoid[Option[A]] = optionMonoid[A]
+  def lastOptionMonoid[A]: Monoid[Option[A]] = dual(firstOptionMonoid)
+
+  // There is a choice of implementation here as well.
+  // Do we implement it as `f compose g` or `f andThen g`? We have to pick one.
+  def endoMonoid[A]: Monoid[A => A] = new Monoid[A => A] {
+    def op(f: A => A, g: A => A) = f compose g
+    val zero = (a: A) => a
+  }
+
+  import fpinscala.testing._
+  import Prop._
+
+  def monoidLaws[A](m: Monoid[A], gen: Gen[A]): Prop =
+    // Associativity
+    forAll(for {
+      x <- gen
+      y <- gen
+      z <- gen
+    } yield (x, y, z))(p =>
+      m.op(p._1, m.op(p._2, p._3)) == m.op(m.op(p._1, p._2), p._3)) &&
+    // Identity
+    forAll(gen)((a: A) =>
+      m.op(a, m.zero) == a && m.op(m.zero, a) == a)
+
+  def concatenate[A](as: List[A], m: Monoid[A]): A =
+    as.foldLeft(m.zero)(m.op)
+
+  // Notice that this function does not require the use of `map` at all.
+  // All we need is `foldLeft`.
+  def foldMap[A, B](as: List[A], m: Monoid[B])(f: A => B): B =
+    as.foldLeft(m.zero)((b, a) => m.op(b, f(a)))
+
+  // The function type `(A, B) => B`, when curried, is `A => (B => B)`.
+  // And of course, `B => B` is a monoid for any `B` (via function composition).
+  def foldRight[A, B](as: List[A])(z: B)(f: (A, B) => B): B =
+    foldMap(as, endoMonoid[B])(f.curried)(z)
+
+  // Folding to the left is the same except we flip the arguments to
+  // the function `f` to put the `B` on the correct side.
+  // Then we have to also "flip" the monoid so that it operates from left to right.
+  def foldLeft[A, B](as: List[A])(z: B)(f: (B, A) => B): B =
+    foldMap(as, dual(endoMonoid[B]))(a => b => f(b, a))(z)
+
+  def foldMapV[A, B](as: IndexedSeq[A], m: Monoid[B])(f: A => B): B =
+    if (as.length == 0)
+      m.zero
+    else if (as.length == 1)
+      f(as(0))
+    else {
+      val (l, r) = as.splitAt(as.length / 2)
+      m.op(foldMapV(l, m)(f), foldMapV(r, m)(f))
+    }
+
+  // This implementation detects only ascending order,
+  // but you can write a monoid that detects both ascending and descending
+  // order if you like.
+  def ordered(ints: IndexedSeq[Int]): Boolean = {
+    // Our monoid tracks the minimum and maximum element seen so far
+    // as well as whether the elements are so far ordered.
+    val mon = new Monoid[Option[(Int, Int, Boolean)]] {
+      def op(o1: Option[(Int, Int, Boolean)], o2: Option[(Int, Int, Boolean)]) =
+        (o1, o2) match {
+          // The ranges should not overlap if the sequence is ordered.
+          case (Some((x1, y1, p)), Some((x2, y2, q))) =>
+            Some((x1 min x2, y1 max y2, p && q && y1 <= x2))
+          case (x, None) => x
+          case (None, x) => x
+        }
+      val zero = None
+    }
+    // The empty sequence is ordered, and each element by itself is ordered.
+    foldMapV(ints, mon)(i => Some((i, i, true))).map(_._3).getOrElse(true)
+  }
+
+  // This ability to 'lift' a monoid any monoid to operate within
+  // some context (here `Par`) is something we'll discuss more in
+  // chapters 11 & 12
+  def par[A](m: Monoid[A]): Monoid[Par[A]] = new Monoid[Par[A]] {
+    def zero = Par.unit(m.zero)
+    def op(a: Par[A], b: Par[A]) = a.map2(b)(m.op)
+  }
+
+  // we perform the mapping and the reducing both in parallel
+  def parFoldMap[A,B](v: IndexedSeq[A], m: Monoid[B])(f: A => B): Par[B] =
+    Par.parMap(v)(f).flatMap { bs =>
+      foldMapV(bs, par(m))(b => Par.lazyUnit(b))
+    }
+
+  sealed trait WC
+  case class Stub(chars: String) extends WC
+  case class Part(lStub: String, words: Int, rStub: String) extends WC
+
+  val wcMonoid: Monoid[WC] = new Monoid[WC] {
+    // The empty result, where we haven't seen any characters yet.
+    val zero = Stub("")
+
+    def op(a: WC, b: WC) = (a, b) match {
+      case (Stub(c), Stub(d)) => Stub(c + d)
+      case (Stub(c), Part(l, w, r)) => Part(c + l, w, r)
+      case (Part(l, w, r), Stub(c)) => Part(l, w, r + c)
+      case (Part(l1, w1, r1), Part(l2, w2, r2)) =>
+        Part(l1, w1 + (if ((r1 + l2).isEmpty) 0 else 1) + w2, r2)
+    }
+  }
+
+  def count(s: String): Int = {
+    // A single character's count. Whitespace does not count,
+    // and non-whitespace starts a new Stub.
+    def wc(c: Char): WC =
+      if (c.isWhitespace)
+        Part("", 0, "")
+      else
+        Stub(c.toString)
+    // `unstub(s)` is 0 if `s` is empty, otherwise 1.
+    def unstub(s: String) = s.length min 1
+    foldMapV(s.toIndexedSeq, wcMonoid)(wc) match {
+      case Stub(s) => unstub(s)
+      case Part(l, w, r) => unstub(l) + w + unstub(r)
+    }
+  }
+
+  def productMonoid[A,B](A: Monoid[A], B: Monoid[B]): Monoid[(A, B)] =
+    new Monoid[(A, B)] {
+      def op(x: (A, B), y: (A, B)) =
+        (A.op(x._1, y._1), B.op(x._2, y._2))
+      val zero = (A.zero, B.zero)
+    }
+
+  def functionMonoid[A,B](B: Monoid[B]): Monoid[A => B] =
+    new Monoid[A => B] {
+      def op(f: A => B, g: A => B) = a => B.op(f(a), g(a))
+      val zero: A => B = a => B.zero
+    }
+
+  def mapMergeMonoid[K,V](V: Monoid[V]): Monoid[Map[K, V]] =
+    new Monoid[Map[K, V]] {
+      def zero = Map[K,V]()
+      def op(a: Map[K, V], b: Map[K, V]) =
+        (a.keySet ++ b.keySet).foldLeft(zero) { (acc,k) =>
+          acc.updated(k, V.op(a.getOrElse(k, V.zero),
+                              b.getOrElse(k, V.zero)))
+        }
+    }
+
+
+  def bag[A](as: IndexedSeq[A]): Map[A, Int] =
+    foldMapV(as, mapMergeMonoid[A, Int](intAddition))((a: A) => Map(a -> 1))
+
+}
+
+trait Foldable[F[_]] {
+  import Monoid._
+
+  def foldRight[A,B](as: F[A])(z: B)(f: (A, B) => B): B =
+    foldMap(as)(f.curried)(endoMonoid[B])(z)
+
+  def foldLeft[A,B](as: F[A])(z: B)(f: (B, A) => B): B =
+    foldMap(as)(a => (b: B) => f(b, a))(dual(endoMonoid[B]))(z)
+
+  def foldMap[A, B](as: F[A])(f: A => B)(mb: Monoid[B]): B =
+    foldRight(as)(mb.zero)((a, b) => mb.op(f(a), b))
+
+  def concatenate[A](as: F[A])(m: Monoid[A]): A =
+    foldLeft(as)(m.zero)(m.op)
+
+  def toList[A](as: F[A]): List[A] =
+    foldRight(as)(List[A]())(_ :: _)
+}
+
+object ListFoldable extends Foldable[List] {
+  override def foldRight[A, B](as: List[A])(z: B)(f: (A, B) => B) =
+    as.foldRight(z)(f)
+  override def foldLeft[A, B](as: List[A])(z: B)(f: (B, A) => B) =
+    as.foldLeft(z)(f)
+  override def foldMap[A, B](as: List[A])(f: A => B)(mb: Monoid[B]): B =
+    foldLeft(as)(mb.zero)((b, a) => mb.op(b, f(a)))
+  override def toList[A](as: List[A]): List[A] = as
+}
+
+object IndexedSeqFoldable extends Foldable[IndexedSeq] {
+  import Monoid._
+  override def foldRight[A, B](as: IndexedSeq[A])(z: B)(f: (A, B) => B) =
+    as.foldRight(z)(f)
+  override def foldLeft[A, B](as: IndexedSeq[A])(z: B)(f: (B, A) => B) =
+    as.foldLeft(z)(f)
+  override def foldMap[A, B](as: IndexedSeq[A])(f: A => B)(mb: Monoid[B]): B =
+    foldMapV(as, mb)(f)
+}
+
+object StreamFoldable extends Foldable[Stream] {
+  override def foldRight[A, B](as: Stream[A])(z: B)(f: (A, B) => B) =
+    as.foldRight(z)(f)
+  override def foldLeft[A, B](as: Stream[A])(z: B)(f: (B, A) => B) =
+    as.foldLeft(z)(f)
+}
+
+sealed trait Tree[+A]
+case class Leaf[A](value: A) extends Tree[A]
+case class Branch[A](left: Tree[A], right: Tree[A]) extends Tree[A]
+
+object TreeFoldable extends Foldable[Tree] {
+  override def foldMap[A, B](as: Tree[A])(f: A => B)(mb: Monoid[B]): B = as match {
+    case Leaf(a) => f(a)
+    case Branch(l, r) => mb.op(foldMap(l)(f)(mb), foldMap(r)(f)(mb))
+  }
+  override def foldLeft[A, B](as: Tree[A])(z: B)(f: (B, A) => B) = as match {
+    case Leaf(a) => f(z, a)
+    case Branch(l, r) => foldLeft(r)(foldLeft(l)(z)(f))(f)
+  }
+  override def foldRight[A, B](as: Tree[A])(z: B)(f: (A, B) => B) = as match {
+    case Leaf(a) => f(a, z)
+    case Branch(l, r) => foldRight(l)(foldRight(r)(z)(f))(f)
+  }
+}
+
+// Notice that in `TreeFoldable.foldMap`, we don't actually use the `zero`
+// from the `Monoid`. This is because there is no empty tree.
+// This suggests that there might be a class of types that are foldable
+// with something "smaller" than a monoid, consisting only of an
+// associative `op`. That kind of object (a monoid without a `zero`) is
+// called a semigroup. `Tree` itself is not a monoid, but it is a semigroup.
+
+object OptionFoldable extends Foldable[Option] {
+  override def foldMap[A, B](as: Option[A])(f: A => B)(mb: Monoid[B]): B =
+    as match {
+      case None => mb.zero
+      case Some(a) => f(a)
+    }
+  override def foldLeft[A, B](as: Option[A])(z: B)(f: (B, A) => B) = as match {
+    case None => z
+    case Some(a) => f(z, a)
+  }
+  override def foldRight[A, B](as: Option[A])(z: B)(f: (A, B) => B) = as match {
+    case None => z
+    case Some(a) => f(a, z)
+  }
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Actor.scala b/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Actor.scala
new file mode 100644
index 0000000..3271b23
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Actor.scala
@@ -0,0 +1,137 @@
+package fpinscala.parallelism
+
+import java.util.concurrent.atomic.{AtomicInteger, AtomicReference}
+import java.util.concurrent.{Callable,ExecutorService}
+import annotation.tailrec
+
+/*
+ * Implementation is taken from `scalaz` library, with only minor changes. See:
+ *
+ * https://github.com/scalaz/scalaz/blob/scalaz-seven/concurrent/src/main/scala/scalaz/concurrent/Actor.scala
+ *
+ * This code is copyright Andriy Plokhotnyuk, Runar Bjarnason, and other contributors,
+ * and is licensed using 3-clause BSD, see LICENSE file at:
+ *
+ * https://github.com/scalaz/scalaz/blob/scalaz-seven/etc/LICENCE
+ */
+
+/**
+ * Processes messages of type `A`, one at a time. Messages are submitted to
+ * the actor with the method `!`. Processing is typically performed asynchronously,
+ * this is controlled by the provided `strategy`.
+ *
+ * Memory consistency guarantee: when each message is processed by the `handler`, any memory that it
+ * mutates is guaranteed to be visible by the `handler` when it processes the next message, even if
+ * the `strategy` runs the invocations of `handler` on separate threads. This is achieved because
+ * the `Actor` reads a volatile memory location before entering its event loop, and writes to the same
+ * location before suspending.
+ *
+ * Implementation based on non-intrusive MPSC node-based queue, described by Dmitriy Vyukov:
+ * [[http://www.1024cores.net/home/lock-free-algorithms/queues/non-intrusive-mpsc-node-based-queue]]
+ *
+ * @see scalaz.concurrent.Promise for a use case.
+ *
+ * @param handler  The message handler
+ * @param onError  Exception handler, called if the message handler throws any `Throwable`.
+ * @param strategy Execution strategy, for example, a strategy that is backed by an `ExecutorService`
+ * @tparam A       The type of messages accepted by this actor.
+ */
+final class Actor[A](strategy: Strategy)(handler: A => Unit, onError: Throwable => Unit = throw(_)) {
+  self =>
+
+  private val tail = new AtomicReference(new Node[A]())
+  private val suspended = new AtomicInteger(1)
+  private val head = new AtomicReference(tail.get)
+
+  /** Alias for `apply` */
+  def !(a: A) {
+    val n = new Node(a)
+    head.getAndSet(n).lazySet(n)
+    trySchedule()
+  }
+
+  /** Pass the message `a` to the mailbox of this actor */
+  def apply(a: A) {
+    this ! a
+  }
+
+  def contramap[B](f: B => A): Actor[B] =
+    new Actor[B](strategy)((b: B) => (this ! f(b)), onError)
+
+  private def trySchedule() {
+    if (suspended.compareAndSet(1, 0)) schedule()
+  }
+
+  private def schedule() {
+    strategy(act())
+  }
+
+  private def act() {
+    val t = tail.get
+    val n = batchHandle(t, 1024)
+    if (n ne t) {
+      n.a = null.asInstanceOf[A]
+      tail.lazySet(n)
+      schedule()
+    } else {
+      suspended.set(1)
+      if (n.get ne null) trySchedule()
+    }
+  }
+
+  @tailrec
+  private def batchHandle(t: Node[A], i: Int): Node[A] = {
+    val n = t.get
+    if (n ne null) {
+      try {
+        handler(n.a)
+      } catch {
+        case ex: Throwable => onError(ex)
+      }
+      if (i > 0) batchHandle(n, i - 1) else n
+    } else t
+  }
+}
+
+private class Node[A](var a: A = null.asInstanceOf[A]) extends AtomicReference[Node[A]]
+
+object Actor {
+
+  /** Create an `Actor` backed by the given `ExecutorService`. */
+  def apply[A](es: ExecutorService)(handler: A => Unit, onError: Throwable => Unit = throw(_)): Actor[A] =
+    new Actor(Strategy.fromExecutorService(es))(handler, onError)
+}
+
+/**
+ * Provides a function for evaluating expressions, possibly asynchronously.
+ * The `apply` function should typically begin evaluating its argument
+ * immediately. The returned thunk can be used to block until the resulting `A`
+ * is available.
+ */
+trait Strategy {
+  def apply[A](a: => A): () => A
+}
+
+object Strategy {
+
+  /**
+   * We can create a `Strategy` from any `ExecutorService`. It's a little more
+   * convenient than submitting `Callable` objects directly.
+   */
+  def fromExecutorService(es: ExecutorService): Strategy = new Strategy {
+    def apply[A](a: => A): () => A = {
+      val f = es.submit { new Callable[A] { def call = a} }
+      () => f.get
+    }
+  }
+
+  /**
+   * A `Strategy` which begins executing its argument immediately in the calling thread.
+   */
+  def sequential: Strategy = new Strategy {
+    def apply[A](a: => A): () => A = {
+      val r = a
+      () => r
+    }
+  }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala b/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala
new file mode 100644
index 0000000..dca2377
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Nonblocking.scala
@@ -0,0 +1,197 @@
+package fpinscala.parallelism
+
+import java.util.concurrent.{Callable, CountDownLatch, ExecutorService}
+import java.util.concurrent.atomic.AtomicReference
+import language.implicitConversions
+
+object Nonblocking {
+
+  trait Future[+A] {
+    private[parallelism] def apply(k: A => Unit): Unit
+  }
+
+  type Par[+A] = ExecutorService => Future[A]
+
+  object Par {
+
+    def run[A](es: ExecutorService)(p: Par[A]): A = {
+      val ref = new java.util.concurrent.atomic.AtomicReference[A] // A mutable, threadsafe reference, to use for storing the result
+      val latch = new CountDownLatch(1) // A latch which, when decremented, implies that `ref` has the result
+      p(es) { a => ref.set(a); latch.countDown } // Asynchronously set the result, and decrement the latch
+      latch.await // Block until the `latch.countDown` is invoked asynchronously
+      ref.get // Once we've passed the latch, we know `ref` has been set, and return its value
+    }
+
+    def unit[A](a: A): Par[A] =
+      es => new Future[A] {
+        def apply(cb: A => Unit): Unit =
+          cb(a)
+      }
+
+    /** A non-strict version of `unit` */
+    def delay[A](a: => A): Par[A] =
+      es => new Future[A] {
+        def apply(cb: A => Unit): Unit =
+          cb(a)
+      }
+
+    def fork[A](a: => Par[A]): Par[A] =
+      es => new Future[A] {
+        def apply(cb: A => Unit): Unit =
+          eval(es)(a(es)(cb))
+      }
+
+    /**
+     * Helper function for constructing `Par` values out of calls to non-blocking continuation-passing-style APIs.
+     * This will come in handy in Chapter 13.
+     */
+    def async[A](f: (A => Unit) => Unit): Par[A] = es => new Future[A] {
+      def apply(k: A => Unit) = f(k)
+    }
+
+    /**
+     * Helper function, for evaluating an action
+     * asynchronously, using the given `ExecutorService`.
+     */
+    def eval(es: ExecutorService)(r: => Unit): Unit =
+      es.submit(new Callable[Unit] { def call = r })
+
+    def map2[A,B,C](p: Par[A], p2: Par[B])(f: (A,B) => C): Par[C] =
+      es => new Future[C] {
+        def apply(cb: C => Unit): Unit = {
+          var ar: Option[A] = None
+          var br: Option[B] = None
+          // this implementation is a little too liberal in forking of threads -
+          // it forks a new logical thread for the actor and for stack-safety,
+          // forks evaluation of the callback `cb`
+          val combiner = Actor[Either[A,B]](es) {
+            case Left(a) =>
+              if (br.isDefined) eval(es)(cb(f(a,br.get)))
+              else ar = Some(a)
+            case Right(b) =>
+              if (ar.isDefined) eval(es)(cb(f(ar.get,b)))
+              else br = Some(b)
+          }
+          p(es)(a => combiner ! Left(a))
+          p2(es)(b => combiner ! Right(b))
+        }
+      }
+
+    // specialized version of `map`
+    def map[A,B](p: Par[A])(f: A => B): Par[B] =
+      es => new Future[B] {
+        def apply(cb: B => Unit): Unit =
+          p(es)(a => eval(es) { cb(f(a)) })
+      }
+
+    def lazyUnit[A](a: => A): Par[A] =
+      fork(unit(a))
+
+    def asyncF[A,B](f: A => B): A => Par[B] =
+      a => lazyUnit(f(a))
+
+    def sequenceRight[A](as: List[Par[A]]): Par[List[A]] =
+      as match {
+        case Nil => unit(Nil)
+        case h :: t => map2(h, fork(sequence(t)))(_ :: _)
+      }
+
+    def sequenceBalanced[A](as: IndexedSeq[Par[A]]): Par[IndexedSeq[A]] = fork {
+      if (as.isEmpty) unit(Vector())
+      else if (as.length == 1) map(as.head)(a => Vector(a))
+      else {
+        val (l,r) = as.splitAt(as.length/2)
+        map2(sequenceBalanced(l), sequenceBalanced(r))(_ ++ _)
+      }
+    }
+
+    def sequence[A](as: List[Par[A]]): Par[List[A]] =
+      map(sequenceBalanced(as.toIndexedSeq))(_.toList)
+
+    def parMap[A,B](as: List[A])(f: A => B): Par[List[B]] =
+      sequence(as.map(asyncF(f)))
+
+    def parMap[A,B](as: IndexedSeq[A])(f: A => B): Par[IndexedSeq[B]] =
+      sequenceBalanced(as.map(asyncF(f)))
+
+    // exercise answers
+
+    /*
+     * We can implement `choice` as a new primitive.
+     *
+     * `p(es)(result => ...)` for some `ExecutorService`, `es`, and
+     * some `Par`, `p`, is the idiom for running `p`, and registering
+     * a callback to be invoked when its result is available. The
+     * result will be bound to `result` in the function passed to
+     * `p(es)`.
+     *
+     * If you find this code difficult to follow, you may want to
+     * write down the type of each subexpression and follow the types
+     * through the implementation. What is the type of `p(es)`? What
+     * about `t(es)`? What about `t(es)(cb)`?
+     */
+    def choice[A](p: Par[Boolean])(t: Par[A], f: Par[A]): Par[A] =
+      es => new Future[A] {
+        def apply(cb: A => Unit): Unit =
+          p(es) { b =>
+            if (b) eval(es) { t(es)(cb) }
+            else eval(es) { f(es)(cb) }
+          }
+      }
+
+    /* The code here is very similar. */
+    def choiceN[A](p: Par[Int])(ps: List[Par[A]]): Par[A] =
+      es => new Future[A] {
+        def apply(cb: A => Unit): Unit =
+          p(es) { ind => eval(es) { ps(ind)(es)(cb) }}
+      }
+
+    def choiceViaChoiceN[A](a: Par[Boolean])(ifTrue: Par[A], ifFalse: Par[A]): Par[A] =
+      choiceN(map(a)(b => if (b) 0 else 1))(List(ifTrue, ifFalse))
+
+    def choiceMap[K,V](p: Par[K])(ps: Map[K,Par[V]]): Par[V] =
+      es => new Future[V] {
+        def apply(cb: V => Unit): Unit =
+          p(es)(k => ps(k)(es)(cb))
+      }
+
+    /* `chooser` is usually called `flatMap` or `bind`. */
+    def chooser[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
+      flatMap(p)(f)
+
+    def flatMap[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
+      es => new Future[B] {
+        def apply(cb: B => Unit): Unit =
+          p(es)(a => f(a)(es)(cb))
+      }
+
+    def choiceViaFlatMap[A](p: Par[Boolean])(f: Par[A], t: Par[A]): Par[A] =
+      flatMap(p)(b => if (b) t else f)
+
+    def choiceNViaFlatMap[A](p: Par[Int])(choices: List[Par[A]]): Par[A] =
+      flatMap(p)(i => choices(i))
+
+    def join[A](p: Par[Par[A]]): Par[A] =
+      es => new Future[A] {
+        def apply(cb: A => Unit): Unit =
+          p(es)(p2 => eval(es) { p2(es)(cb) })
+      }
+
+    def joinViaFlatMap[A](a: Par[Par[A]]): Par[A] =
+      flatMap(a)(x => x)
+
+    def flatMapViaJoin[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
+      join(map(p)(f))
+
+    /* Gives us infix syntax for `Par`. */
+    implicit def toParOps[A](p: Par[A]): ParOps[A] = new ParOps(p)
+
+    // infix versions of `map`, `map2` and `flatMap`
+    class ParOps[A](p: Par[A]) {
+      def map[B](f: A => B): Par[B] = Par.map(p)(f)
+      def map2[B,C](b: Par[B])(f: (A,B) => C): Par[C] = Par.map2(p,b)(f)
+      def flatMap[B](f: A => Par[B]): Par[B] = Par.flatMap(p)(f)
+      def zip[B](b: Par[B]): Par[(A,B)] = p.map2(b)((_,_))
+    }
+  }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Par.scala b/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Par.scala
new file mode 100644
index 0000000..d8b7ced
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parallelism/Par.scala
@@ -0,0 +1,148 @@
+package fpinscala.parallelism
+
+import java.util.concurrent._
+import language.implicitConversions
+
+
+object Par {
+  type Par[A] = ExecutorService => Future[A]
+
+  def run[A](s: ExecutorService)(a: Par[A]): Future[A] = a(s)
+
+  def unit[A](a: A): Par[A] = (es: ExecutorService) => UnitFuture(a) // `unit` is represented as a function that returns a `UnitFuture`, which is a simple implementation of `Future` that just wraps a constant value. It doesn't use the `ExecutorService` at all. It's always done and can't be cancelled. Its `get` method simply returns the value that we gave it.
+
+  private case class UnitFuture[A](get: A) extends Future[A] {
+    def isDone = true
+    def get(timeout: Long, units: TimeUnit) = get
+    def isCancelled = false
+    def cancel(evenIfRunning: Boolean): Boolean = false
+  }
+
+  def map2[A,B,C](a: Par[A], b: Par[B])(f: (A,B) => C): Par[C] = // `map2` doesn't evaluate the call to `f` in a separate logical thread, in accord with our design choice of having `fork` be the sole function in the API for controlling parallelism. We can always do `fork(map2(a,b)(f))` if we want the evaluation of `f` to occur in a separate thread.
+    (es: ExecutorService) => {
+      val af = a(es)
+      val bf = b(es)
+      UnitFuture(f(af.get, bf.get)) // This implementation of `map2` does _not_ respect timeouts. It simply passes the `ExecutorService` on to both `Par` values, waits for the results of the Futures `af` and `bf`, applies `f` to them, and wraps them in a `UnitFuture`. In order to respect timeouts, we'd need a new `Future` implementation that records the amount of time spent evaluating `af`, then subtracts that time from the available time allocated for evaluating `bf`.
+    }
+
+  def fork[A](a: => Par[A]): Par[A] = // This is the simplest and most natural implementation of `fork`, but there are some problems with it--for one, the outer `Callable` will block waiting for the "inner" task to complete. Since this blocking occupies a thread in our thread pool, or whatever resource backs the `ExecutorService`, this implies that we're losing out on some potential parallelism. Essentially, we're using two threads when one should suffice. This is a symptom of a more serious problem with the implementation, and we will discuss this later in the chapter.
+    es => es.submit(new Callable[A] {
+      def call = a(es).get
+    })
+
+  def lazyUnit[A](a: => A): Par[A] = fork(unit(a))
+
+  def asyncF[A,B](f: A => B): A => Par[B] =
+    a => lazyUnit(f(a))
+
+  def map[A,B](pa: Par[A])(f: A => B): Par[B] =
+    map2(pa, unit(()))((a,_) => f(a))
+
+  def sortPar(parList: Par[List[Int]]) = map(parList)(_.sorted)
+
+  def sequence_simple[A](l: List[Par[A]]): Par[List[A]] =
+    l.foldRight[Par[List[A]]](unit(List()))((h,t) => map2(h,t)(_ :: _))
+
+  // This implementation forks the recursive step off to a new logical thread,
+  // making it effectively tail-recursive. However, we are constructing
+  // a right-nested parallel program, and we can get better performance by
+  // dividing the list in half, and running both halves in parallel.
+  // See `sequenceBalanced` below.
+  def sequenceRight[A](as: List[Par[A]]): Par[List[A]] =
+    as match {
+      case Nil => unit(Nil)
+      case h :: t => map2(h, fork(sequenceRight(t)))(_ :: _)
+    }
+
+  // We define `sequenceBalanced` using `IndexedSeq`, which provides an
+  // efficient function for splitting the sequence in half.
+  def sequenceBalanced[A](as: IndexedSeq[Par[A]]): Par[IndexedSeq[A]] = fork {
+    if (as.isEmpty) unit(Vector())
+    else if (as.length == 1) map(as.head)(a => Vector(a))
+    else {
+      val (l,r) = as.splitAt(as.length/2)
+      map2(sequenceBalanced(l), sequenceBalanced(r))(_ ++ _)
+    }
+  }
+
+  def sequence[A](as: List[Par[A]]): Par[List[A]] =
+    map(sequenceBalanced(as.toIndexedSeq))(_.toList)
+
+  def parFilter[A](l: List[A])(f: A => Boolean): Par[List[A]] = {
+    val pars: List[Par[List[A]]] =
+      l map (asyncF((a: A) => if (f(a)) List(a) else List()))
+    map(sequence(pars))(_.flatten) // convenience method on `List` for concatenating a list of lists
+  }
+
+  def equal[A](e: ExecutorService)(p: Par[A], p2: Par[A]): Boolean =
+    p(e).get == p2(e).get
+
+  def delay[A](fa: => Par[A]): Par[A] =
+    es => fa(es)
+
+  def choice[A](cond: Par[Boolean])(t: Par[A], f: Par[A]): Par[A] =
+    es =>
+      if (run(es)(cond).get) t(es) // Notice we are blocking on the result of `cond`.
+      else f(es)
+
+  def choiceN[A](n: Par[Int])(choices: List[Par[A]]): Par[A] =
+    es => {
+      val ind = run(es)(n).get // Full source files
+      run(es)(choices(ind))
+    }
+
+  def choiceViaChoiceN[A](a: Par[Boolean])(ifTrue: Par[A], ifFalse: Par[A]): Par[A] =
+    choiceN(map(a)(b => if (b) 0 else 1))(List(ifTrue, ifFalse))
+
+  def choiceMap[K,V](key: Par[K])(choices: Map[K,Par[V]]): Par[V] =
+    es => {
+      val k = run(es)(key).get
+      run(es)(choices(k))
+    }
+
+  def chooser[A,B](p: Par[A])(choices: A => Par[B]): Par[B] =
+    es => {
+      val k = run(es)(p).get
+      run(es)(choices(k))
+    }
+
+  /* `chooser` is usually called `flatMap` or `bind`. */
+  def flatMap[A,B](p: Par[A])(choices: A => Par[B]): Par[B] =
+    es => {
+      val k = run(es)(p).get
+      run(es)(choices(k))
+    }
+
+  def choiceViaFlatMap[A](p: Par[Boolean])(f: Par[A], t: Par[A]): Par[A] =
+    flatMap(p)(b => if (b) t else f)
+
+  def choiceNViaFlatMap[A](p: Par[Int])(choices: List[Par[A]]): Par[A] =
+    flatMap(p)(i => choices(i))
+
+  // see nonblocking implementation in `Nonblocking.scala`
+  def join[A](a: Par[Par[A]]): Par[A] =
+    es => run(es)(run(es)(a).get())
+
+  def joinViaFlatMap[A](a: Par[Par[A]]): Par[A] =
+    flatMap(a)(x => x)
+
+  def flatMapViaJoin[A,B](p: Par[A])(f: A => Par[B]): Par[B] =
+    join(map(p)(f))
+  /* Gives us infix syntax for `Par`. */
+  implicit def toParOps[A](p: Par[A]): ParOps[A] = new ParOps(p)
+
+  class ParOps[A](p: Par[A]) {
+
+  }
+}
+
+object Examples {
+  import Par._
+  def sum(ints: IndexedSeq[Int]): Int = // `IndexedSeq` is a superclass of random-access sequences like `Vector` in the standard library. Unlike lists, these sequences provide an efficient `splitAt` method for dividing them into two parts at a particular index.
+    if (ints.size <= 1)
+      ints.headOption getOrElse 0 // `headOption` is a method defined on all collections in Scala. We saw this function in chapter 3.
+    else {
+      val (l,r) = ints.splitAt(ints.length/2) // Divide the sequence in half using the `splitAt` function.
+      sum(l) + sum(r) // Recursively sum both halves and add the results together.
+    }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parsing/JSON.scala b/src/main/scala/answers/src/main/scala/fpinscala/parsing/JSON.scala
new file mode 100644
index 0000000..a6630af
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parsing/JSON.scala
@@ -0,0 +1,81 @@
+package fpinscala.parsing
+
+import language.higherKinds
+import language.implicitConversions
+
+trait JSON
+
+object JSON {
+  case object JNull extends JSON
+  case class JNumber(get: Double) extends JSON
+  case class JString(get: String) extends JSON
+  case class JBool(get: Boolean) extends JSON
+  case class JArray(get: IndexedSeq[JSON]) extends JSON
+  case class JObject(get: Map[String, JSON]) extends JSON
+
+  def jsonParser[Parser[+_]](P: Parsers[Parser]): Parser[JSON] = {
+    // we'll hide the string implicit conversion and promote strings to tokens instead
+    // this is a bit nicer than having to write token everywhere
+    import P.{string => _, _}
+    implicit def tok(s: String) = token(P.string(s))
+
+    def array = surround("[","]")(
+      value sep "," map (vs => JArray(vs.toIndexedSeq))) scope "array"
+    def obj = surround("{","}")(
+      keyval sep "," map (kvs => JObject(kvs.toMap))) scope "object"
+    def keyval = escapedQuoted ** (":" *> value)
+    def lit = scope("literal") {
+      "null".as(JNull) |
+      double.map(JNumber(_)) |
+      escapedQuoted.map(JString(_)) |
+      "true".as(JBool(true)) |
+      "false".as(JBool(false))
+    }
+    def value: Parser[JSON] = lit | obj | array
+    root(whitespace *> (obj | array))
+  }
+}
+
+/**
+ * JSON parsing example.
+ */
+object JSONExample extends App {
+  val jsonTxt = """
+{
+  "Company name" : "Microsoft Corporation",
+  "Ticker"  : "MSFT",
+  "Active"  : true,
+  "Price"   : 30.66,
+  "Shares outstanding" : 8.38e9,
+  "Related companies" : [ "HPQ", "IBM", "YHOO", "DELL", "GOOG" ]
+}
+"""
+
+  val malformedJson1 = """
+{
+  "Company name" ; "Microsoft Corporation"
+}
+"""
+
+  val malformedJson2 = """
+[
+  [ "HPQ", "IBM",
+  "YHOO", "DELL" ++
+  "GOOG"
+  ]
+]
+"""
+
+  val P = fpinscala.parsing.Reference
+  import fpinscala.parsing.ReferenceTypes.Parser
+
+  def printResult[E](e: Either[E,JSON]) =
+    e.fold(println, println)
+
+  val json: Parser[JSON] = JSON.jsonParser(P)
+  printResult { P.run(json)(jsonTxt) }
+  println("--")
+  printResult { P.run(json)(malformedJson1) }
+  println("--")
+  printResult { P.run(json)(malformedJson2) }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parsing/Parsers.scala b/src/main/scala/answers/src/main/scala/fpinscala/parsing/Parsers.scala
new file mode 100644
index 0000000..5238d1c
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parsing/Parsers.scala
@@ -0,0 +1,247 @@
+package fpinscala.parsing
+
+import java.util.regex._
+import scala.util.matching.Regex
+import fpinscala.testing._
+import fpinscala.testing.Prop._
+import language.higherKinds
+import language.implicitConversions
+
+trait Parsers[Parser[+_]] { self => // so inner classes may call methods of trait
+  def run[A](p: Parser[A])(input: String): Either[ParseError,A]
+
+  implicit def string(s: String): Parser[String]
+  implicit def operators[A](p: Parser[A]) = ParserOps[A](p)
+  implicit def asStringParser[A](a: A)(implicit f: A => Parser[String]):
+    ParserOps[String] = ParserOps(f(a))
+
+  def char(c: Char): Parser[Char] =
+    string(c.toString) map (_.charAt(0))
+
+  /*
+   * A default `succeed` implementation in terms of `string` and `map`.
+   * We leave `succeed` abstract, since `map` is defined below in terms of
+   * `flatMap` and `succeed`, which would be a circular definition! But we include
+   * the definition here in case implementations wish to use it
+   * (say if they provide a custom implementation of `map`, breaking the cycle)
+   */
+  def defaultSucceed[A](a: A): Parser[A] =
+    string("") map (_ => a)
+
+  def succeed[A](a: A): Parser[A]
+
+  def slice[A](p: Parser[A]): Parser[String]
+
+  def many1[A](p: Parser[A]): Parser[List[A]] =
+    map2(p, many(p))(_ :: _)
+
+  def listOfN[A](n: Int, p: Parser[A]): Parser[List[A]] =
+    if (n <= 0) succeed(List())
+    else map2(p, listOfN(n-1, p))(_ :: _)
+
+  def many[A](p: Parser[A]): Parser[List[A]] =
+    map2(p, many(p))(_ :: _) or succeed(List())
+
+  def or[A](p1: Parser[A], p2: => Parser[A]): Parser[A]
+
+  def flatMap[A,B](p: Parser[A])(f: A => Parser[B]): Parser[B]
+
+  implicit def regex(r: Regex): Parser[String]
+
+  /*
+  These can be implemented using a for-comprehension, which delegates to the `flatMap` and `map` implementations we've provided on `ParserOps`, or they can be implemented in terms of these functions directly.
+  */
+  def product[A,B](p: Parser[A], p2: => Parser[B]): Parser[(A,B)] =
+    flatMap(p)(a => map(p2)(b => (a,b)))
+
+  def map2[A,B,C](p: Parser[A], p2: => Parser[B])(f: (A,B) => C): Parser[C] =
+    for { a <- p; b <- p2 } yield f(a,b)
+
+  def map[A,B](a: Parser[A])(f: A => B): Parser[B] =
+    flatMap(a)(f andThen succeed)
+
+  def label[A](msg: String)(p: Parser[A]): Parser[A]
+
+  def scope[A](msg: String)(p: Parser[A]): Parser[A]
+
+  def attempt[A](p: Parser[A]): Parser[A]
+
+  /** Sequences two parsers, ignoring the result of the first.
+    * We wrap the ignored half in slice, since we don't care about its result. */
+  def skipL[B](p: Parser[Any], p2: => Parser[B]): Parser[B] =
+    map2(slice(p), p2)((_,b) => b)
+
+  /** Sequences two parsers, ignoring the result of the second.
+    * We wrap the ignored half in slice, since we don't care about its result. */
+  def skipR[A](p: Parser[A], p2: => Parser[Any]): Parser[A] =
+    map2(p, slice(p2))((a,b) => a)
+
+  def opt[A](p: Parser[A]): Parser[Option[A]] =
+    p.map(Some(_)) or succeed(None)
+
+  /** Parser which consumes zero or more whitespace characters. */
+  def whitespace: Parser[String] = "\\s*".r
+
+  /** Parser which consumes 1 or more digits. */
+  def digits: Parser[String] = "\\d+".r
+
+  /** Parser which consumes reluctantly until it encounters the given string. */
+  def thru(s: String): Parser[String] = (".*?"+Pattern.quote(s)).r
+
+  /** Unescaped string literals, like "foo" or "bar". */
+  def quoted: Parser[String] = string("\"") *> thru("\"").map(_.dropRight(1))
+
+  /** Unescaped or escaped string literals, like "An \n important \"Quotation\"" or "bar". */
+  def escapedQuoted: Parser[String] =
+    // rather annoying to write, left as an exercise
+    // we'll just use quoted (unescaped literals) for now
+    token(quoted label "string literal")
+
+  /** C/Java style floating point literals, e.g .1, -1.0, 1e9, 1E-23, etc.
+    * Result is left as a string to keep full precision
+    */
+  def doubleString: Parser[String] =
+    token("[-+]?([0-9]*\\.)?[0-9]+([eE][-+]?[0-9]+)?".r)
+
+  /** Floating point literals, converted to a `Double`. */
+  def double: Parser[Double] =
+    doubleString map (_.toDouble) label "double literal"
+
+  /** Attempts `p` and strips trailing whitespace, usually used for the tokens of a grammar. */
+  def token[A](p: Parser[A]): Parser[A] =
+    attempt(p) <* whitespace
+
+  /** Zero or more repetitions of `p`, separated by `p2`, whose results are ignored. */
+  def sep[A](p: Parser[A], p2: Parser[Any]): Parser[List[A]] = // use `Parser[Any]` since don't care about result type of separator
+    sep1(p,p2) or succeed(List())
+
+  /** One or more repetitions of `p`, separated by `p2`, whose results are ignored. */
+  def sep1[A](p: Parser[A], p2: Parser[Any]): Parser[List[A]] =
+    map2(p, many(p2 *> p))(_ :: _)
+
+  /** Parses a sequence of left-associative binary operators with the same precedence. */
+  def opL[A](p: Parser[A])(op: Parser[(A,A) => A]): Parser[A] =
+    map2(p, many(op ** p))((h,t) => t.foldLeft(h)((a,b) => b._1(a,b._2)))
+
+  /** Wraps `p` in start/stop delimiters. */
+  def surround[A](start: Parser[Any], stop: Parser[Any])(p: => Parser[A]) =
+    start *> p <* stop
+
+  /** A parser that succeeds when given empty input. */
+  def eof: Parser[String] =
+    regex("\\z".r).label("unexpected trailing characters")
+
+  /** The root of the grammar, expects no further input following `p`. */
+  def root[A](p: Parser[A]): Parser[A] =
+    p <* eof
+
+  case class ParserOps[A](p: Parser[A]) {
+    def |[B>:A](p2: => Parser[B]): Parser[B] = self.or(p,p2) // use `self` to explicitly disambiguate reference to the `or` method on the `trait`
+    def or[B>:A](p2: => Parser[B]): Parser[B] = self.or(p,p2)
+
+    def map[B](f: A => B): Parser[B] = self.map(p)(f)
+    def many = self.many(p)
+
+    def slice: Parser[String] = self.slice(p)
+
+    def **[B](p2: => Parser[B]): Parser[(A,B)] =
+      self.product(p,p2)
+    def product[B](p2: => Parser[B]): Parser[(A,B)] =
+      self.product(p,p2)
+
+    def flatMap[B](f: A => Parser[B]): Parser[B] =
+      self.flatMap(p)(f)
+
+    def label(msg: String): Parser[A] = self.label(msg)(p)
+
+    def scope(msg: String): Parser[A] = self.scope(msg)(p)
+
+    def *>[B](p2: => Parser[B]) = self.skipL(p, p2)
+    def <*(p2: => Parser[Any]) = self.skipR(p, p2)
+    def token = self.token(p)
+    def sep(separator: Parser[Any]) = self.sep(p, separator)
+    def sep1(separator: Parser[Any]) = self.sep1(p, separator)
+    def as[B](b: B): Parser[B] = self.map(self.slice(p))(_ => b)
+    def opL(op: Parser[(A,A) => A]): Parser[A] = self.opL(p)(op)
+  }
+  object Laws {
+    def equal[A](p1: Parser[A], p2: Parser[A])(in: Gen[String]): Prop =
+      forAll(in)(s => run(p1)(s) == run(p2)(s))
+
+    def mapLaw[A](p: Parser[A])(in: Gen[String]): Prop =
+      equal(p, p.map(a => a))(in)
+  }
+}
+
+case class Location(input: String, offset: Int = 0) {
+
+  lazy val line = input.slice(0,offset+1).count(_ == '\n') + 1
+  lazy val col = input.slice(0,offset+1).lastIndexOf('\n') match {
+    case -1 => offset + 1
+    case lineStart => offset - lineStart
+  }
+
+  def toError(msg: String): ParseError =
+    ParseError(List((this, msg)))
+
+  def advanceBy(n: Int) = copy(offset = offset+n)
+
+  /* Returns the line corresponding to this location */
+  def currentLine: String =
+    if (input.length > 1) input.lines.drop(line-1).next
+    else ""
+
+  def columnCaret = (" " * (col-1)) + "^"
+}
+
+case class ParseError(stack: List[(Location,String)] = List()) {
+  def push(loc: Location, msg: String): ParseError =
+    copy(stack = (loc,msg) :: stack)
+
+  def label[A](s: String): ParseError =
+    ParseError(latestLoc.map((_,s)).toList)
+
+  def latest: Option[(Location,String)] =
+    stack.lastOption
+
+  def latestLoc: Option[Location] =
+    latest map (_._1)
+
+  /**
+  Display collapsed error stack - any adjacent stack elements with the
+  same location are combined on one line. For the bottommost error, we
+  display the full line, with a caret pointing to the column of the error.
+  Example:
+
+  1.1 file 'companies.json'; array
+  5.1 object
+  5.2 key-value
+  5.10 ':'
+
+  { "MSFT" ; 24,
+  */
+  override def toString =
+    if (stack.isEmpty) "no error message"
+    else {
+      val collapsed = collapseStack(stack)
+      val context =
+        collapsed.lastOption.map("\n\n" + _._1.currentLine).getOrElse("") +
+        collapsed.lastOption.map("\n" + _._1.columnCaret).getOrElse("")
+      collapsed.map { case (loc,msg) => loc.line.toString + "." + loc.col + " " + msg }.mkString("\n") +
+      context
+    }
+
+  /* Builds a collapsed version of the given error stack -
+   * messages at the same location have their messages merged,
+   * separated by semicolons */
+  def collapseStack(s: List[(Location,String)]): List[(Location,String)] =
+    s.groupBy(_._1).
+      mapValues(_.map(_._2).mkString("; ")).
+      toList.sortBy(_._1.offset)
+
+  def formatLoc(l: Location): String = l.line + "." + l.col
+}
+
+object Parsers {
+
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala b/src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala
new file mode 100644
index 0000000..6a21394
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Reference.scala
@@ -0,0 +1,148 @@
+package fpinscala
+package parsing
+
+import ReferenceTypes._
+import scala.util.matching.Regex
+
+object ReferenceTypes {
+
+  /** A parser is a kind of state action that can fail. */
+  type Parser[+A] = ParseState => Result[A]
+
+  /** `ParseState` wraps a `Location` and provides some extra
+    * convenience functions. The sliceable parsers defined
+    * in `Sliceable.scala` add an `isSliced` `Boolean` flag
+    * to `ParseState`.
+    */
+  case class ParseState(loc: Location) {
+    def advanceBy(numChars: Int): ParseState =
+      copy(loc = loc.copy(offset = loc.offset + numChars))
+    def input: String = loc.input.substring(loc.offset)
+    def slice(n: Int) = loc.input.substring(loc.offset, loc.offset + n)
+  }
+
+  /* Likewise, we define a few helper functions on `Result`. */
+  sealed trait Result[+A] {
+    def extract: Either[ParseError,A] = this match {
+      case Failure(e,_) => Left(e)
+      case Success(a,_) => Right(a)
+    }
+    /* Used by `attempt`. */
+    def uncommit: Result[A] = this match {
+      case Failure(e,true) => Failure(e,false)
+      case _ => this
+    }
+    /* Used by `flatMap` */
+    def addCommit(isCommitted: Boolean): Result[A] = this match {
+      case Failure(e,c) => Failure(e, c || isCommitted)
+      case _ => this
+    }
+    /* Used by `scope`, `label`. */
+    def mapError(f: ParseError => ParseError): Result[A] = this match {
+      case Failure(e,c) => Failure(f(e),c)
+      case _ => this
+    }
+    def advanceSuccess(n: Int): Result[A] = this match {
+      case Success(a,m) => Success(a,n+m)
+      case _ => this
+    }
+  }
+  case class Success[+A](get: A, length: Int) extends Result[A]
+  case class Failure(get: ParseError, isCommitted: Boolean) extends Result[Nothing]
+
+  /** Returns -1 if s1.startsWith(s2), otherwise returns the
+    * first index where the two strings differed. If s2 is
+    * longer than s1, returns s1.length. */
+  def firstNonmatchingIndex(s1: String, s2: String, offset: Int): Int = {
+    var i = 0
+    while (i < s1.length && i < s2.length) {
+      if (s1.charAt(i+offset) != s2.charAt(i)) return i
+      i += 1
+    }
+    if (s1.length-offset >= s2.length) -1
+    else s1.length-offset
+  }
+}
+
+object Reference extends Parsers[Parser] {
+
+  def run[A](p: Parser[A])(s: String): Either[ParseError,A] = {
+    val s0 = ParseState(Location(s))
+    p(s0).extract
+  }
+
+  // consume no characters and succeed with the given value
+  def succeed[A](a: A): Parser[A] = s => Success(a, 0)
+
+  def or[A](p: Parser[A], p2: => Parser[A]): Parser[A] =
+    s => p(s) match {
+      case Failure(e,false) => p2(s)
+      case r => r // committed failure or success skips running `p2`
+    }
+
+  def flatMap[A,B](f: Parser[A])(g: A => Parser[B]): Parser[B] =
+    s => f(s) match {
+      case Success(a,n) => g(a)(s.advanceBy(n))
+                           .addCommit(n != 0)
+                           .advanceSuccess(n)
+      case f@Failure(_,_) => f
+    }
+
+  def string(w: String): Parser[String] = {
+    val msg = "'" + w + "'"
+    s => {
+      val i = firstNonmatchingIndex(s.loc.input, w, s.loc.offset)
+      if (i == -1) // they matched
+        Success(w, w.length)
+      else
+        Failure(s.loc.advanceBy(i).toError(msg), i != 0)
+    }
+  }
+
+  /* note, regex matching is 'all-or-nothing':
+   * failures are uncommitted */
+  def regex(r: Regex): Parser[String] = {
+    val msg = "regex " + r
+    s => r.findPrefixOf(s.input) match {
+      case None => Failure(s.loc.toError(msg), false)
+      case Some(m) => Success(m,m.length)
+    }
+  }
+
+  def scope[A](msg: String)(p: Parser[A]): Parser[A] =
+    s => p(s).mapError(_.push(s.loc,msg))
+
+  def label[A](msg: String)(p: Parser[A]): Parser[A] =
+    s => p(s).mapError(_.label(msg))
+
+  def fail[A](msg: String): Parser[A] =
+    s => Failure(s.loc.toError(msg), true)
+
+  def attempt[A](p: Parser[A]): Parser[A] =
+    s => p(s).uncommit
+
+  def slice[A](p: Parser[A]): Parser[String] =
+    s => p(s) match {
+      case Success(_,n) => Success(s.slice(n),n)
+      case f@Failure(_,_) => f
+    }
+
+  /* We provide an overridden version of `many` that accumulates
+   * the list of results using a monolithic loop. This avoids
+   * stack overflow errors for most grammars.
+   */
+  override def many[A](p: Parser[A]): Parser[List[A]] =
+    s => {
+      var nConsumed: Int = 0
+      val buf = new collection.mutable.ListBuffer[A]
+      def go(p: Parser[A], offset: Int): Result[List[A]] = {
+        p(s.advanceBy(offset)) match {
+          case Success(a,n) => buf += a; go(p, offset+n)
+          case f@Failure(e,true) => f
+          case Failure(e,_) => Success(buf.toList,offset)
+        }
+      }
+      go(p, 0)
+    }
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala b/src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala
new file mode 100644
index 0000000..6826b52
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/parsing/instances/Sliceable.scala
@@ -0,0 +1,273 @@
+package fpinscala
+package parsing
+
+import SliceableTypes._
+import scala.util.matching.Regex
+
+/*
+This implementation is a bit trickier than the one in `Reference.scala`.
+The main change is to add another piece of state to `ParseState`,
+an `isSliced` flag, and an additional `Slice` constructor to `Result`.
+If the `isSliced` flag is set, parsers avoid building a meaningful
+result--see in particular the overridden implementations for `map`,
+`map2`, and `many`.
+
+This implementation runs up against some limitations of Scala's
+type system--Scala does not appropriately refine type parameters when
+pattern matching. Keep reading for more details on this.
+*/
+object SliceableTypes {
+
+  /* A parser is a kind of state action that can fail.
+   * This type is slightly fancier than the one discussed in the chapter,
+   * to support efficient slicing. If the parser is surrounded by
+   * a `slice` combinator, the `isSliced` field of `ParseState` will
+   * be `true`, and we return a `Slice` output.
+   */
+  type Parser[+A] = ParseState => Result[A]
+
+  /** `isSliced` indicates if the current parser is surround by a
+    * `slice` combinator. This lets us avoid building up values that
+    * will end up getting thrown away.
+    *
+    * There are several convenience functions on `ParseState` to make
+    * implementing some of the combinators easier.
+    */
+  case class ParseState(loc: Location, isSliced: Boolean) {
+    // some convenience functions
+    def advanceBy(numChars: Int): ParseState =
+      copy(loc = loc.copy(offset = loc.offset + numChars))
+    def input: String = loc.input.substring(loc.offset)
+    def unslice = copy(isSliced = false)
+    def reslice(s: ParseState) = copy(isSliced = s.isSliced)
+    def slice(n: Int) = loc.input.substring(loc.offset, loc.offset + n)
+  }
+
+  /** The result of a parse--a `Parser[A]` returns a `Result[A]`.
+    *
+    * There are three cases:
+    *   - Success(a,n): a is the value, n is # of consumed characters
+    *   - Slice(n): a successful slice; n is the # of consumed characters
+    *   - Failure(n,isCommitted): a failing parse
+    *
+    * As usual, we define some helper functions on `Result`.
+    * Defining functions on `Result` gives us better type
+    * information--there are cases (see `map` and `map2` below) where
+    * Scala will not appropriately refine type information when
+    * pattern matching on `Result`.
+    */
+  sealed trait Result[+A] {
+    def extract(input: String): Either[ParseError,A]
+    def slice: Result[String]
+    /* Used by `attempt`. */
+    def uncommit: Result[A] = this match {
+      case Failure(e,true) => Failure(e,false)
+      case _ => this
+    }
+    /* Used by `flatMap` */
+    def addCommit(isCommitted: Boolean): Result[A] = this match {
+      case Failure(e,c) => Failure(e, c || isCommitted)
+      case _ => this
+    }
+    /* Used by `scope`, `label`. */
+    def mapError(f: ParseError => ParseError): Result[A] = this match {
+      case Failure(e,c) => Failure(f(e),c)
+      case _ => this
+    }
+    def advanceSuccess(n: Int): Result[A]
+  }
+  case class Slice(length: Int) extends Result[String] {
+    def extract(s: String) = Right(s.substring(0,length))
+    def slice = this
+    def advanceSuccess(n: Int) = Slice(length+n)
+  }
+  case class Success[+A](get: A, length: Int) extends Result[A] {
+    def extract(s: String) = Right(get)
+    def slice = Slice(length)
+    def advanceSuccess(n: Int) = Success(get, length+n)
+  }
+  case class Failure(get: ParseError, isCommitted: Boolean) extends Result[Nothing] {
+    def extract(s: String) = Left(get)
+    def slice = this
+    def advanceSuccess(n: Int) = this
+  }
+
+  /** Returns -1 if s.startsWith(s2), otherwise returns the
+    * first index where the two strings differed. If s2 is
+    * longer than s1, returns s.length. */
+  def firstNonmatchingIndex(s: String, s2: String, offset: Int): Int = {
+    var i = 0
+    while (i+offset < s.length && i < s2.length) {
+      if (s.charAt(i+offset) != s2.charAt(i)) return i
+      i += 1
+    }
+    if (s.length-offset >= s2.length) -1
+    else s.length-offset
+  }
+}
+
+object Sliceable extends Parsers[Parser] {
+
+  def run[A](p: Parser[A])(s: String): Either[ParseError,A] = {
+    val s0 = ParseState(Location(s), false)
+    p(s0).extract(s)
+  }
+
+  // consume no characters and succeed with the given value
+  def succeed[A](a: A): Parser[A] = s => Success(a, 0)
+
+  def or[A](p: Parser[A], p2: => Parser[A]): Parser[A] =
+    s => p(s) match {
+      case Failure(e,false) => p2(s)
+      case r => r // committed failure or success skips running `p2`
+    }
+
+  /*
+   * `Result` is an example of a Generalized Algebraic Data Type (GADT),
+   * which means that not all the data constructors of `Result` have
+   * the same type. In particular, `Slice` _refines_ the `A` type
+   * parameter to be `String`. If we pattern match on a `Result`
+   * and obtain a `Slice`, we expect to be able to assume that `A` was
+   * in fact `String` and use this type information elsewhere.
+   *
+   * Unfortunately, Scala doesn't quite support this. Let's look
+   * at an example, `map`.
+   */
+
+  /* Pattern matching on Slice should refine the type `A` to `String`,
+   * and allow us to call `f(s.slice(n))`, since `f` accepts an
+   * `A` which is known to be `String`. We resort to a cast here.
+   */
+  override def map[A,B](p: Parser[A])(f: A => B): Parser[B] =
+    s => p(s) match {
+      case Success(a,n) => Success(f(a),n)
+      case Slice(n) => Success(f(s.slice(n).asInstanceOf[A]),n)
+      case f@Failure(_,_) => f
+    }
+
+  /* See this gist for more information, examples, and discussion
+   * of Scala's GADT support:
+   * https://gist.github.com/1369239
+   */
+
+  /* This implementation is rather delicate. Since we need an `A`
+   * to generate the second parser, we need to run the first parser
+   * 'unsliced', even if the `flatMap` is wrapped in a `slice` call.
+   * Once we have the `A` and have generated the second parser to
+   * run, we can 'reslice' the second parser.
+   *
+   * Note that this implementation is less efficient than it could
+   * be in the case where the choice of the second parser does not
+   * depend on the first (as in `map2`). In that case, we could
+   * continue to run the first parser sliced.
+   *
+   * Again, note the cast needed.
+   */
+  def flatMap[A,B](f: Parser[A])(g: A => Parser[B]): Parser[B] =
+    s => f(s.unslice) match {
+      case Success(a,n) =>
+        g(a)(s.advanceBy(n).reslice(s))
+        .addCommit(n != 0)
+        .advanceSuccess(n)
+      case Slice(n) => g(s.slice(n).asInstanceOf[A])(s.advanceBy(n).reslice(s))
+                       .advanceSuccess(n)
+      case f@Failure(_,_) => f
+    }
+
+  // other functions are quite similar to impls in `Reference.scala`
+
+  def string(w: String): Parser[String] = {
+    val msg = "'" + w + "'"
+    s => {
+      val i = firstNonmatchingIndex(s.loc.input, w, s.loc.offset)
+      if (i == -1) { // they matched
+        if (s.isSliced) Slice(w.length)
+        else            Success(w, w.length)
+      }
+      else
+        Failure(s.loc.advanceBy(i).toError(msg), i != 0)
+    }
+  }
+
+  // note, regex matching is 'all-or-nothing' - failures are
+  // uncommitted
+  def regex(r: Regex): Parser[String] = {
+    val msg = "regex " + r
+    s => r.findPrefixOf(s.input) match {
+      case None => Failure(s.loc.toError(msg), false)
+      case Some(m) =>
+        if (s.isSliced) Slice(m.length)
+        else            Success(m,m.length)
+    }
+  }
+
+  def scope[A](msg: String)(p: Parser[A]): Parser[A] =
+    s => p(s).mapError(_.push(s.loc,msg))
+
+  def label[A](msg: String)(p: Parser[A]): Parser[A] =
+    s => p(s).mapError(_.label(msg))
+
+  def fail[A](msg: String): Parser[A] =
+    s => Failure(s.loc.toError(msg), true)
+
+  def attempt[A](p: Parser[A]): Parser[A] =
+    s => p(s).uncommit
+
+  def slice[A](p: Parser[A]): Parser[String] =
+    s => p(s.copy(isSliced = true)).slice
+
+  /* As with `map`, we require casts in a few places. */
+  override def map2[A,B,C](p: Parser[A], p2: => Parser[B])(f: (A,B) => C): Parser[C] =
+    s => p(s) match {
+      case Success(a,n) => val s2 = s.advanceBy(n); p2(s2) match {
+        case Success(b,m) => Success(f(a,b),n+m)
+        case Slice(m) => Success(f(a,s2.slice(m).asInstanceOf[B]), n+m)
+        case f@Failure(_,_) => f
+      }
+      case Slice(n) => val s2 = s.advanceBy(n); p2(s2) match {
+        case Success(b,m) => Success(f(s.slice(n).asInstanceOf[A],b),n+m)
+        case Slice(m) =>
+          if (s.isSliced) Slice(n+m).asInstanceOf[Result[C]]
+          else Success(f(s.slice(n).asInstanceOf[A],s2.slice(m).asInstanceOf[B]), n+m)
+        case f@Failure(_,_) => f
+      }
+      case f@Failure(_,_) => f
+    }
+
+  override def product[A,B](p: Parser[A], p2: => Parser[B]): Parser[(A,B)] =
+    map2(p,p2)((_,_))
+
+  /* We provide an overridden version of `many` that accumulates
+   * the list of results using a monolithic loop. This avoids
+   * stack overflow errors.
+   */
+  override def many[A](p: Parser[A]): Parser[List[A]] =
+    s => {
+      var nConsumed: Int = 0
+      if (s.isSliced) {
+        def go(p: Parser[String], offset: Int): Result[String] =
+          p(s.advanceBy(offset)) match {
+            case f@Failure(e,true) => f
+            case Failure(e,_) => Slice(offset)
+            case Slice(n) => go(p, offset+n)
+            case Success(_,_) => sys.error("sliced parser should not return success, only slice")
+          }
+        go(p.slice, 0).asInstanceOf[Result[List[A]]]
+      }
+      else {
+        val buf = new collection.mutable.ListBuffer[A]
+        def go(p: Parser[A], offset: Int): Result[List[A]] = {
+          p(s.advanceBy(offset)) match {
+            case Success(a,n) => buf += a; go(p, offset+n)
+            case f@Failure(e,true) => f
+            case Failure(e,_) => Success(buf.toList,offset)
+            case Slice(n) =>
+              buf += s.input.substring(offset,offset+n).
+                     asInstanceOf[A]
+              go(p, offset+n)
+          }
+        }
+        go(p, 0)
+      }
+    }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/state/State.scala b/src/main/scala/answers/src/main/scala/fpinscala/state/State.scala
new file mode 100644
index 0000000..88e7b48
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/state/State.scala
@@ -0,0 +1,241 @@
+package fpinscala.state
+
+
+trait RNG {
+  def nextInt: (Int, RNG) // Should generate a random `Int`. We'll later define other functions in terms of `nextInt`.
+}
+
+object RNG {
+  // NB - this was called SimpleRNG in the book text
+
+  case class Simple(seed: Long) extends RNG {
+    def nextInt: (Int, RNG) = {
+      val newSeed = (seed * 0x5DEECE66DL + 0xBL) & 0xFFFFFFFFFFFFL // `&` is bitwise AND. We use the current seed to generate a new seed.
+      val nextRNG = Simple(newSeed) // The next state, which is an `RNG` instance created from the new seed.
+      val n = (newSeed >>> 16).toInt // `>>>` is right binary shift with zero fill. The value `n` is our new pseudo-random integer.
+      (n, nextRNG) // The return value is a tuple containing both a pseudo-random integer and the next `RNG` state.
+    }
+  }
+
+  // We need to be quite careful not to skew the generator.
+  // Since `Int.Minvalue` is 1 smaller than `-(Int.MaxValue)`,
+  // it suffices to increment the negative numbers by 1 and make them positive.
+  // This maps Int.MinValue to Int.MaxValue and -1 to 0.
+  def nonNegativeInt(rng: RNG): (Int, RNG) = {
+    val (i, r) = rng.nextInt
+    (if (i < 0) -(i + 1) else i, r)
+  }
+
+  // We generate an integer >= 0 and divide it by one higher than the
+  // maximum. This is just one possible solution.
+  def double(rng: RNG): (Double, RNG) = {
+    val (i, r) = nonNegativeInt(rng)
+    (i / (Int.MaxValue.toDouble + 1), r)
+  }
+
+  def boolean(rng: RNG): (Boolean, RNG) =
+    rng.nextInt match { case (i,rng2) => (i%2==0,rng2) }
+
+  def intDouble(rng: RNG): ((Int, Double), RNG) = {
+    val (i, r1) = rng.nextInt
+    val (d, r2) = double(r1)
+    ((i, d), r2)
+  }
+
+  def doubleInt(rng: RNG): ((Double, Int), RNG) = {
+    val ((i, d), r) = intDouble(rng)
+    ((d, i), r)
+  }
+
+  def double3(rng: RNG): ((Double, Double, Double), RNG) = {
+    val (d1, r1) = double(rng)
+    val (d2, r2) = double(r1)
+    val (d3, r3) = double(r2)
+    ((d1, d2, d3), r3)
+  }
+
+  // There is something terribly repetitive about passing the RNG along
+  // every time. What could we do to eliminate some of this duplication
+  // of effort?
+
+  // A simple recursive solution
+  def ints(count: Int)(rng: RNG): (List[Int], RNG) =
+    if (count == 0)
+      (List(), rng)
+    else {
+      val (x, r1)  = rng.nextInt
+      val (xs, r2) = ints(count - 1)(r1)
+      (x :: xs, r2)
+    }
+
+  // A tail-recursive solution
+  def ints2(count: Int)(rng: RNG): (List[Int], RNG) = {
+    def go(count: Int, r: RNG, xs: List[Int]): (List[Int], RNG) =
+      if (count == 0)
+        (xs, r)
+      else {
+        val (x, r2) = r.nextInt
+        go(count - 1, r2, x :: xs)
+      }
+    go(count, rng, List())
+  }
+
+  type Rand[+A] = RNG => (A, RNG)
+
+  val int: Rand[Int] = _.nextInt
+
+  def unit[A](a: A): Rand[A] =
+    rng => (a, rng)
+
+  def map[A,B](s: Rand[A])(f: A => B): Rand[B] =
+    rng => {
+      val (a, rng2) = s(rng)
+      (f(a), rng2)
+    }
+
+  val _double: Rand[Double] =
+    map(nonNegativeInt)(_ / (Int.MaxValue.toDouble + 1))
+
+  // This implementation of map2 passes the initial RNG to the first argument
+  // and the resulting RNG to the second argument. It's not necessarily wrong
+  // to do this the other way around, since the results are random anyway.
+  // We could even pass the initial RNG to both `f` and `g`, but that might
+  // have unexpected results. E.g. if both arguments are `RNG.int` then we would
+  // always get two of the same `Int` in the result. When implementing functions
+  // like this, it's important to consider how we would test them for
+  // correctness.
+  def map2[A,B,C](ra: Rand[A], rb: Rand[B])(f: (A, B) => C): Rand[C] =
+    rng => {
+      val (a, r1) = ra(rng)
+      val (b, r2) = rb(r1)
+      (f(a, b), r2)
+    }
+
+  def both[A,B](ra: Rand[A], rb: Rand[B]): Rand[(A,B)] =
+    map2(ra, rb)((_, _))
+
+  val randIntDouble: Rand[(Int, Double)] =
+    both(int, double)
+
+  val randDoubleInt: Rand[(Double, Int)] =
+    both(double, int)
+
+  // In `sequence`, the base case of the fold is a `unit` action that returns
+  // the empty list. At each step in the fold, we accumulate in `acc`
+  // and `f` is the current element in the list.
+  // `map2(f, acc)(_ :: _)` results in a value of type `Rand[List[A]]`
+  // We map over that to prepend (cons) the element onto the accumulated list.
+  //
+  // We are using `foldRight`. If we used `foldLeft` then the values in the
+  // resulting list would appear in reverse order. It would be arguably better
+  // to use `foldLeft` followed by `reverse`. What do you think?
+  def sequence[A](fs: List[Rand[A]]): Rand[List[A]] =
+    fs.foldRight(unit(List[A]()))((f, acc) => map2(f, acc)(_ :: _))
+
+  // It's interesting that we never actually need to talk about the `RNG` value
+  // in `sequence`. This is a strong hint that we could make this function
+  // polymorphic in that type.
+
+  def _ints(count: Int): Rand[List[Int]] =
+    sequence(List.fill(count)(int))
+
+  def flatMap[A,B](f: Rand[A])(g: A => Rand[B]): Rand[B] =
+    rng => {
+      val (a, r1) = f(rng)
+      g(a)(r1) // We pass the new state along
+    }
+
+  def nonNegativeLessThan(n: Int): Rand[Int] = {
+    flatMap(nonNegativeInt) { i =>
+      val mod = i % n
+      if (i + (n-1) - mod >= 0) unit(mod) else nonNegativeLessThan(n)
+    }
+  }
+
+  def _map[A,B](s: Rand[A])(f: A => B): Rand[B] =
+    flatMap(s)(a => unit(f(a)))
+
+  def _map2[A,B,C](ra: Rand[A], rb: Rand[B])(f: (A, B) => C): Rand[C] =
+    flatMap(ra)(a => map(rb)(b => f(a, b)))
+}
+
+import State._
+
+case class State[S, +A](run: S => (A, S)) {
+  def map[B](f: A => B): State[S, B] =
+    flatMap(a => unit(f(a)))
+  def map2[B,C](sb: State[S, B])(f: (A, B) => C): State[S, C] =
+    flatMap(a => sb.map(b => f(a, b)))
+  def flatMap[B](f: A => State[S, B]): State[S, B] = State(s => {
+    val (a, s1) = run(s)
+    f(a).run(s1)
+  })
+}
+
+object State {
+  type Rand[A] = State[RNG, A]
+
+  def unit[S, A](a: A): State[S, A] =
+    State(s => (a, s))
+
+  // The idiomatic solution is expressed via foldRight
+  def sequenceViaFoldRight[S,A](sas: List[State[S, A]]): State[S, List[A]] =
+    sas.foldRight(unit[S, List[A]](List()))((f, acc) => f.map2(acc)(_ :: _))
+
+  // This implementation uses a loop internally and is the same recursion
+  // pattern as a left fold. It is quite common with left folds to build
+  // up a list in reverse order, then reverse it at the end.
+  // (We could also use a collection.mutable.ListBuffer internally.)
+  def sequence[S, A](sas: List[State[S, A]]): State[S, List[A]] = {
+    def go(s: S, actions: List[State[S,A]], acc: List[A]): (List[A],S) =
+      actions match {
+        case Nil => (acc.reverse,s)
+        case h :: t => h.run(s) match { case (a,s2) => go(s2, t, a :: acc) }
+      }
+    State((s: S) => go(s,sas,List()))
+  }
+
+  // We can also write the loop using a left fold. This is tail recursive like the
+  // previous solution, but it reverses the list _before_ folding it instead of after.
+  // You might think that this is slower than the `foldRight` solution since it
+  // walks over the list twice, but it's actually faster! The `foldRight` solution
+  // technically has to also walk the list twice, since it has to unravel the call
+  // stack, not being tail recursive. And the call stack will be as tall as the list
+  // is long.
+  def sequenceViaFoldLeft[S,A](l: List[State[S, A]]): State[S, List[A]] =
+    l.reverse.foldLeft(unit[S, List[A]](List()))((acc, f) => f.map2(acc)( _ :: _ ))
+
+  def modify[S](f: S => S): State[S, Unit] = for {
+    s <- get // Gets the current state and assigns it to `s`.
+    _ <- set(f(s)) // Sets the new state to `f` applied to `s`.
+  } yield ()
+
+  def get[S]: State[S, S] = State(s => (s, s))
+
+  def set[S](s: S): State[S, Unit] = State(_ => ((), s))
+}
+
+sealed trait Input
+case object Coin extends Input
+case object Turn extends Input
+
+case class Machine(locked: Boolean, candies: Int, coins: Int)
+
+object Candy {
+  def update = (i: Input) => (s: Machine) =>
+    (i, s) match {
+      case (_, Machine(_, 0, _)) => s
+      case (Coin, Machine(false, _, _)) => s
+      case (Turn, Machine(true, _, _)) => s
+      case (Coin, Machine(true, candy, coin)) =>
+        Machine(false, candy, coin + 1)
+      case (Turn, Machine(false, candy, coin)) =>
+        Machine(true, candy - 1, coin)
+    }
+
+  def simulateMachine(inputs: List[Input]): State[Machine, (Int, Int)] = for {
+    _ <- sequence(inputs map (modify[Machine] _ compose update))
+    s <- get
+  } yield (s.coins, s.candies)
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/streamingio/Eq.scala b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/Eq.scala
new file mode 100644
index 0000000..da555f8
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/Eq.scala
@@ -0,0 +1,16 @@
+package fpinscala.streamingio
+
+/* 
+ * `Eq[A,B]` provides evidence that types `A` and `B` are equal. 
+ * There is just one public constructor, `Eq.refl`, ensuring that
+ * we cannot construct an `Eq` instance in which the `A` and `B`
+ * differ.
+ * 
+ * There is a version of this in the scala standard library, 
+ * called =:=[A,B] (and usually written infix as `A =:= B`) but
+ * we include a version here just to show that it is not magic.
+ */
+case class Eq[A,B] private(to: A => B, from: B => A)
+
+object Eq { def refl[A]: Eq[A,A] = Eq(identity, identity) } 
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala
new file mode 100644
index 0000000..b292fe5
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/MonadCatch.scala
@@ -0,0 +1,23 @@
+package fpinscala.streamingio
+
+import fpinscala.iomonad._
+
+import language.higherKinds
+
+/*
+ * A context in which exceptions can be caught and
+ * thrown.
+ */
+trait MonadCatch[F[_]] extends Monad[F] {
+  def attempt[A](a: F[A]): F[Either[Throwable,A]]
+  def fail[A](t: Throwable): F[A]
+}
+
+object MonadCatch {
+  implicit def task = new MonadCatch[Task] {
+    def unit[A](a: => A): Task[A] = Task.unit(a)
+    def flatMap[A,B](a: Task[A])(f: A => Task[B]): Task[B] = a flatMap f
+    def attempt[A](a: Task[A]): Task[Either[Throwable,A]] = a.attempt
+    def fail[A](err: Throwable): Task[A] = Task.fail(err)
+  }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/streamingio/Partial.scala b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/Partial.scala
new file mode 100644
index 0000000..4ead887
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/Partial.scala
@@ -0,0 +1,13 @@
+package fpinscala.streamingio
+
+import language.higherKinds
+
+/* 
+ * A context in which exceptions can be caught and
+ * thrown. 
+ */
+trait Partial[F[_]] { 
+  def attempt[A](a: F[A]): F[Either[Throwable,A]]
+  def fail[A](t: Throwable): F[A]
+}
+
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala
new file mode 100644
index 0000000..d11903a
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/StreamingIO.scala
@@ -0,0 +1,1133 @@
+package fpinscala.streamingio
+
+import fpinscala.iomonad.{IO,Monad,Free,unsafePerformIO}
+import language.implicitConversions
+import language.higherKinds
+import language.postfixOps
+
+object ImperativeAndLazyIO {
+
+                            /*
+
+  We are going to consider various approaches to the simple task of
+  checking whether a file contains more than 40,000 lines.
+
+  Our first implementation is an imperative implementation, embedded
+  into `IO`.
+                             */
+
+  import java.io._
+
+  def linesGt40k(filename: String): IO[Boolean] = IO {
+    // There are a number of convenience functions in scala.io.Source
+    // for reading from external sources such as files.
+    val src = io.Source.fromFile(filename)
+    try {
+      var count = 0
+      // Obtain a stateful iterator from the Source
+      val lines: Iterator[String] = src.getLines
+      while (count <= 40000 && lines.hasNext) {
+        lines.next // has side effect of advancing to next element
+        count += 1
+      }
+      count > 40000
+    }
+    finally src.close
+  }
+
+                            /*
+
+  The above code is rather low-level, and it's not compositional,
+  either. Consider the following scenarios:
+
+  * Check whether the number of _nonempty_ lines in the file exceeds
+    40,000
+  * Find a line index before 40,000 where the first letter of
+    consecutive lines spells out `"abracadabra"`.
+
+  We cannot just compose our existing implementation with some
+  other combinator(s) to implement these tasks. Our implementation is
+  a monolithic loop, and we must modify this loop directly if we want
+  to change its behavior.
+
+  Now imagine if we had a `Stream[String]` for the lines of the file
+  and we could assemble functionality using all the `Stream` functions
+  we know and love.
+                             */
+
+  object Examples {
+    val lines: Stream[String] = sys.error("defined elsewhere")
+    val ex1 = lines.zipWithIndex.exists(_._2 + 1 >= 40000)
+    val ex2 = lines.filter(!_.trim.isEmpty).zipWithIndex.exists(_._2 + 1 >= 40000)
+    val ex3 = lines.take(40000).map(_.head).indexOfSlice("abracadabra".toList)
+  }
+
+                            /*
+
+  Could we actually write the above? Not quite. We could 'cheat' and
+  return an `IO[Stream[String]]` representing the lines of a file:
+
+                             */
+
+  def lines(filename: String): IO[Stream[String]] = IO {
+    val src = io.Source.fromFile(filename)
+    src.getLines.toStream append { src.close; Stream.empty }
+  }
+                            /*
+
+  This is called _lazy I/O_, and it's problematic for a number of
+  reasons, discussed in the book text. However, it would be nice to
+  recover the same high-level, compositional style we are used to
+  from our use of `List` and `Stream`.
+
+                             */
+}
+
+object SimpleStreamTransducers {
+
+                            /*
+
+  We now introduce a type, `Process`, representing pure, single-input
+  stream transducers. It can be in of three states - it can be
+  emitting a value to the output (`Emit`), reading a value from its
+  input (`Await`) or signaling termination via `Halt`.
+
+                             */
+
+  sealed trait Process[I,O] {
+    import Process._
+
+    /*
+     * A `Process[I,O]` can be used to transform a `Stream[I]` to a
+     * `Stream[O]`.
+     */
+    def apply(s: Stream[I]): Stream[O] = this match {
+      case Halt() => Stream()
+      case Await(recv) => s match {
+        case h #:: t => recv(Some(h))(t)
+        case xs => recv(None)(xs) // Stream is empty
+      }
+      case Emit(h,t) => h #:: t(s)
+    }
+
+    /*
+     * `Process` can be thought of as a sequence of values of type `O`
+     * and many of the operations that would be defined for `List[O]`
+     * can be defined for `Process[I,O]`, for instance `map`, `++` and
+     * `flatMap`. The definitions are analogous.
+     */
+
+    def map[O2](f: O => O2): Process[I,O2] = this match {
+      case Halt() => Halt()
+      case Emit(h, t) => Emit(f(h), t map f)
+      case Await(recv) => Await(recv andThen (_ map f))
+    }
+    def ++(p: => Process[I,O]): Process[I,O] = this match {
+      case Halt() => p
+      case Emit(h, t) => Emit(h, t ++ p)
+      case Await(recv) => Await(recv andThen (_ ++ p))
+    }
+    def flatMap[O2](f: O => Process[I,O2]): Process[I,O2] = this match {
+      case Halt() => Halt()
+      case Emit(h, t) => f(h) ++ t.flatMap(f)
+      case Await(recv) => Await(recv andThen (_ flatMap f))
+    }
+
+    /*
+     * Exercise 5: Implement `|>`. Let the types guide your implementation.
+     */
+    def |>[O2](p2: Process[O,O2]): Process[I,O2] = {
+      p2 match {
+        case Halt() => Halt()
+        case Emit(h,t) => Emit(h, this |> t)
+        case Await(f) => this match {
+          case Emit(h,t) => t |> f(Some(h))
+          case Halt() => Halt() |> f(None)
+          case Await(g) => Await((i: Option[I]) => g(i) |> p2)
+        }
+      }
+    }
+
+    /*
+     * Feed `in` to this `Process`. Uses a tail recursive loop as long
+     * as `this` is in the `Await` state.
+     */
+    def feed(in: Seq[I]): Process[I,O] = {
+      @annotation.tailrec
+      def go(in: Seq[I], cur: Process[I,O]): Process[I,O] =
+        cur match {
+          case Halt() => Halt()
+          case Await(recv) =>
+            if (in.nonEmpty) go(in.tail, recv(Some(in.head)))
+            else cur
+          case Emit(h, t) => Emit(h, t.feed(in))
+        }
+      go(in, this)
+    }
+
+
+    /*
+     * See `Process.lift` for a typical repeating `Process`
+     * definition expressed with explicit recursion.
+     */
+
+    /*
+     * `Process` definitions can often be expressed without explicit
+     * recursion, by repeating some simpler `Process` forever.
+     */
+    def repeat: Process[I,O] = {
+      def go(p: Process[I,O]): Process[I,O] = p match {
+        case Halt() => go(this)
+        case Await(recv) => Await {
+          case None => recv(None)
+          case i => go(recv(i))
+        }
+        case Emit(h, t) => Emit(h, go(t))
+      }
+      go(this)
+    }
+
+    def repeatN(n: Int): Process[I,O] = {
+      def go(n: Int, p: Process[I,O]): Process[I,O] = p match {
+        case Halt() => if (n > 0) go(n-1, this) else Halt()
+        case Await(recv) => Await {
+          case None => recv(None)
+          case i => go(n,recv(i))
+        }
+        case Emit(h, t) => Emit(h, go(n,t))
+      }
+      go(n, this)
+    }
+
+    /*
+     * As an example of `repeat`, see `Process.filter`. We define
+     * a convenience function here for composing this `Process`
+     * with a `Process` that filters the output type `O`.
+     */
+    def filter(f: O => Boolean): Process[I,O] =
+      this |> Process.filter(f)
+
+    /** Exercise 7: see definition below. */
+    def zip[O2](p: Process[I,O2]): Process[I,(O,O2)] =
+      Process.zip(this, p)
+
+    /*
+     * Exercise 6: Implement `zipWithIndex`.
+     */
+    def zipWithIndex: Process[I,(O,Int)] =
+      this zip (count map (_ - 1))
+
+    /* Add `p` to the fallback branch of this process */
+    def orElse(p: Process[I,O]): Process[I,O] = this match {
+      case Halt() => p
+      case Await(recv) => Await {
+        case None => p
+        case x => recv(x)
+      }
+      case _ => this
+    }
+  }
+
+  object Process {
+
+    case class Emit[I,O](
+        head: O,
+        tail: Process[I,O] = Halt[I,O]())
+      extends Process[I,O]
+
+    case class Await[I,O](
+        recv: Option[I] => Process[I,O])
+      extends Process[I,O]
+
+    case class Halt[I,O]() extends Process[I,O]
+
+    def emit[I,O](head: O,
+                  tail: Process[I,O] = Halt[I,O]()): Process[I,O] =
+      Emit(head, tail)
+
+    // Process forms a monad, and we provide monad syntax for it
+
+    import fpinscala.iomonad.Monad
+
+    def monad[I]: Monad[({ type f[x] = Process[I,x]})#f] =
+      new Monad[({ type f[x] = Process[I,x]})#f] {
+        def unit[O](o: => O): Process[I,O] = emit(o)
+        def flatMap[O,O2](p: Process[I,O])(f: O => Process[I,O2]): Process[I,O2] =
+          p flatMap f
+      }
+
+    // enable monadic syntax for `Process` type
+    implicit def toMonadic[I,O](a: Process[I,O]) = monad[I].toMonadic(a)
+
+    /**
+     * A helper function to await an element or fall back to another process
+     * if there is no input.
+     */
+    def await[I,O](f: I => Process[I,O],
+                   fallback: Process[I,O] = Halt[I,O]()): Process[I,O] =
+      Await[I,O] {
+        case Some(i) => f(i)
+        case None => fallback
+      }
+
+    /*
+     * We can convert any function `f: I => O` to a `Process[I,O]`. We
+     * simply `Await`, then `Emit` the value received, transformed by
+     * `f`.
+     */
+    def liftOne[I,O](f: I => O): Process[I,O] =
+      Await {
+        case Some(i) => emit(f(i))
+        case None => Halt()
+      }
+
+    def lift[I,O](f: I => O): Process[I,O] =
+      liftOne(f).repeat
+
+    /*
+     * As an example of `repeat`, here's a definition of `filter` that
+     * uses `repeat`.
+     */
+    def filter[I](f: I => Boolean): Process[I,I] =
+      Await[I,I] {
+        case Some(i) if f(i) => emit(i)
+        case _ => Halt()
+      }.repeat
+
+    /*
+     * Here's a typical `Process` definition that requires tracking some
+     * piece of state (in this case, the running total):
+     */
+    def sum: Process[Double,Double] = {
+      def go(acc: Double): Process[Double,Double] =
+        await(d => emit(d+acc, go(d+acc)))
+      go(0.0)
+    }
+
+    /*
+     * Exercise 1: Implement `take`, `drop`, `takeWhile`, and `dropWhile`.
+     */
+    def take[I](n: Int): Process[I,I] =
+      if (n <= 0) Halt()
+      else await(i => emit(i, take[I](n-1)))
+
+    def drop[I](n: Int): Process[I,I] =
+      if (n <= 0) id
+      else await(i => drop[I](n-1))
+
+    def takeWhile[I](f: I => Boolean): Process[I,I] =
+      await(i =>
+        if (f(i)) emit(i, takeWhile(f))
+        else      Halt())
+
+    def dropWhile[I](f: I => Boolean): Process[I,I] =
+      await(i =>
+        if (f(i)) dropWhile(f)
+        else      emit(i,id))
+
+    /* The identity `Process`, just repeatedly echos its input. */
+    def id[I]: Process[I,I] = lift(identity)
+
+    /*
+     * Exercise 2: Implement `count`.
+     *
+     * Here's one implementation, with three stages - we map all inputs
+     * to 1.0, compute a running sum, then finally convert the output
+     * back to `Int`. The three stages will be interleaved - as soon
+     * as the first element is examined, it will be converted to 1.0,
+     * then added to the running total, and then this running total
+     * will be converted back to `Int`, then the `Process` will examine
+     * the next element, and so on.
+     */
+    def count[I]: Process[I,Int] =
+      lift((i: I) => 1.0) |> sum |> lift(_.toInt)
+
+    /* For comparison, here is an explicit recursive implementation. */
+    def count2[I]: Process[I,Int] = {
+      def go(n: Int): Process[I,Int] =
+        await((i: I) => emit(n+1, go(n+1)))
+      go(0)
+    }
+
+    /*
+     * Exercise 3: Implement `mean`.
+     *
+     * This is an explicit recursive definition. We'll factor out a
+     * generic combinator shortly.
+     */
+    def mean: Process[Double,Double] = {
+      def go(sum: Double, count: Double): Process[Double,Double] =
+        await((d: Double) => emit((sum+d) / (count+1), go(sum+d,count+1)))
+      go(0.0, 0.0)
+    }
+
+    def loop[S,I,O](z: S)(f: (I,S) => (O,S)): Process[I,O] =
+      await((i: I) => f(i,z) match {
+        case (o,s2) => emit(o, loop(s2)(f))
+      })
+
+    /* Exercise 4: Implement `sum` and `count` in terms of `loop` */
+
+    def sum2: Process[Double,Double] =
+      loop(0.0)((d:Double, acc) => (acc+d,acc+d))
+
+    def count3[I]: Process[I,Int] =
+      loop(0)((_:I,n) => (n+1,n+1))
+
+    /*
+     * Exercise 7: Can you think of a generic combinator that would
+     * allow for the definition of `mean` in terms of `sum` and
+     * `count`?
+     *
+     * Yes, it is `zip`, which feeds the same input to two processes.
+     * The implementation is a bit tricky, as we have to make sure
+     * that input gets fed to both `p1` and `p2`.
+     */
+    def zip[A,B,C](p1: Process[A,B], p2: Process[A,C]): Process[A,(B,C)] =
+      (p1, p2) match {
+        case (Halt(), _) => Halt()
+        case (_, Halt()) => Halt()
+        case (Emit(b, t1), Emit(c, t2)) => Emit((b,c), zip(t1, t2))
+        case (Await(recv1), _) =>
+          Await((oa: Option[A]) => zip(recv1(oa), feed(oa)(p2)))
+        case (_, Await(recv2)) =>
+          Await((oa: Option[A]) => zip(feed(oa)(p1), recv2(oa)))
+      }
+
+    def feed[A,B](oa: Option[A])(p: Process[A,B]): Process[A,B] =
+      p match {
+        case Halt() => p
+        case Emit(h,t) => Emit(h, feed(oa)(t))
+        case Await(recv) => recv(oa)
+      }
+
+    /*
+     * Using zip, we can then define `mean`. Again, this definition
+     * operates in a single pass.
+     */
+    val mean2 = (sum zip count) |> lift { case (s,n) => s / n }
+
+    /*
+     * Exercise 6: Implement `zipWithIndex`.
+     *
+     * See definition on `Process` above.
+     */
+
+    /*
+     * Exercise 8: Implement `exists`
+     *
+     * We choose to emit all intermediate values, and not halt.
+     * See `existsResult` below for a trimmed version.
+     */
+    def exists[I](f: I => Boolean): Process[I,Boolean] =
+      lift(f) |> any
+
+    /* Emits whether a `true` input has ever been received. */
+    def any: Process[Boolean,Boolean] =
+      loop(false)((b:Boolean,s) => (s || b, s || b))
+
+    /* A trimmed `exists`, containing just the final result. */
+    def existsResult[I](f: I => Boolean) =
+      exists(f) |> takeThrough(!_) |> dropWhile(!_) |> echo.orElse(emit(false))
+
+    /*
+     * Like `takeWhile`, but includes the first element that tests
+     * false.
+     */
+    def takeThrough[I](f: I => Boolean): Process[I,I] =
+      takeWhile(f) ++ echo
+
+    /* Awaits then emits a single value, then halts. */
+    def echo[I]: Process[I,I] = await(i => emit(i))
+
+    def skip[I,O]: Process[I,O] = await(i => Halt())
+    def ignore[I,O]: Process[I,O] = skip.repeat
+
+    def terminated[I]: Process[I,Option[I]] =
+      await((i: I) => emit(Some(i), terminated[I]), emit(None))
+
+    def processFile[A,B](f: java.io.File,
+                         p: Process[String, A],
+                         z: B)(g: (B, A) => B): IO[B] = IO {
+      @annotation.tailrec
+      def go(ss: Iterator[String], cur: Process[String, A], acc: B): B =
+        cur match {
+          case Halt() => acc
+          case Await(recv) =>
+            val next = if (ss.hasNext) recv(Some(ss.next))
+                       else recv(None)
+            go(ss, next, acc)
+          case Emit(h, t) => go(ss, t, g(acc, h))
+        }
+      val s = io.Source.fromFile(f)
+      try go(s.getLines, p, z)
+      finally s.close
+    }
+
+    /*
+     * Exercise 9: Write a program that reads degrees fahrenheit as `Double` values from a file,
+     * converts each temperature to celsius, and writes results to another file.
+     */
+
+    // This process defines the here is core logic, a transducer that converts input lines
+    // (assumed to be temperatures in degrees fahrenheit) to output lines (temperatures in
+    // degress celsius). Left as an exercise to supply another wrapper like `processFile`
+    // to actually do the IO and drive the process.
+    def convertFahrenheit: Process[String,String] =
+      filter((line: String) => !line.startsWith("#")) |>
+      filter(line => line.trim.nonEmpty) |>
+      lift(line => toCelsius(line.toDouble).toString)
+
+    def toCelsius(fahrenheit: Double): Double =
+      (5.0 / 9.0) * (fahrenheit - 32.0)
+  }
+}
+
+object GeneralizedStreamTransducers {
+
+                            /*
+
+  Our generalized process type is parameterized on the protocol used for
+  communicating with the driver. This works similarly to the `IO` type
+  we defined in chapter 13. The `Await` constructor emits a request of
+  type `F[A]`, and receives a response of type `Either[Throwable,A]`:
+
+    trait Process[F,A]
+    case class Await[F[_],A,O](
+      req: F[A],
+      recv: Either[Throwable,A] => Process[F,O]) extends Process[F,O]
+    case class Halt[F[_],O](err: Throwable) extends Process[F,O]
+    case class Emit[F[_],O](head: O, tail: Process[F,O]) extends Process[F,O]
+
+  The `Await` constructor may now receive a successful result or an error.
+
+  The `Halt` constructor now has a _reason_ for termination, which may be
+  either normal termination indicated by the special exception `End`,
+  forceful terimation, indicated by the special exception `Kill`,
+  or some other error.
+
+  We'll use the improved `Await` and `Halt` cases together to ensure
+  that all resources get released, even in the event of exceptions.
+
+                             */
+
+  trait Process[F[_],O] {
+    import Process._
+
+    /*
+     * Many of the same operations can be defined for this generalized
+     * `Process` type, regardless of the choice of `F`.
+     */
+
+    def map[O2](f: O => O2): Process[F,O2] = this match {
+      case Await(req,recv) =>
+        Await(req, recv andThen (_ map f))
+      case Emit(h, t) => Try { Emit(f(h), t map f) }
+      case Halt(err) => Halt(err)
+    }
+
+    def ++(p: => Process[F,O]): Process[F,O] =
+      this.onHalt {
+        case End => Try(p) // we consult `p` only on normal termination
+        case err => Halt(err)
+      }
+
+    /*
+     * Like `++`, but _always_ runs `p`, even if `this` halts with an error.
+     */
+    def onComplete(p: => Process[F,O]): Process[F,O] =
+      this.onHalt {
+        case End => p.asFinalizer
+        case err => p.asFinalizer ++ Halt(err) // we always run `p`, but preserve any errors
+      }
+
+    def asFinalizer: Process[F,O] = this match {
+      case Emit(h, t) => Emit(h, t.asFinalizer)
+      case Halt(e) => Halt(e)
+      case Await(req,recv) => await(req) {
+        case Left(Kill) => this.asFinalizer
+        case x => recv(x)
+      }
+    }
+
+    def onHalt(f: Throwable => Process[F,O]): Process[F,O] = this match {
+      case Halt(e) => Try(f(e))
+      case Emit(h, t) => Emit(h, t.onHalt(f))
+      case Await(req,recv) => Await(req, recv andThen (_.onHalt(f)))
+    }
+
+    /*
+     * Anywhere we _call_ `f`, we catch exceptions and convert them to `Halt`.
+     * See the helper function `Try` defined below.
+     */
+    def flatMap[O2](f: O => Process[F,O2]): Process[F,O2] =
+      this match {
+        case Halt(err) => Halt(err)
+        case Emit(o, t) => Try(f(o)) ++ t.flatMap(f)
+        case Await(req,recv) =>
+          Await(req, recv andThen (_ flatMap f))
+      }
+
+    def repeat: Process[F,O] =
+      this ++ this.repeat
+
+    def repeatNonempty: Process[F,O] = {
+      val cycle = (this.map(o => Some(o): Option[O]) ++ emit(None)).repeat
+      // cut off the cycle when we see two `None` values in a row, as this
+      // implies `this` has produced no values during an iteration
+      val trimmed = cycle |> window2 |> (takeWhile {
+        case (Some(None), None) => false
+        case _ => true
+      })
+      trimmed.map(_._2).flatMap {
+        case None => Halt(End)
+        case Some(o) => emit(o)
+      }
+    }
+
+    /*
+     * Exercise 10: This function is defined only if given a `MonadCatch[F]`.
+     * Unlike the simple `runLog` interpreter defined in the companion object
+     * below, this is not tail recursive and responsibility for stack safety
+     * is placed on the `Monad` instance.
+     */
+    def runLog(implicit F: MonadCatch[F]): F[IndexedSeq[O]] = {
+      def go(cur: Process[F,O], acc: IndexedSeq[O]): F[IndexedSeq[O]] =
+        cur match {
+          case Emit(h,t) => go(t, acc :+ h)
+          case Halt(End) => F.unit(acc)
+          case Halt(err) => F.fail(err)
+          case Await(req,recv) => F.flatMap (F.attempt(req)) { e => go(Try(recv(e)), acc) }
+        }
+      go(this, IndexedSeq())
+    }
+
+    /*
+     * We define `Process1` as a type alias - see the companion object
+     * for `Process` below. Using that, we can then define `|>` once
+     * more. The definition is extremely similar to our previous
+     * definition. We again use the helper function, `feed`, to take
+     * care of the case where `this` is emitting values while `p2`
+     * is awaiting these values.
+     *
+     * The one subtlety is we make sure that if `p2` halts, we
+     * `kill` this process, giving it a chance to run any cleanup
+     * actions (like closing file handles, etc).
+     */
+    def |>[O2](p2: Process1[O,O2]): Process[F,O2] = {
+      p2 match {
+        case Halt(e) => this.kill onHalt { e2 => Halt(e) ++ Halt(e2) }
+        case Emit(h, t) => Emit(h, this |> t)
+        case Await(req,recv) => this match {
+          case Halt(err) => Halt(err) |> recv(Left(err))
+          case Emit(h,t) => t |> Try(recv(Right(h)))
+          case Await(req0,recv0) => await(req0)(recv0 andThen (_ |> p2))
+        }
+      }
+    }
+
+    @annotation.tailrec
+    final def kill[O2]: Process[F,O2] = this match {
+      case Await(req,recv) => recv(Left(Kill)).drain.onHalt {
+        case Kill => Halt(End) // we convert the `Kill` exception back to normal termination
+        case e => Halt(e)
+      }
+      case Halt(e) => Halt(e)
+      case Emit(h, t) => t.kill
+    }
+
+    /** Alias for `this |> p2`. */
+    def pipe[O2](p2: Process1[O,O2]): Process[F,O2] =
+      this |> p2
+
+    final def drain[O2]: Process[F,O2] = this match {
+      case Halt(e) => Halt(e)
+      case Emit(h, t) => t.drain
+      case Await(req,recv) => Await(req, recv andThen (_.drain))
+    }
+
+    def filter(f: O => Boolean): Process[F,O] =
+      this |> Process.filter(f)
+
+    def take(n: Int): Process[F,O] =
+      this |> Process.take(n)
+
+    def once: Process[F,O] = take(1)
+
+    /*
+     * Use a `Tee` to interleave or combine the outputs of `this` and
+     * `p2`. This can be used for zipping, interleaving, and so forth.
+     * Nothing requires that the `Tee` read elements from each
+     * `Process` in lockstep. It could read fifty elements from one
+     * side, then two elements from the other, then combine or
+     * interleave these values in some way, etc.
+     *
+     * This definition uses two helper functions, `feedL` and `feedR`,
+     * which feed the `Tee` in a tail-recursive loop as long as
+     * it is awaiting input.
+     */
+    def tee[O2,O3](p2: Process[F,O2])(t: Tee[O,O2,O3]): Process[F,O3] = {
+      t match {
+        case Halt(e) => this.kill onComplete p2.kill onComplete Halt(e)
+        case Emit(h,t) => Emit(h, (this tee p2)(t))
+        case Await(side, recv) => side.get match {
+          case Left(isO) => this match {
+            case Halt(e) => p2.kill onComplete Halt(e)
+            case Emit(o,ot) => (ot tee p2)(Try(recv(Right(o))))
+            case Await(reqL, recvL) =>
+              await(reqL)(recvL andThen (this2 => this2.tee(p2)(t)))
+          }
+          case Right(isO2) => p2 match {
+            case Halt(e) => this.kill onComplete Halt(e)
+            case Emit(o2,ot) => (this tee ot)(Try(recv(Right(o2))))
+            case Await(reqR, recvR) =>
+              await(reqR)(recvR andThen (p3 => this.tee(p3)(t)))
+          }
+        }
+      }
+    }
+
+    def zipWith[O2,O3](p2: Process[F,O2])(f: (O,O2) => O3): Process[F,O3] =
+      (this tee p2)(Process.zipWith(f))
+
+    def zip[O2](p2: Process[F,O2]): Process[F,(O,O2)] =
+      zipWith(p2)((_,_))
+
+    def to[O2](sink: Sink[F,O]): Process[F,Unit] =
+      join { (this zipWith sink)((o,f) => f(o)) }
+
+    def through[O2](p2: Channel[F, O, O2]): Process[F,O2] =
+      join { (this zipWith p2)((o,f) => f(o)) }
+  }
+
+  object Process {
+    case class Await[F[_],A,O](
+      req: F[A],
+      recv: Either[Throwable,A] => Process[F,O]) extends Process[F,O]
+
+    case class Emit[F[_],O](
+      head: O,
+      tail: Process[F,O]) extends Process[F,O]
+
+    case class Halt[F[_],O](err: Throwable) extends Process[F,O]
+
+    def emit[F[_],O](
+        head: O,
+        tail: Process[F,O] = Halt[F,O](End)): Process[F,O] =
+      Emit(head, tail)
+
+    def await[F[_],A,O](req: F[A])(recv: Either[Throwable,A] => Process[F,O]): Process[F,O] =
+      Await(req, recv)
+
+    /**
+     * Helper function to safely produce `p`, or gracefully halt
+     * with an error if an exception is thrown.
+     */
+    def Try[F[_],O](p: => Process[F,O]): Process[F,O] =
+      try p
+      catch { case e: Throwable => Halt(e) }
+
+    /*
+     * Safely produce `p`, or run `cleanup` and halt gracefully with the
+     * exception thrown while evaluating `p`.
+     */
+    def TryOr[F[_],O](p: => Process[F,O])(cleanup: Process[F,O]): Process[F,O] =
+      try p
+      catch { case e: Throwable => cleanup ++ Halt(e) }
+
+    /*
+     * Safely produce `p`, or run `cleanup` or `fallback` if an exception
+     * occurs while evaluating `p`.
+     */
+    def TryAwait[F[_],O](p: => Process[F,O])(fallback: Process[F,O], cleanup: Process[F,O]): Process[F,O] =
+      try p
+      catch {
+        case End => fallback
+        case e: Throwable => cleanup ++ Halt(e)
+      }
+
+    /* Our generalized `Process` type can represent sources! */
+
+    import fpinscala.iomonad.IO
+
+    /* Special exception indicating normal termination */
+    case object End extends Exception
+
+    /* Special exception indicating forceful termination */
+    case object Kill extends Exception
+
+    /*
+     * A `Process[F,O]` where `F` is a monad like `IO` can be thought of
+     * as a source.
+     */
+
+    /*
+     * Here is a simple tail recursive function to collect all the
+     * output of a `Process[IO,O]`. Notice we are using the fact
+     * that `IO` can be `run` to produce either a result or an
+     * exception.
+     */
+    def runLog[O](src: Process[IO,O]): IO[IndexedSeq[O]] = IO {
+      val E = java.util.concurrent.Executors.newFixedThreadPool(4)
+      @annotation.tailrec
+      def go(cur: Process[IO,O], acc: IndexedSeq[O]): IndexedSeq[O] =
+        cur match {
+          case Emit(h,t) => go(t, acc :+ h)
+          case Halt(End) => acc
+          case Halt(err) => throw err
+          case Await(req,recv) =>
+            val next =
+              try recv(Right(fpinscala.iomonad.unsafePerformIO(req)(E)))
+              catch { case err: Throwable => recv(Left(err)) }
+            go(next, acc)
+        }
+      try go(src, IndexedSeq())
+      finally E.shutdown
+    }
+
+    /*
+     * We can write a version of collect that works for any `Monad`.
+     * See the definition in the body of `Process`.
+     */
+
+    import java.io.{BufferedReader,FileReader}
+    val p: Process[IO, String] =
+      await(IO(new BufferedReader(new FileReader("lines.txt")))) {
+        case Right(b) =>
+          lazy val next: Process[IO,String] = await(IO(b.readLine)) {
+            case Left(e) => await(IO(b.close))(_ => Halt(e))
+            case Right(line) => Emit(line, next)
+          }
+          next
+        case Left(e) => Halt(e)
+      }
+
+    /*
+     * Generic combinator for producing a `Process[IO,O]` from some
+     * effectful `O` source. The source is tied to some resource,
+     * `R` (like a file handle) that we want to ensure is released.
+     * See `lines` below for an example use.
+     */
+    def resource[R,O](acquire: IO[R])(
+                      use: R => Process[IO,O])(
+                      release: R => Process[IO,O]): Process[IO,O] =
+      eval(acquire) flatMap { r => use(r).onComplete(release(r)) }
+
+    /*
+     * Like `resource`, but `release` is a single `IO` action.
+     */
+    def resource_[R,O](acquire: IO[R])(
+                       use: R => Process[IO,O])(
+                       release: R => IO[Unit]): Process[IO,O] =
+      resource(acquire)(use)(release andThen (eval_[IO,Unit,O]))
+
+    /*
+     * Create a `Process[IO,O]` from the lines of a file, using
+     * the `resource` combinator above to ensure the file is closed
+     * when processing the stream of lines is finished.
+     */
+    def lines(filename: String): Process[IO,String] =
+      resource
+        { IO(io.Source.fromFile(filename)) }
+        { src =>
+            lazy val iter = src.getLines // a stateful iterator
+            def step = if (iter.hasNext) Some(iter.next) else None
+            lazy val lines: Process[IO,String] = eval(IO(step)).flatMap {
+              case None => Halt(End)
+              case Some(line) => Emit(line, lines)
+            }
+            lines
+        }
+        { src => eval_ { IO(src.close) } }
+
+    /* Exercise 11: Implement `eval`, `eval_`, and use these to implement `lines`. */
+    def eval[F[_],A](a: F[A]): Process[F,A] =
+      await[F,A,A](a) {
+        case Left(err) => Halt(err)
+        case Right(a) => Emit(a, Halt(End))
+      }
+
+    /* Evaluate the action purely for its effects. */
+    def eval_[F[_],A,B](a: F[A]): Process[F,B] =
+      eval[F,A](a).drain[B]
+
+    /* Helper function with better type inference. */
+    def evalIO[A](a: IO[A]): Process[IO,A] =
+      eval[IO,A](a)
+
+    /*
+     * We now have nice, resource safe effectful sources, but we don't
+     * have any way to transform them or filter them. Luckily we can
+     * still represent the single-input `Process` type we introduced
+     * earlier, which we'll now call `Process1`.
+     */
+
+    case class Is[I]() {
+      sealed trait f[X]
+      val Get = new f[I] {}
+    }
+    def Get[I] = Is[I]().Get
+
+    type Process1[I,O] = Process[Is[I]#f, O]
+
+    /* Some helper functions to improve type inference. */
+
+    def await1[I,O](
+        recv: I => Process1[I,O],
+        fallback: => Process1[I,O] = halt1[I,O]): Process1[I, O] =
+      Await(Get[I], (e: Either[Throwable,I]) => e match {
+        case Left(End) => fallback
+        case Left(err) => Halt(err)
+        case Right(i) => Try(recv(i))
+      })
+
+    def emit1[I,O](h: O, tl: Process1[I,O] = halt1[I,O]): Process1[I,O] =
+      emit(h, tl)
+
+    def halt1[I,O]: Process1[I,O] = Halt[Is[I]#f, O](End)
+
+    def lift[I,O](f: I => O): Process1[I,O] =
+      await1[I,O]((i:I) => emit(f(i))) repeat
+
+    def filter[I](f: I => Boolean): Process1[I,I] =
+      await1[I,I](i => if (f(i)) emit(i) else halt1) repeat
+
+    // we can define take, takeWhile, and so on as before
+
+    def take[I](n: Int): Process1[I,I] =
+      if (n <= 0) halt1
+      else await1[I,I](i => emit(i, take(n-1)))
+
+    def takeWhile[I](f: I => Boolean): Process1[I,I] =
+      await1(i =>
+        if (f(i)) emit(i, takeWhile(f))
+        else      halt1)
+
+    def dropWhile[I](f: I => Boolean): Process1[I,I] =
+      await1(i =>
+        if (f(i)) dropWhile(f)
+        else      emit(i,id))
+
+    def id[I]: Process1[I,I] =
+      await1((i: I) => emit(i, id))
+
+    def window2[I]: Process1[I,(Option[I],I)] = {
+      def go(prev: Option[I]): Process1[I,(Option[I],I)] =
+        await1[I,(Option[I],I)](i => emit(prev -> i) ++ go(Some(i)))
+      go(None)
+    }
+
+    /** Emits `sep` in between each input received. */
+    def intersperse[I](sep: I): Process1[I,I] =
+      await1[I,I](i => emit1(i) ++ id.flatMap(i => emit1(sep) ++ emit1(i)))
+
+                            /*
+
+    We sometimes need to construct a `Process` that will pull values
+    from multiple input sources. For instance, suppose we want to
+    'zip' together two files, `f1.txt` and `f2.txt`, combining
+    corresponding lines in some way. Using the same trick we used for
+    `Process1`, we can create a two-input `Process` which can request
+    values from either the 'left' stream or the 'right' stream. We'll
+    call this a `Tee`, after the letter 'T', which looks like a
+    little diagram of two inputs being combined into one output.
+
+                             */
+
+    case class T[I,I2]() {
+      sealed trait f[X] { def get: Either[I => X, I2 => X] }
+      val L = new f[I] { def get = Left(identity) }
+      val R = new f[I2] { def get = Right(identity) }
+    }
+    def L[I,I2] = T[I,I2]().L
+    def R[I,I2] = T[I,I2]().R
+
+    type Tee[I,I2,O] = Process[T[I,I2]#f, O]
+
+    /* Again some helper functions to improve type inference. */
+
+    def haltT[I,I2,O]: Tee[I,I2,O] =
+      Halt[T[I,I2]#f,O](End)
+
+    def awaitL[I,I2,O](recv: I => Tee[I,I2,O],
+                       fallback: => Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
+      await[T[I,I2]#f,I,O](L) {
+        case Left(End) => fallback
+        case Left(err) => Halt(err)
+        case Right(a) => Try(recv(a))
+      }
+
+    def awaitR[I,I2,O](recv: I2 => Tee[I,I2,O],
+                       fallback: => Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
+      await[T[I,I2]#f,I2,O](R) {
+        case Left(End) => fallback
+        case Left(err) => Halt(err)
+        case Right(a) => Try(recv(a))
+      }
+
+    def emitT[I,I2,O](h: O, tl: Tee[I,I2,O] = haltT[I,I2,O]): Tee[I,I2,O] =
+      emit(h, tl)
+
+    def zipWith[I,I2,O](f: (I,I2) => O): Tee[I,I2,O] =
+      awaitL[I,I2,O](i  =>
+      awaitR        (i2 => emitT(f(i,i2)))) repeat
+
+    def zip[I,I2]: Tee[I,I2,(I,I2)] = zipWith((_,_))
+
+    /* Ignores all input from left. */
+    def passR[I,I2]: Tee[I,I2,I2] = awaitR(emitT(_, passR))
+
+    /* Ignores input from the right. */
+    def passL[I,I2]: Tee[I,I2,I] = awaitL(emitT(_, passL))
+
+    /* Alternate pulling values from the left and the right inputs. */
+    def interleaveT[I]: Tee[I,I,I] =
+      awaitL[I,I,I](i =>
+      awaitR       (i2 => emitT(i) ++ emitT(i2))) repeat
+
+                            /*
+
+    Our `Process` type can also represent effectful sinks (like a file).
+    A `Sink` is simply a source of effectful functions! See the
+    definition of `to` in `Process` for an example of how to feed a
+    `Process` to a `Sink`.
+
+                             */
+
+    type Sink[F[_],O] = Process[F, O => Process[F,Unit]]
+
+    import java.io.FileWriter
+
+    /* A `Sink` which writes input strings to the given file. */
+    def fileW(file: String, append: Boolean = false): Sink[IO,String] =
+      resource[FileWriter, String => Process[IO,Unit]]
+        { IO { new FileWriter(file, append) }}
+        { w => constant { (s: String) => eval[IO,Unit](IO(w.write(s))) }}
+        { w => eval_(IO(w.close)) }
+
+    /* The infinite, constant stream. */
+    def constant[A](a: A): Process[IO,A] =
+      eval(IO(a)).flatMap { a => Emit(a, constant(a)) }
+
+    /* Exercise 12: Implement `join`. Notice this is the standard monadic combinator! */
+    def join[F[_],A](p: Process[F,Process[F,A]]): Process[F,A] =
+      p.flatMap(pa => pa)
+
+    /*
+     * An example use of the combinators we have so far: incrementally
+     * convert the lines of a file from fahrenheit to celsius.
+     */
+
+    import fpinscala.iomonad.IO0.fahrenheitToCelsius
+
+    val converter: Process[IO,Unit] =
+      lines("fahrenheit.txt").
+      filter(line => !line.startsWith("#") && !line.trim.isEmpty).
+      map(line => fahrenheitToCelsius(line.toDouble).toString).
+      pipe(intersperse("\n")).
+      to(fileW("celsius.txt")).
+      drain
+
+                            /*
+
+    More generally, we can feed a `Process` through an effectful
+    channel which returns a value other than `Unit`.
+
+                             */
+
+    type Channel[F[_],I,O] = Process[F, I => Process[F,O]]
+
+    /*
+     * Here is an example, a JDBC query runner which returns the
+     * stream of rows from the result set of the query. We have
+     * the channel take a `Connection => PreparedStatement` as
+     * input, so code that uses this channel does not need to be
+     * responsible for knowing how to obtain a `Connection`.
+     */
+    import java.sql.{Connection, PreparedStatement, ResultSet}
+
+    def query(conn: IO[Connection]):
+        Channel[IO, Connection => PreparedStatement, Map[String,Any]] =
+      resource_
+        { conn }
+        { conn => constant { (q: Connection => PreparedStatement) =>
+          resource_
+            { IO {
+                val rs = q(conn).executeQuery
+                val ncols = rs.getMetaData.getColumnCount
+                val cols = (1 to ncols).map(rs.getMetaData.getColumnName)
+                (rs, cols)
+            }}
+            { case (rs, cols) =>
+                def step =
+                  if (!rs.next) None
+                  else Some(cols.map(c => (c, rs.getObject(c): Any)).toMap)
+                lazy val rows: Process[IO,Map[String,Any]] =
+                  eval(IO(step)).flatMap {
+                    case None => Halt(End)
+                    case Some(row) => Emit(row, rows)
+                  }
+                rows
+            }
+            { p => IO { p._1.close } } // close the ResultSet
+        }}
+        { c => IO(c.close) }
+
+    /*
+     * We can allocate resources dynamically when defining a `Process`.
+     * As an example, this program reads a list of filenames to process
+     * _from another file_, opening each file, processing it and closing
+     * it promptly.
+     */
+
+    val convertAll: Process[IO,Unit] = (for {
+      out <- fileW("celsius.txt").once
+      file <- lines("fahrenheits.txt")
+      _ <- lines(file).
+           map(line => fahrenheitToCelsius(line.toDouble)).
+           flatMap(celsius => out(celsius.toString))
+    } yield ()) drain
+
+    /*
+     * Just by switching the order of the `flatMap` calls, we can output
+     * to multiple files.
+     */
+    val convertMultisink: Process[IO,Unit] = (for {
+      file <- lines("fahrenheits.txt")
+      _ <- lines(file).
+           map(line => fahrenheitToCelsius(line.toDouble)).
+           map(_ toString).
+           to(fileW(file + ".celsius"))
+    } yield ()) drain
+
+    /*
+     * We can attach filters or other transformations at any point in the
+     * program, for example:
+     */
+    val convertMultisink2: Process[IO,Unit] = (for {
+      file <- lines("fahrenheits.txt")
+      _ <- lines(file).
+           filter(!_.startsWith("#")).
+           map(line => fahrenheitToCelsius(line.toDouble)).
+           filter(_ > 0). // ignore below zero temperatures
+           map(_ toString).
+           to(fileW(file + ".celsius"))
+    } yield ()) drain
+  }
+}
+
+object ProcessTest extends App {
+  import GeneralizedStreamTransducers._
+  import fpinscala.iomonad.IO
+  import Process._
+
+  val p = eval(IO { println("woot"); 1 }).repeat
+  val p2 = eval(IO { println("cleanup"); 2 } ).onHalt {
+    case Kill => println { "cleanup was killed, instead of bring run" }; Halt(Kill)
+    case e => Halt(e)
+  }
+
+  println { Process.runLog { p2.onComplete(p2).onComplete(p2).take(1).take(1) } }
+  println { Process.runLog(converter) }
+  // println { Process.collect(Process.convertAll) }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/streamingio/These.scala b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/These.scala
new file mode 100644
index 0000000..ade1a0b
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/streamingio/These.scala
@@ -0,0 +1,48 @@
+package fpinscala.streamingio
+
+import language.postfixOps
+
+/* Data type representing either A, B, or both A and B. */
+trait These[+A,+B] {
+  import These._
+
+  def bimap[A2,B2](f: A => A2, g: B => B2): These[A2,B2] = 
+    this match {
+      case This(a) => This(f(a)) 
+      case That(b) => That(g(b)) 
+      case Both(a,b) => Both(f(a), g(b)) 
+    }
+
+  def mapL[A2,B2>:B](f: A => A2): These[A2,B2] = 
+    bimap(f, identity)
+
+  def mapR[A2>:A,B2](f: B => B2): These[A2,B2] = 
+    bimap(identity, f)
+
+  def isBoth = this match {
+    case Both(_,_) => true
+    case _ => false
+  }
+}
+
+object These {
+  case class This[+A](a: A) extends These[A,Nothing]
+  case class That[+B](b: B) extends These[Nothing,B]
+  case class Both[+A,+B](a: A, b: B) extends These[A,B]
+
+  def zipAll[A,B,C](a: Seq[A], b: Seq[B]): Stream[These[A,B]] = 
+    if (a isEmpty) b.toStream.map(That(_))
+    else if (b isEmpty) a.toStream.map(This(_))
+    else Both(a.head, b.head) #:: zipAll(a.tail, b.tail)
+  
+  /* 
+   * Zips together the two `Seq`s, returning the remaining elemnts 
+   * of each (possibly empty). 
+   */
+  def zipResidual[A,B,C](a: Seq[A], b: Seq[B]): 
+     (Seq[(A,B)], Seq[A], Seq[B]) = {
+    val z = a zip b
+    val len = z.length
+    (z, a drop len, b drop len)
+  }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/testing/Exhaustive.scala b/src/main/scala/answers/src/main/scala/fpinscala/testing/Exhaustive.scala
new file mode 100644
index 0000000..476d71a
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/testing/Exhaustive.scala
@@ -0,0 +1,419 @@
+package fpinscala.testing.exhaustive
+
+import language.implicitConversions
+import language.postfixOps
+
+/*
+This source file contains the answers to the last two exercises in the section
+"Test Case Minimization" of chapter 8 on property-based testing.
+
+The Gen data type in this file incorporates exhaustive checking of finite domains.
+*/
+
+import fpinscala.laziness.{Stream,Cons,Empty}
+import fpinscala.state._
+import fpinscala.parallelism._
+import fpinscala.parallelism.Par.Par
+import Gen._
+import Prop._
+import Status._
+import java.util.concurrent.{Executors,ExecutorService}
+
+
+case class Prop(run: (MaxSize,TestCases,RNG) => Result) {
+  def &&(p: Prop) = Prop {
+    (max,n,rng) => run(max,n,rng) match {
+      case Right((a,n)) => p.run(max,n,rng).right.map { case (s,m) => (s,n+m) }
+      case l => l
+    }
+  }
+  def ||(p: Prop) = Prop {
+    (max,n,rng) => run(max,n,rng) match {
+      case Left(msg) => p.tag(msg).run(max,n,rng)
+      case r => r
+    }
+  }
+  /* This is rather simplistic - in the event of failure, we simply prepend
+   * the given message on a newline in front of the existing message.
+   */
+  def tag(msg: String) = Prop {
+    (max,n,rng) => run(max,n,rng) match {
+      case Left(e) => Left(msg + "\n" + e)
+      case r => r
+    }
+  }
+}
+
+object Prop {
+  type TestCases = Int
+  type MaxSize = Int
+  type FailedCase = String
+  type Result = Either[FailedCase,(Status,TestCases)]
+  def forAll[A](a: Gen[A])(f: A => Boolean): Prop = Prop {
+    (n,rng) => {
+      def go(i: Int, j: Int, s: Stream[Option[A]], onEnd: Int => Result): Result =
+        if (i == j) Right((Unfalsified, i))
+        else s match {
+          case Cons(h,t) => h() match {
+            case Some(h) =>
+              try {
+                if (f(h)) go(i+1,j,t(),onEnd)
+                else Left(h.toString) }
+              catch { case e: Exception => Left(buildMsg(h, e)) }
+            case None => Right((Unfalsified,i))
+          }
+          case _ => onEnd(i)
+        }
+      go(0, n/3, a.exhaustive, i => Right((Proven, i))) match {
+        case Right((Unfalsified,_)) =>
+          val rands = randomStream(a)(rng).map(Some(_))
+          go(n/3, n, rands, i => Right((Unfalsified, i)))
+        case s => s // If proven or failed, stop immediately
+      }
+    }
+  }
+
+  def buildMsg[A](s: A, e: Exception): String =
+    "test case: " + s + "\n" +
+    "generated an exception: " + e.getMessage + "\n" +
+    "stack trace:\n" + e.getStackTrace.mkString("\n")
+
+  def apply(f: (TestCases,RNG) => Result): Prop =
+    Prop { (_,n,rng) => f(n,rng) }
+
+  /* We pattern match on the `SGen`, and delegate to our `Gen` version of `forAll`
+   * if `g` is unsized; otherwise, we call the sized version of `forAll` (below).
+   */
+  def forAll[A](g: SGen[A])(f: A => Boolean): Prop = g match {
+    case Unsized(g2) => forAll(g2)(f)
+    case Sized(gs) => forAll(gs)(f)
+  }
+
+  /* The sized case of `forAll` is as before, though we convert from `Proven` to
+   * `Exhausted`. A sized generator can never be proven, since there are always
+   * larger-sized tests that were not run which may have failed.
+   */
+  def forAll[A](g: Int => Gen[A])(f: A => Boolean): Prop = Prop {
+    (max,n,rng) =>
+      val casesPerSize = n / max + 1
+      val props: List[Prop] =
+        Stream.from(0).take(max+1).map(i => forAll(g(i))(f)).toList
+      val p: Prop = props.map(p => Prop((max,n,rng) => p.run(max,casesPerSize,rng))).
+            reduceLeft(_ && _)
+      p.run(max,n,rng).right.map {
+        case (Proven,n) => (Exhausted,n)
+        case x => x
+      }
+  }
+
+  def run(p: Prop,
+          maxSize: Int = 100, // A default argument of `200`
+          testCases: Int = 100,
+          rng: RNG = RNG.Simple(System.currentTimeMillis)): Unit = {
+    p.run(maxSize, testCases, rng) match {
+      case Left(msg) => println("! test failed:\n" + msg)
+      case Right((Unfalsified,n)) =>
+        println("+ property unfalsified, ran " + n + " tests")
+      case Right((Proven,n)) =>
+        println("+ property proven, ran " + n + " tests")
+      case Right((Exhausted,n)) =>
+        println("+ property unfalsified up to max size, ran " +
+                 n + " tests")
+    }
+  }
+
+  val ES: ExecutorService = Executors.newCachedThreadPool
+  val p1 = Prop.forAll(Gen.unit(Par.unit(1)))(i =>
+    Par.map(i)(_ + 1)(ES).get == Par.unit(2)(ES).get)
+
+  def check(p: => Boolean): Prop = // Note that we are non-strict here
+    forAll(unit(()))(_ => p)
+
+  val p2 = check {
+    val p = Par.map(Par.unit(1))(_ + 1)
+    val p2 = Par.unit(2)
+    p(ES).get == p2(ES).get
+  }
+
+  def equal[A](p: Par[A], p2: Par[A]): Par[Boolean] =
+    Par.map2(p,p2)(_ == _)
+
+  val p3 = check {
+    equal (
+      Par.map(Par.unit(1))(_ + 1),
+      Par.unit(2)
+    ) (ES) get
+  }
+
+  val S = weighted(
+    choose(1,4).map(Executors.newFixedThreadPool) -> .75,
+    unit(Executors.newCachedThreadPool) -> .25) // `a -> b` is syntax sugar for `(a,b)`
+
+  def forAllPar[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
+    forAll(S.map2(g)((_,_))) { case (s,a) => f(a)(s).get }
+
+  def checkPar(p: Par[Boolean]): Prop =
+    forAllPar(Gen.unit(()))(_ => p)
+
+  def forAllPar2[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
+    forAll(S ** g) { case (s,a) => f(a)(s).get }
+
+  def forAllPar3[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
+    forAll(S ** g) { case s ** a => f(a)(s).get }
+
+  val pint = Gen.choose(0,10) map (Par.unit(_))
+  val p4 =
+    forAllPar(pint)(n => equal(Par.map(n)(y => y), n))
+
+  val forkProp = Prop.forAllPar(pint2)(i => equal(Par.fork(i), i)) tag "fork"
+}
+
+sealed trait Status {}
+
+object Status {
+  case object Exhausted extends Status
+  case object Proven extends Status
+  case object Unfalsified extends Status
+}
+
+/*
+The `Gen` type now has a random generator as well as an exhaustive stream.
+Infinite domains will simply generate infinite streams of None.
+A finite domain is exhausted when the stream reaches empty.
+*/
+case class Gen[+A](sample: State[RNG,A], exhaustive: Stream[Option[A]]) {
+  def map[B](f: A => B): Gen[B] =
+    Gen(sample.map(f), exhaustive.map(_.map(f)))
+
+  def map2[B,C](g: Gen[B])(f: (A,B) => C): Gen[C] =
+    Gen(sample.map2(g.sample)(f),
+        map2Stream(exhaustive,g.exhaustive)(map2Option(_,_)(f)))
+
+  def flatMap[B](f: A => Gen[B]): Gen[B] =
+    Gen(sample.flatMap(a => f(a).sample),
+        exhaustive.flatMap {
+          case None => unbounded
+          case Some(a) => f(a).exhaustive
+        })
+
+  /* A method alias for the function we wrote earlier. */
+  def listOfN(size: Int): Gen[List[A]] =
+    Gen.listOfN(size, this)
+
+  /* A version of `listOfN` that generates the size to use dynamically. */
+  def listOfN(size: Gen[Int]): Gen[List[A]] =
+    size flatMap (n => this.listOfN(n))
+
+  def listOf: SGen[List[A]] = Gen.listOf(this)
+  def listOf1: SGen[List[A]] = Gen.listOf1(this)
+
+  def unsized = Unsized(this)
+
+  def **[B](g: Gen[B]): Gen[(A,B)] =
+    (this map2 g)((_,_))
+}
+
+object Gen {
+  type Domain[+A] = Stream[Option[A]]
+
+  def bounded[A](a: Stream[A]): Domain[A] = a map (Some(_))
+  def unbounded: Domain[Nothing] = Stream(None)
+
+  def unit[A](a: => A): Gen[A] =
+    Gen(State.unit(a), bounded(Stream(a)))
+
+  def boolean: Gen[Boolean] =
+    Gen(State(RNG.boolean), bounded(Stream(true,false)))
+
+  def choose(start: Int, stopExclusive: Int): Gen[Int] =
+    Gen(State(RNG.nonNegativeInt).map(n => start + n % (stopExclusive-start)),
+        bounded(Stream.from(start).take(stopExclusive-start)))
+
+  /* This implementation is rather tricky, but almost impossible to get wrong
+   * if you follow the types. It relies on several helper functions (see below).
+   */
+  def listOfN[A](n: Int, g: Gen[A]): Gen[List[A]] =
+    Gen(State.sequence(List.fill(n)(g.sample)),
+        cartesian(Stream.constant(g.exhaustive).take(n)).
+        map(l => sequenceOption(l.toList)))
+
+  /* `cartesian` generates all possible combinations of a `Stream[Stream[A]]`. For instance:
+   *
+   *    cartesian(Stream(Stream(1,2), Stream(3), Stream(4,5))) ==
+   *    Stream(Stream(1,3,4), Stream(1,3,5), Stream(2,3,4), Stream(2,3,5))
+  */
+  def cartesian[A](s: Stream[Stream[A]]): Stream[Stream[A]] =
+    s.foldRight(Stream(Stream[A]()))((hs,ts) => map2Stream(hs,ts)(Stream.cons(_,_)))
+
+  /* `map2Option` and `map2Stream`. Notice the duplication! */
+  def map2Option[A,B,C](oa: Option[A], ob: Option[B])(f: (A,B) => C): Option[C] =
+    for { a <- oa; b <- ob } yield f(a,b)
+
+  /* This is not the same as `zipWith`, a function we've implemented before.
+   * We are generating all (A,B) combinations and using each to produce a `C`.
+   * This implementation desugars to sa.flatMap(a => sb.map(b => f(a,b))).
+   */
+  def map2Stream[A,B,C](sa: Stream[A], sb: => Stream[B])(f: (A,=>B) => C): Stream[C] =
+    for { a <- sa; b <- sb } yield f(a,b)
+
+  /* This is a function we've implemented before. Unfortunately, it does not
+   * exist in the standard library. This implementation is uses a foldLeft,
+   * followed by a reverse, which is equivalent to a foldRight, but does not
+   * use any stack space.
+   */
+  def sequenceOption[A](o: List[Option[A]]): Option[List[A]] =
+    o.foldLeft[Option[List[A]]](Some(List()))(
+      (t,h) => map2Option(h,t)(_ :: _)).map(_.reverse)
+
+  /* Notice we are using the `unbounded` definition here, which is just
+   * `Stream(None)` in our current representation of `exhaustive`.
+   */
+  def uniform: Gen[Double] =
+    Gen(State(RNG.double), unbounded)
+
+  def choose(i: Double, j: Double): Gen[Double] =
+    Gen(State(RNG.double).map(d => i + d*(j-i)), unbounded)
+
+  /* Basic idea is add 1 to the result of `choose` if it is of the wrong
+   * parity, but we require some special handling to deal with the maximum
+   * integer in the range.
+   */
+  def even(start: Int, stopExclusive: Int): Gen[Int] =
+    choose(start, if (stopExclusive%2 == 0) stopExclusive - 1 else stopExclusive).
+    map (n => if (n%2 != 0) n+1 else n)
+
+  def odd(start: Int, stopExclusive: Int): Gen[Int] =
+    choose(start, if (stopExclusive%2 != 0) stopExclusive - 1 else stopExclusive).
+    map (n => if (n%2 == 0) n+1 else n)
+
+  def sameParity(from: Int, to: Int): Gen[(Int,Int)] = for {
+    i <- choose(from,to)
+    j <- if (i%2 == 0) even(from,to) else odd(from,to)
+  } yield (i,j)
+
+  def listOfN_1[A](n: Int, g: Gen[A]): Gen[List[A]] =
+    List.fill(n)(g).foldRight(unit(List[A]()))((a,b) => a.map2(b)(_ :: _))
+
+  /* The simplest possible implementation. This will put all elements of one
+   * `Gen` before the other in the exhaustive traversal. It might be nice to
+   * interleave the two streams, so we get a more representative sample if we
+   * don't get to examine the entire exhaustive stream.
+   */
+  def union_1[A](g1: Gen[A], g2: Gen[A]): Gen[A] =
+    boolean.flatMap(b => if (b) g1 else g2)
+
+  def union[A](g1: Gen[A], g2: Gen[A]): Gen[A] =
+    Gen(
+      State(RNG.boolean).flatMap(b => if (b) g1.sample else g2.sample),
+      interleave(g1.exhaustive, g2.exhaustive)
+    )
+
+  def interleave[A](s1: Stream[A], s2: Stream[A]): Stream[A] =
+    s1.zipAll(s2).flatMap { case (a,a2) => Stream((a.toList ++ a2.toList): _*) }
+
+  /* The random case is simple - we generate a double and use this to choose between
+   * the two random samplers. The exhaustive case is trickier if we want to try
+   * to produce a stream that does a weighted interleave of the two exhaustive streams.
+   */
+  def weighted[A](g1: (Gen[A],Double), g2: (Gen[A],Double)): Gen[A] = {
+    /* The probability we should pull from `g1`. */
+    val g1Threshold = g1._2.abs / (g1._2.abs + g2._2.abs)
+
+    /* Some random booleans to use for selecting between g1 and g2 in the exhaustive case.
+     * Making up a seed locally is fine here, since we just want a deterministic schedule
+     * with the right distribution. */
+    def bools: Stream[Boolean] =
+      randomStream(uniform.map(_ < g1Threshold))(RNG.Simple(302837L))
+
+    Gen(State(RNG.double).flatMap(d => if (d < g1Threshold) g1._1.sample else g2._1.sample),
+        interleave(bools, g1._1.exhaustive, g2._1.exhaustive))
+  }
+
+  /* Produce an infinite random stream from a `Gen` and a starting `RNG`. */
+  def randomStream[A](g: Gen[A])(rng: RNG): Stream[A] =
+    Stream.unfold(rng)(rng => Some(g.sample.run(rng)))
+
+  /* Interleave the two streams, using `b` to control which stream to pull from at each step.
+   * A value of `true` attempts to pull from `s1`; `false` attempts to pull from `s1`.
+   * When either stream is exhausted, insert all remaining elements from the other stream.
+   */
+  def interleave[A](b: Stream[Boolean], s1: Stream[A], s2: Stream[A]): Stream[A] =
+    b.headOption map { hd =>
+      if (hd) s1 match {
+        case Cons(h, t) => Stream.cons(h(), interleave(b drop 1, t(), s2))
+        case _ => s2
+      }
+      else s2 match {
+        case Cons(h, t) => Stream.cons(h(), interleave(b drop 1, s1, t()))
+        case _ => s1
+      }
+    } getOrElse Stream.empty
+
+  def listOf[A](g: Gen[A]): SGen[List[A]] =
+    Sized(n => g.listOfN(n))
+
+  /* Not the most efficient implementation, but it's simple.
+   * This generates ASCII strings.
+   */
+  def stringN(n: Int): Gen[String] =
+    listOfN(n, choose(0,127)).map(_.map(_.toChar).mkString)
+
+  def string: SGen[String] = Sized(stringN)
+
+  case class Sized[+A](forSize: Int => Gen[A]) extends SGen[A]
+  case class Unsized[+A](get: Gen[A]) extends SGen[A]
+
+  implicit def unsized[A](g: Gen[A]): SGen[A] = Unsized(g)
+
+  val smallInt = Gen.choose(-10,10)
+  val maxProp = forAll(listOf(smallInt)) { l =>
+    val max = l.max
+    !l.exists(_ > max) // No value greater than `max` should exist in `l`
+  }
+
+  def listOf1[A](g: Gen[A]): SGen[List[A]] =
+    Sized(n => g.listOfN(n max 1))
+
+  val maxProp1 = forAll(listOf1(smallInt)) { l =>
+    val max = l.max
+    !l.exists(_ > max) // No value greater than `max` should exist in `l`
+  }
+
+  val sortedProp = forAll(listOf(smallInt)) { l =>
+    val ls = l.sorted
+    l.isEmpty || ls.tail.isEmpty || !l.zip(ls.tail).exists { case (a,b) => a > b }
+  }
+
+  object ** {
+    def unapply[A,B](p: (A,B)) = Some(p)
+  }
+
+  /* A `Gen[Par[Int]]` generated from a list summation that spawns a new parallel
+   * computation for each element of the input list summed to produce the final
+   * result. This is not the most compelling example, but it provides at least some
+   * variation in structure to use for testing.
+   */
+  lazy val pint2: Gen[Par[Int]] = choose(-100,100).listOfN(choose(0,20)).map(l =>
+    l.foldLeft(Par.unit(0))((p,i) =>
+      Par.fork { Par.map2(p, Par.unit(i))(_ + _) }))
+
+  def genStringIntFn(g: Gen[Int]): Gen[String => Int] =
+    g map (i => (s => i))
+}
+
+trait SGen[+A] {
+  def map[B](f: A => B): SGen[B] = this match {
+    case Sized(g) => Sized(g andThen (_ map f))
+    case Unsized(g) => Unsized(g map f)
+  }
+  def flatMap[B](f: A => Gen[B]): SGen[B] = this match {
+    case Sized(g) => Sized(g andThen (_ flatMap f))
+    case Unsized(g) => Unsized(g flatMap f)
+  }
+  def **[B](s2: SGen[B]): SGen[(A,B)] = (this,s2) match {
+    case (Sized(g), Sized(g2)) => Sized(n => g(n) ** g2(n))
+    case (Unsized(g), Unsized(g2)) => Unsized(g ** g2)
+    case (Sized(g), Unsized(g2)) => Sized(n => g(n) ** g2)
+    case (Unsized(g), Sized(g2)) => Sized(n => g ** g2(n))
+  }
+}
diff --git a/src/main/scala/answers/src/main/scala/fpinscala/testing/Gen.scala b/src/main/scala/answers/src/main/scala/fpinscala/testing/Gen.scala
new file mode 100644
index 0000000..d2610c2
--- /dev/null
+++ b/src/main/scala/answers/src/main/scala/fpinscala/testing/Gen.scala
@@ -0,0 +1,305 @@
+package fpinscala.testing
+
+import fpinscala.laziness.Stream
+import fpinscala.state._
+import fpinscala.parallelism._
+import fpinscala.parallelism.Par.Par
+import Gen._
+import Prop._
+import java.util.concurrent.{Executors,ExecutorService}
+import language.postfixOps
+import language.implicitConversions
+
+case class Prop(run: (MaxSize,TestCases,RNG) => Result) {
+  def &&(p: Prop) = Prop {
+    (max,n,rng) => run(max,n,rng) match {
+      case Passed | Proved => p.run(max, n, rng)
+      case x => x
+    }
+  }
+
+  def ||(p: Prop) = Prop {
+    (max,n,rng) => run(max,n,rng) match {
+      // In case of failure, run the other prop.
+      case Falsified(msg, _) => p.tag(msg).run(max,n,rng)
+      case x => x
+    }
+  }
+
+  /* This is rather simplistic - in the event of failure, we simply prepend
+   * the given message on a newline in front of the existing message.
+   */
+  def tag(msg: String) = Prop {
+    (max,n,rng) => run(max,n,rng) match {
+      case Falsified(e, c) => Falsified(msg + "\n" + e, c)
+      case x => x
+    }
+  }
+}
+
+object Prop {
+  type SuccessCount = Int
+  type TestCases = Int
+  type MaxSize = Int
+  type FailedCase = String
+
+  sealed trait Result {
+    def isFalsified: Boolean
+  }
+  case object Passed extends Result {
+    def isFalsified = false
+  }
+  case class Falsified(failure: FailedCase,
+                       successes: SuccessCount) extends Result {
+    def isFalsified = true
+  }
+  case object Proved extends Result {
+    def isFalsified = false
+  }
+
+
+  /* Produce an infinite random stream from a `Gen` and a starting `RNG`. */
+  def randomStream[A](g: Gen[A])(rng: RNG): Stream[A] =
+    Stream.unfold(rng)(rng => Some(g.sample.run(rng)))
+
+  def forAll[A](as: Gen[A])(f: A => Boolean): Prop = Prop {
+    (n,rng) => randomStream(as)(rng).zip(Stream.from(0)).take(n).map {
+      case (a, i) => try {
+        if (f(a)) Passed else Falsified(a.toString, i)
+      } catch { case e: Exception => Falsified(buildMsg(a, e), i) }
+    }.find(_.isFalsified).getOrElse(Passed)
+  }
+
+
+  // String interpolation syntax. A string starting with `s"` can refer to
+  // a Scala value `v` as `$v` or `${v}` in the string.
+  // This will be expanded to `v.toString` by the Scala compiler.
+  def buildMsg[A](s: A, e: Exception): String =
+    s"test case: $s\n" +
+    s"generated an exception: ${e.getMessage}\n" +
+    s"stack trace:\n ${e.getStackTrace.mkString("\n")}"
+
+  def apply(f: (TestCases,RNG) => Result): Prop =
+    Prop { (_,n,rng) => f(n,rng) }
+
+  def forAll[A](g: SGen[A])(f: A => Boolean): Prop =
+    forAll(g(_))(f)
+
+  def forAll[A](g: Int => Gen[A])(f: A => Boolean): Prop = Prop {
+    (max,n,rng) =>
+      val casesPerSize = (n - 1) / max + 1
+      val props: Stream[Prop] =
+        Stream.from(0).take((n min max) + 1).map(i => forAll(g(i))(f))
+      val prop: Prop =
+        props.map(p => Prop { (max, n, rng) =>
+          p.run(max, casesPerSize, rng)
+        }).toList.reduce(_ && _)
+      prop.run(max,n,rng)
+  }
+
+  def run(p: Prop,
+          maxSize: Int = 100,
+          testCases: Int = 100,
+          rng: RNG = RNG.Simple(System.currentTimeMillis)): Unit =
+    p.run(maxSize, testCases, rng) match {
+      case Falsified(msg, n) =>
+        println(s"! Falsified after $n passed tests:\n $msg")
+      case Passed =>
+        println(s"+ OK, passed $testCases tests.")
+      case Proved =>
+        println(s"+ OK, proved property.")
+    }
+
+  val ES: ExecutorService = Executors.newCachedThreadPool
+  val p1 = Prop.forAll(Gen.unit(Par.unit(1)))(i =>
+    Par.map(i)(_ + 1)(ES).get == Par.unit(2)(ES).get)
+
+  def check(p: => Boolean): Prop = Prop { (_, _, _) =>
+    if (p) Passed else Falsified("()", 0)
+  }
+
+  val p2 = check {
+    val p = Par.map(Par.unit(1))(_ + 1)
+    val p2 = Par.unit(2)
+    p(ES).get == p2(ES).get
+  }
+
+  def equal[A](p: Par[A], p2: Par[A]): Par[Boolean] =
+    Par.map2(p,p2)(_ == _)
+
+  val p3 = check {
+    equal (
+      Par.map(Par.unit(1))(_ + 1),
+      Par.unit(2)
+    ) (ES) get
+  }
+
+  val S = weighted(
+    choose(1,4).map(Executors.newFixedThreadPool) -> .75,
+    unit(Executors.newCachedThreadPool) -> .25) // `a -> b` is syntax sugar for `(a,b)`
+
+  def forAllPar[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
+    forAll(S.map2(g)((_,_))) { case (s,a) => f(a)(s).get }
+
+  def checkPar(p: Par[Boolean]): Prop =
+    forAllPar(Gen.unit(()))(_ => p)
+
+  def forAllPar2[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
+    forAll(S ** g) { case (s,a) => f(a)(s).get }
+
+  def forAllPar3[A](g: Gen[A])(f: A => Par[Boolean]): Prop =
+    forAll(S ** g) { case s ** a => f(a)(s).get }
+
+  val pint = Gen.choose(0,10) map (Par.unit(_))
+  val p4 =
+    forAllPar(pint)(n => equal(Par.map(n)(y => y), n))
+
+  val forkProp = Prop.forAllPar(pint2)(i => equal(Par.fork(i), i)) tag "fork"
+}
+
+case class Gen[+A](sample: State[RNG,A]) {
+  def map[B](f: A => B): Gen[B] =
+    Gen(sample.map(f))
+
+  def map2[B,C](g: Gen[B])(f: (A,B) => C): Gen[C] =
+    Gen(sample.map2(g.sample)(f))
+
+  def flatMap[B](f: A => Gen[B]): Gen[B] =
+    Gen(sample.flatMap(a => f(a).sample))
+
+  /* A method alias for the function we wrote earlier. */
+  def listOfN(size: Int): Gen[List[A]] =
+    Gen.listOfN(size, this)
+
+  /* A version of `listOfN` that generates the size to use dynamically. */
+  def listOfN(size: Gen[Int]): Gen[List[A]] =
+    size flatMap (n => this.listOfN(n))
+
+  def listOf: SGen[List[A]] = Gen.listOf(this)
+  def listOf1: SGen[List[A]] = Gen.listOf1(this)
+
+  def unsized = SGen(_ => this)
+
+  def **[B](g: Gen[B]): Gen[(A,B)] =
+    (this map2 g)((_,_))
+}
+
+object Gen {
+  def unit[A](a: => A): Gen[A] =
+    Gen(State.unit(a))
+
+  val boolean: Gen[Boolean] =
+    Gen(State(RNG.boolean))
+
+  def choose(start: Int, stopExclusive: Int): Gen[Int] =
+    Gen(State(RNG.nonNegativeInt).map(n => start + n % (stopExclusive-start)))
+
+  def listOfN[A](n: Int, g: Gen[A]): Gen[List[A]] =
+    Gen(State.sequence(List.fill(n)(g.sample)))
+
+  val uniform: Gen[Double] = Gen(State(RNG.double))
+
+  def choose(i: Double, j: Double): Gen[Double] =
+    Gen(State(RNG.double).map(d => i + d*(j-i)))
+
+  /* Basic idea is to add 1 to the result of `choose` if it is of the wrong
+   * parity, but we require some special handling to deal with the maximum
+   * integer in the range.
+   */
+  def even(start: Int, stopExclusive: Int): Gen[Int] =
+    choose(start, if (stopExclusive%2 == 0) stopExclusive - 1 else stopExclusive).
+    map (n => if (n%2 != 0) n+1 else n)
+
+  def odd(start: Int, stopExclusive: Int): Gen[Int] =
+    choose(start, if (stopExclusive%2 != 0) stopExclusive - 1 else stopExclusive).
+    map (n => if (n%2 == 0) n+1 else n)
+
+  def sameParity(from: Int, to: Int): Gen[(Int,Int)] = for {
+    i <- choose(from,to)
+    j <- if (i%2 == 0) even(from,to) else odd(from,to)
+  } yield (i,j)
+
+  def listOfN_1[A](n: Int, g: Gen[A]): Gen[List[A]] =
+    List.fill(n)(g).foldRight(unit(List[A]()))((a,b) => a.map2(b)(_ :: _))
+
+  def union[A](g1: Gen[A], g2: Gen[A]): Gen[A] =
+    boolean.flatMap(b => if (b) g1 else g2)
+
+  def weighted[A](g1: (Gen[A],Double), g2: (Gen[A],Double)): Gen[A] = {
+    /* The probability we should pull from `g1`. */
+    val g1Threshold = g1._2.abs / (g1._2.abs + g2._2.abs)
+
+    Gen(State(RNG.double).flatMap(d => if (d < g1Threshold) g1._1.sample else g2._1.sample))
+  }
+
+  def listOf[A](g: Gen[A]): SGen[List[A]] =
+    SGen(n => g.listOfN(n))
+
+  /* Not the most efficient implementation, but it's simple.
+   * This generates ASCII strings.
+   */
+  def stringN(n: Int): Gen[String] =
+    listOfN(n, choose(0,127)).map(_.map(_.toChar).mkString)
+
+  val string: SGen[String] = SGen(stringN)
+
+  implicit def unsized[A](g: Gen[A]): SGen[A] = SGen(_ => g)
+
+  val smallInt = Gen.choose(-10,10)
+  val maxProp = forAll(listOf(smallInt)) { l =>
+    val max = l.max
+    !l.exists(_ > max) // No value greater than `max` should exist in `l`
+  }
+
+  def listOf1[A](g: Gen[A]): SGen[List[A]] =
+    SGen(n => g.listOfN(n max 1))
+
+  val maxProp1 = forAll(listOf1(smallInt)) { l =>
+    val max = l.max
+    !l.exists(_ > max) // No value greater than `max` should exist in `l`
+  }
+
+  // We specify that every sorted list is either empty, has one element,
+  // or has no two consecutive elements `(a,b)` such that `a` is greater than `b`.
+  val sortedProp = forAll(listOf(smallInt)) { l =>
+    val ls = l.sorted
+    l.isEmpty || ls.tail.isEmpty || !ls.zip(ls.tail).exists { case (a,b) => a > b }
+  }
+
+  object ** {
+    def unapply[A,B](p: (A,B)) = Some(p)
+  }
+
+  /* A `Gen[Par[Int]]` generated from a list summation that spawns a new parallel
+   * computation for each element of the input list summed to produce the final
+   * result. This is not the most compelling example, but it provides at least some
+   * variation in structure to use for testing.
+   *
+   * Note that this has to be a `lazy val` because of the way Scala initializes objects.
+   * It depends on the `Prop` companion object being created, which references `pint2`.
+   */
+  lazy val pint2: Gen[Par[Int]] = choose(-100,100).listOfN(choose(0,20)).map(l =>
+    l.foldLeft(Par.unit(0))((p,i) =>
+      Par.fork { Par.map2(p, Par.unit(i))(_ + _) }))
+
+  def genStringIntFn(g: Gen[Int]): Gen[String => Int] =
+    g map (i => (s => i))
+}
+
+case class SGen[+A](g: Int => Gen[A]) {
+  def apply(n: Int): Gen[A] = g(n)
+
+  def map[B](f: A => B): SGen[B] =
+    SGen { g(_) map f }
+
+  def flatMap[B](f: A => SGen[B]): SGen[B] = {
+    val g2: Int => Gen[B] = n => {
+      g(n) flatMap { f(_).g(n) }
+    }
+    SGen(g2)
+  }
+
+  def **[B](s2: SGen[B]): SGen[(A,B)] =
+    SGen(n => apply(n) ** s2(n))
+}
+
-- 
2.7.4

